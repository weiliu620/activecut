\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb} \setcounter{tocdepth}{3} \usepackage{graphicx}

\usepackage{url} \urldef{\mailsa}\path|{alfred.hofmann, ursula.barth,
  ingrid.haas, frank.holzwarth,| \urldef{\mailsb}\path|anna.kramer,
  leonie.kunz, christine.reiss, nicole.sator,|
  \urldef{\mailsc}\path|erika.siebert-cole, peter.strasser,
  lncs}@springer.com|
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
  \noindent\keywordname\enspace\ignorespaces#1}

% added by Wei Liu
\usepackage{lwdefs}


\begin{document}

\mainmatter % start of an individual contribution


\title{Spatial Regularization of Functional Connectivity Using
  High-Dimensional Markov Random Fields}


\titlerunning{Functional connectivity using high dimensional MRF}
%
\author{}
% \author{Wei Liu, Jeffrey S. Anderson, and P. Thomas Fletcher }

%
% \authorrunning{Lecture Notes in Computer Science: Authors'
%   Instructions}

\institute{}
  

\toctitle{Functional connectivity using MRF} \tocauthor{Authors'
  Instructions}
\maketitle

\begin{abstract}
In this paper we present a new method for spatial regularization of functional
connectivity maps based on Markov Random Field (MRF) priors. The high level of
noise in fMRI leads to errors in functional connectivity detection
algorithms. These errors can be mitigated by some form of spatial
regularization, which leverages correlations between neighboring voxels. A
common approach along these lines is to apply a spatial Gaussian smoothing, but
this can lead to small connectivity regions being lost and to blurring of
regions beyond their actual boundaries. Recent work has proposed MRFs as spatial
priors in detection of fMRI activation in task-based paradigms. We propose to
apply MRF priors to the computation of functional connectivity in resting-state
fMRI. Our Markov priors are in the space of pairwise voxel connections, rather
than in the original image space, resulting in a MRF whose dimension is twice
that of the original image. This prior has the intuitive interpretation that a
pair of voxels are more likely to be connected if they are connected to each
others neighbors. The high dimensionality of the MRF estimation problem leads to
computational challenges. We present an efficient, highly parallelized algorithm
on the Graphics Processing Unit (GPU). We validate our approach on a
synthetically generated example as well as real data from a resting state fMRI
study.
\end{abstract}
 
\section{Introduction}

Functional magnetic resonance imaging (fMRI) provides a non-invasive measurement
of cerebral blood flow in the brain that can be used to infer regions of neural
activity. Traditional fMRI studies are based on measuring the response to a set
of stimuli, and analysis involves testing the time series at each voxel for
correlations with the experimental protocol. Recently, there has been growing
interest in using resting-state fMRI to infer the connectivity between spatially
distant regions. A standard approach is to use correlation between pairs of time
series as a measurement of their functional connectivity. The high level of
noise present in fMRI can cause errors in pairwise connectivity measurements,
resulting in spurious false connections as well as false negatives.

In both task-based and resting-state fMRI the impact of imaging noise can be
reduced by taking advantage of the spatial correlations between neighoring
voxels in the image. A common approach used for instance in Statistical
Parametric Mapping (SPM) \cite{Friston95} is to apply a spatial Gaussian filter
to smooth the signal prior to statistical analysis. However, this can lead to
overly blurred results, where effects with small spatial extent can be lost and
detected regions may extend beyond their actual boundaries. An alternative
approach to spatial regularization that has been proposed for task activation
paradigms is to use a Markov Random Field (MRF) prior
\cite{Descombes1,Descombes2,Cosman,Ou,Woolrich}, which models the conditional
dependence of the signals in neighboring voxels.

In this work we propose to use MRF models in resting-state fMRI in order to
leverage spatial correlations in functional connectivity maps. Unlike previous
MRF-based approaches, which use the neighborhood structure defined by the
original image voxel grid, the neighborhoods in functional connectivity must
take in to account the possibility relationships between spatially distant
voxels. Therefore, we define the neighborhood graph on the set of all voxel
pairs. This results in a Markov structure on a grid with twice the dimension of
the original image data, i.e., the pairwise connectivities for three-dimensional
images results in a six-dimensional MRF. Intuitively, the neighborhood structure
is defined so that two voxels are more likely to be connected if they are
connected to each other's spatial neighbors.

We combine the Markov prior on functional connectivity maps with a likelihood
model of the time series correlations in a posterior estimation problem.
Furthermore, we model the parameters of the MRF and likelihood as unobserved
random variables in a fully Bayesian framework. The full model is solved using
an Expectation Maximization (EM) algorithm. In the estimation step the posterior
random field is sampled using Gibbs Sampling and estimated using Mean Field
theory.

In the next section we describe our MRF model of functional connectivity maps.
In Section~\ref{sec:algorithm} we give the details of the algorithm to estimate
the functional connectivity probabilities, including implementation details for
the GPU solver. Finally, in Section~\ref{sec:results} we demonstrate the
advantages of our approach on a synthetically generated data set as well as on
real resting-state fMRI data.

% In this paper we use Markov Random field in modeling this spatial
% dependency. existing method that use MRF in fMRI study in (Woolrich
% 2005) have a two state study. In the first step use a univariate
% method of SPM to get the response of each voxel, and in the second
% step, build a MRF on the response.

% Our method is different from previous method in that we do not build
% MRF on the voxels. Instead we look at the connectivity between any
% pair of two voxels. Because the connectivity of two voxels depend on
% the connectivity of the voxels' neighbors, we can also get a random
% field with the `connectivity' as the site of the field. We call this
% the connectivity field. The connectivity is a discrete label with
% possible value $0$ and $1$.

% This connectivity field is Gibbs distribution under (??theory). We use
% Gaussian distribution as the emission function to generate the data
% (here is correlation between two voxels/time series). Then given the
% correlation map, compute the posterior probability that two voxels
% have connectivity 1, which again is a Gibbs distribution. The model
% parameters are estimated by mean field theory and
% Expectation-Maximization method. 

% Our method is different with previous
% application of MRF in fMRI\cite{woolrich_mixture_2005} in that they
% assume smoothness on the $t$ statistics and apply MRF as a second
% stage.

% The novel part of this study is by using MRF to model prior
% distribution of connectivity in a Bayesian framework, we combine the
% information from prior knowledge of 'spatial continuity' and those
% from data, without applying spatial smoothing. In addition, other
% modality like fiber tracking of DT-MRI can be integrated into this
% frame work as a prior knowledge.

% Once we have the posterior probability of the connectivity between any
% pair of voxels or regions, we can use this to compute a default
% functional network. (LW: this is going to far, we haven't done that
% yet. should be in in the 'analysis' or 'conclusion' section).

\section{Markov Random Fields for Functional Connectivity}
<<<<<<< .mine
\ref{sec:model}
Markov Random Field is a powerful tool to model spatial
property. Conventional application of MRF on image segmentation define
the sites of the field as the pixel in a 2D image or voxels in 3D
image. Because our goal is pairwise connectivity between two
images (either same or different), we need to define a MRF in a high
dimensional space:
=======
\label{sec:model}


Conventional image analysis applications of MRFs define the set of sites of the
random field as the image voxels, with the neighborhood structure given by a
regular lattice. Because we are studying the pairwise connectivity between
voxels, we need to define a MRF in the higher-dimensional space of voxel
location pairs. Thus, if $\Omega \subset \mathbb{Z}^d$ is a $d$-dimensional
image domain, then the sites for our connectivity MRF form the set $\mathcal{S}
= \Omega \times \Omega$. Let $i, j \in \Omega$ be voxel locations, and let
$\mathcal{N}_i, \mathcal{N}_j$ denote the set of neighbors of voxel $i$ and $j$,
respectively, in the original image lattice. Then the set of neighbors for the
site $(i, j) \in \mathcal{S}$ is given by $\mathcal{N}_{ij} = (\{i\} \times
\mathcal{N}_y) \cup (\mathcal{N}_x \times \{j\})$. In other words, two sites are
neighbors if they share one coordinate and their other coordinates are neighbors
in the original image lattice. This neighborhood structure will give us the
property in the MRF that two voxels $i, j$ in the image are more likely to be
connected if $i$ is connected to $j$'s neighbors or vice-versa. Equipped with
this graph structure, $\mathcal{S}$ is a regular $2d$-dimensional lattice.

We next define a multivariate random variable $\vec x = \{ x_{ij} \}$ on the set
$\mathcal{S}$, where each random variable $x_{ij}$ is a binary variable that
denotes the connectivity ($x_{ij} = 1$) or lack of connectivity ($x_{ij} = -1$)
between voxel $i$ and $j$. If $A \subset \mathcal{S}$, let $\vec x_A$ denote the
set of all $x_{ij}$ with $(i,j) \in A$, and let $\vec x_{-ij}$ denote the
collection of all variables in $\vec x$ excluding $x_{ij}$. For $\vec x$ to be a
MRF it must satisfy the Markov property,
>>>>>>> .r33
\begin{equation*}
  P( x_{ij} \, | \, \vec x_{-ij}) = p(x_{ij} \, | \, x_{\mathcal{N}_{ij}}).
\end{equation*}
<<<<<<< .mine
$\mathcal{S}$ is the set of sites in a four-dimension regular
lattice. $i$, $j$ are indeces in original image $\mat A$, and $k$, $l$
are indices in image $\mat B$. We can also define a linear index $n$
for the four-tuple $(i, j, k, l)$. We then define a multivariate
random variable $\vec x = \{ x_1,\dots, x_N\}$ on the set
$\mathcal{S}$, and each random variable $x_n$ denotes the connectivity
between pixel $a_{i, j}$ and $b_{k, l}$. The
family $\vec x$ is random field because given all other random
variable $x_{-n}$, the distribution of $x_n$ only depend on its
neighbors in 4-D lattice. And these neighbors correspond to
connectivity between neighbors of $a_{i,j}$ in original image $\mat A$
and $b_{k,l}$ in $\mat B$., and also the connectivity between
$a_{i,j}$ and neighbors of $b_{i,j}$. 
\begin{equation*}
  P( x_n \lvert \vec x_{-n}) = p(x_n | x_{\mathcal{N}_n}).
\end{equation*}
If we define four neighbors of $a_{i,j}$ and $b_{i,j}$ respectively,
there will be eight neighbors for site $s_n$. The dimensions of image
$\mat A$ and $\mat B$ can be any between $1$ to $3$, and accordingly
$\mathcal{S}$ and $\vec x$ can be any from 2-D to 6-D. In this paper
we only consider connectivity between two 2-D image as illustration
so $\vec x$ is 4-D.
=======
>>>>>>> .r33
 
<<<<<<< .mine
The equivalence between Markov random fields and Gibbs distribution
\cite{besag_spatial_1974} pointed out $X$ is Markov random field if
and only if it is also Gibbs distribution defined as
=======
According to the Hammersley and Clifford Theorem, $\vec x$ is Markov random
field if and only if it is also a Gibbs distribution, defined as
>>>>>>> .r33
\begin{equation}
  P(\vec x) = \frac{1}{Z}\exp\left(-U(\vec x)\right),
\end{equation}
<<<<<<< .mine
where $U(\vec x) = \sum_{c}^{}V_c$ is energy function with
$V_c$ the clique potential. We use a special version of MRF --
Ising model, because like Ising model, our variable $x$ only have two states:
connectivity is defined by $x = +1$, and non-connectivity is defined
by $x = -1$. The energy function for a single data point is given by $
U(x_n) = - \beta \sum_{m \in \mathcal{N}_n }^{}x_n x_m$, with
$\mathcal{N}_n$ the neighbors of $x_n$. When $\beta > 0$, this
definition favors identity of neighbors. The partition function $Z$ is
given by $Z =  \exp\{-U(x=1)\} + \exp \{ -U(x=-1)\}$.
=======
where $U$ is the energy function $U(\vec x) = \sum_{c} V_c$, with clique
potentials $V_c$. We use a particular form of MRF---the Ising model---which is a
commonly used model for MRFs with binary states. In this model the energy
function for a single data point is given by $ U(x_{ij}) = - \beta \sum_{(m,n)
  \in \mathcal{N}_{ij} } x_{ij} x_{mn}$. When $\beta > 0$, this definition
favors similarity of neighbors. The partition function $Z$ is given by $Z =
\exp\left(-U(1)\right) + \exp \left( -U(-1)\right)$.
>>>>>>> .r33

What we are really interested in is the posterior connectivity, given
functional MRI data. Because the connectivity measures the
relationship between pairs of voxels, we compute the pairwise
correlation between the time courses on any pair of voxels, and get a
correlation matrix $\vec y$, which like $\vec x$, is also defined
on the high dimensional lattice $\mathcal{S}$, hence is also a high
dimension matrix.  Then the posterior connectivity is $P(\vec x |\vec
y)$, where $\vec y$ is the vector notation of the correlation matrix,
and $\vec y = \{y_n, n = 1,2, \dots, N\}$.

The linear correlation is not the only choice for $\vec y$. We can use
any statistics between time series as long as it indicates the
'affinity' between two voxels. For example, coherence
\cite{mller_multivariate_2001,thirion_detection_2006} in
frequency domain can be good choice if the interest is on the
frequency property of the data.

For inference of posterior connectivity map, we need to define the
conditional likelihood $P(y_n\lvert x_n)$, which is called emission
function in MRF theory. It means given the current site is `connected'
or not, how the data looks like. This is defined as Gaussian
distribution with unknown $\mu$ and $\sigma^2$. It is noted that each
correlation $y_n$ on site $s_n$ only depends on the latent variable
$x_n$ on the same site, and does not depend on neighbors of
$x_n$. With both prior and conditional likelihood available, we define
the posterior as
\begin{equation}
  P(x_n  = k| y_n) \prop P(x_n) P(y_n|x_n) \prop \exp\{\beta\sum_{m \in \mathcal{N}_n}x_n x_m \} \exp \{ -\frac{(x_n - \mu_k)^2}{2\sigma_k^2} - \log(\sigma_k)\} \label{eq:1}
\end{equation}
Once the models are available we also need to know the model's
parameters. We do not know the parameter $\beta$ in the energy
function \eqref{eq:1}, neither do we know the $\mu$ and $\sigma^2$ in
the conditional likelihood $P( y_n| x_n)$. If the connectivity
variable $\vec x$ is available, we can use Maximum-Likelihood method
to estimate them by maximizing the joint probability $P(\vec x, \vec
y)$. However, to know $\vec x$, we need to compute posterior, which
again need the parameters.

we use a Expectation-Maximization method to alternate the above two
steps iteratively. In \textbf{E} step, with properly initialized
parameters, we compute the posterior probability for each $x_n$, and
sample $x_n$ from posterior distribution by Gibbs Sampling. We then
compute the expected value of each connectivity node by mean field
theory. Mean field is computed by replacing the neighbor $x_m$ in
\eqref{eq:1} by its expected value $\langle x_m\rangle$. After we
compute the posterior of current point $x_n$, we update $x_n$ also by
its expected value $\langle x_n \rangle$.

In \textbf{M} step, with $\vec \langle \vec x \rangle$ and data $\vec y$,
the complete data set $\{\vec x, \vec y\}$ is available, and we
estimate the parameters by Maximizing the pseudo likelihood 
\begin{equation}
P(\vec x, \vec y) = \prod_{n=1}^{N}P (x_n) P(y_n|x_n) \label{eq:2}
\end{equation}
. Since this is quadratic
function of parameters $\beta$, $\mu$ and $\sigma^2$, Newton's method
is used to find the global maximum.  After some EM iterations, we get
stable parameters, an additional annealing procedure
\cite{an_stochastic_1984} is followed to get the final MAP estimation.

\section{EM Algorithm and GPU Implementation}
\label{sec:algorithm}
The whole algorithm involves updating a high dimensional connectivity
matrix $\vec x$, iteratively and hence have high computation cost. We
designed a parallel Markov random field updating strategy on graphics
processing unit (GPU). The algorithm take only a few minutes compared
with more than 1 hour on CPU counterpart.

To fit the algorithm into GPU's architecture, we use some special
strategy. First, because GPU only support 3-dimensional array, we have
to reshape high-dimensional matrix $\vec x$ and $\vec y$ by linear
indexing their original subscripts, i.e. $\vec x_{i,j,k,l} = x_{p,
  q}$, where $p\rightarrow (i,j)$ and $q \rightarrow (k,l)$.  Second,
parallel updating each site of MRF have to make sure a site is not
updated at same time with its neighbors, otherwise the field would
fall into a checkerboard-like local maximum. Our strategy is to divide
all the sites of the field into sub-groups, and no neighbors of a
site are in the same sub-group with the site itself.  We then can
update the sub-group sequentially.
\begin{algorithm}[ht]
  \begin{algorithmic}
    \REQUIRE Sample correlation matrix $\mat Y$ with $y_n$ the sample
    correlation between voxel $a_{i,j}$ and $b_{k,l}$.
    \STATE Init posterior matrix by maximizing conditional likelihood
    $P(y_n|x_n)$.  
    \WHILE{$\Delta \{\beta, \mu, \sigma^2 \} >
      \varepsilon$ } 
    \STATE \textbf{E step: }

    (a) Based on the current
    parameters, compute the posterior by \eqref{eq:1}.

    (b) Repeatedly Do Gibbs Sampling until the field  stabilize.

    (c) Based on current value of $x_n$, iteratively compute the mean
    field for all nodes in $\mathcal{S}$ until the field stable.

    \STATE \textbf{M step: } 

    (d) With complete data $\{\vec x, \vec
    y\}$, estimate $\beta$ , $\mu$ and $\sigma^2$by maximizing
    \eqref{eq:2}.
    \ENDWHILE

    (e) Stochastic annealing the posterior probability using parameters
    estimated in previous EM
  \end{algorithmic}
\end{algorithm}

\section{Results}
\label{sec:results}
We first construct two set of synthetic time series, each set can be
seen as a 1-D image with each pixel a time course signal. The time
course was constructed with sine waves of amplitude $A$ plus additive
Gaussian noise of variance $\sigma^2$.  We only add sine wave signal in
some time series while others are purely Gaussian noise. Between
those pixels containing signals the connectivity is $1$, otherwise it
is $0$.

To compare our MRF model with conventional correlation after smoothing
procedure, we did both test on the same data set and have the results
in fig. \ref{fig:1}. on the correlation map of top row, we see
smoothing does remove noise and after smoothing the correlation map
looks more like true connectivity map. However it also smoothed out
small interested regions and leads to more false positive as can be
seen from fig \ref{fig:1e}. By using MRF, fig. \ref{fig:1f} shows true
connectivity region's structure is detected and most false positive
are removed. 

 
\begin{figure}[htb]
  \centering \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/trueConn}
    \label{fig:1a}
  } \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/corrNoSmooth}
    \label{fig:1b}
  } \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/SampleCorr}
    \label{fig:1c}
  }\\ 
  \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/threholdCorrRaw}
    \label{fig:1d}
  } \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/threholdCorrSmoothed}
    \label{fig:1e}
  }
  \subfigure[]{
    \includegraphics[width = 0.25\textwidth]{figures/newtoy/newpost_sym}
  \label{fig:1f}
  }
  \caption[Test on synthetic data.]{Test of synthetic data, showing the (a)
    ground-truth connectivity, (b) correlation of original, noisy data, (c)
    correlation of Gaussian-smoothed data, (d) connectivity based on noisy
    correlations, (e) connectivity based on smoothed data, (f) connectivity
    computed using proposed MRF model.}
  \label{fig:1}
\end{figure}


In fig. \ref{fig:1}, direct thresholding of correlation map
(\ref{fig:1c}) or standard Gaussian mixture model (\ref{fig:1d}) does
not use pixels' spatial context information, hence can not give a
spatial coherent connectivity region. By using MRF in prior
distribution, our method in fig. \ref{fig:1e} is able to get a
clustered region while removing other scattered false positive points.

We then test our method on real dataset. (Tom: can you give some
introduction of the data set here...)

-- choose seed volxel: where is it in anatomy definition.

\begin{figure}[htb]
  \centering 
  \subfigure[sub. 1 corr. no smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R1_corr_nosmooth}
    \label{fig:3a}
  }
  \subfigure[sub. 1 corr with smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R1_corr_smooth}
    \label{fig:3b}
  }
  \subfigure[sub. 1 MRF]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R1_mrf}
    \label{fig:3c}
  }
  \subfigure[sub. 2.  corr. no smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R2_corr_nosmooth}
    \label{fig:3d}
  }
  \subfigure[sub. 2 corr with smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R2_corr_smooth}
    \label{fig:3e}
  }
  \subfigure[sub. 2 MRF]{
    \includegraphics[width = 0.3\textwidth]{figures/no_overlay/R2_mrf}
    \label{fig:3f}
  }

  \caption[]{Correlation map and Posterior Connectivity map between seed voxel and slice that contains the seed. First row is subject 1. (a) the correlation map computed from data without spatial smoothing. (b) correlation map of data after smoothing. (c) Posterior probability computed from MRF. Second row is subject 2 with same test.}
  \label{fig:3}
\end{figure}
Fig. \ref{fig:3} is the test results on real data set. Though the posterior map is between every pair of voxels in a slice (we compute connectivity between same slice), for visualization purpose, only the posterior between one voxel and the slice is shown. From the plot, it is clear to see Gaussian smoothing is able to remove noise, but can not find the connectivity between the seed voxels and frontal lobe. the rightmost plot by MRF indicate clearly such connectivity.  To better visualizing the data we also overlay the connectivity map on the T2 structural image and get fig. \ref{fig:2}
 
\begin{figure}[htb]
  \centering 
  \subfigure[sub. 1 thresholding corr. no smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/thresholding_correlationMap/R1_at_gold.png}
    \label{fig:2a}
  }
  \subfigure[sub. 1 thresholding corr with smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/threshold_smthed_corrMap/R1_at_gold.png}
    \label{fig:2b}
  }
  \subfigure[sub. 1 MRF]{
    \includegraphics[width = 0.3\textwidth]{figures/mrf/R1_mrf_at_05.png}
    \label{fig:2c}
  }
  \subfigure[sub. 2.  thresholding corr. no smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/thresholding_correlationMap/R2_at_gold.png}
    \label{fig:2d}
  }
  \subfigure[sub. 2 thresholding corr with smoothing]{
    \includegraphics[width = 0.3\textwidth]{figures/threshold_smthed_corrMap/R2_at_gold.png}
    \label{fig:2e}
  }
  \subfigure[sub. 2 MRF]{
    \includegraphics[width = 0.3\textwidth]{figures/mrf/R2_mrf_at_05}
    \label{fig:2f}
  }

  \caption[]{Thresholded correlation map and Posterior Connectivity map between seed voxel and slice, overlaid to T2 structural image.  First row is subject 1. (a)     }
  \label{fig:2}
\end{figure}


%\section{My Scratch Pad}
%functional and anatomical connectivity to study the network topology.
%
%reference: mean filed  Theory.
%reference: Consistent resting-state networks across healthy
%subjects Mixture Models with Adaptive Spatial
%Regularization....Woolrich 2005.

\bibliographystyle{splncs} 
\bibliography{zotero}
\end{document}
