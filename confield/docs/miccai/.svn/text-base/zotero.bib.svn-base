
@article{jain_data_1999,
	title = {Data clustering: A review},
	volume = {31},
	shorttitle = {Data clustering},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-17644407408&partnerID=40&md5=5de689aafb85bd608ffa501322e1c221},
	abstract = {Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval. © 2000 {ACM.}},
	number = {3},
	journal = {{ACM} Computing Surveys},
	author = {{A.K.} Jain and {M.N.} Murty and {P.J.} Flynn},
	year = {1999},
	keywords = {Cluster Analysis, Clustering applications, Exploratory data analysis, Incremental clustering, Similarity indices, unsupervised learning},
	pages = {316--323}
},

@inproceedings{zhengdong_lu_constrained_2008,
	title = {Constrained spectral clustering through affinity propagation},
	isbn = {1063-6919},
	doi = {10.1109/CVPR.2008.4587451},
	abstract = {Pairwise constraints specify whether or not two samples should be in one cluster. Although it has been successful to incorporate them into traditional clustering methods, such as K-means, little progress has been made in combining them with spectral clustering. The major challenge in designing an effective constrained spectral clustering is a sensible combination of the scarce pairwise constraints with the original affinity matrix. We propose to combine the two sources of affinity by propagating the pairwise constraints information over the original affinity matrix. Our method has a Gaussian process interpretation and results in a closed-form expression for the new affinity matrix. Experiments show it outperforms state-of-the-art constrained clustering methods in getting good clusterings with fewer constraints, and yields good image segmentation with user-specified pairwise constraints.},
	booktitle = {Computer Vision and Pattern Recognition, 2008. {CVPR} 2008. {IEEE} Conference on},
	author = {Zhengdong Lu and {M.A.} {Carreira-Perpinan}},
	year = {2008},
	keywords = {affinity matrix, affinity propagation, constrained spectral clustering, Gaussian processes, image segmentation, matrix algebra, pairwise constraints, pattern clustering, scarce pairwise constraints, user-specified pairwise constraints},
	pages = {1--8}
},

@article{belkin_manifold_2006,
	title = {Manifold regularization: A geometric framework for learning from labeled and unlabeled examples},
	volume = {7},
	shorttitle = {Manifold regularization},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33750729556&partnerID=40},
	abstract = {We propose a family of learning algorithms based on a new form of regularization that allows us to exploit the geometry of the marginal distribution. We focus on a semi-supervised framework that incorporates labeled and unlabeled data in a general-purpose learner. Some transductive graph learning algorithms and standard methods including support vector machines and regularized least squares can be obtained as special cases. We use properties of reproducing kernel Hilbert spaces to prove new Representer theorems that provide theoretical basis for the algorithms. As a result (in contrast to purely graph-based approaches) we obtain a natural out-of-sample extension to novel examples and so are able to handle both transductive and truly semi-supervised settings. We present experimental evidence suggesting that our semi-supervised algorithms are able to use unlabeled data effectively. Finally we have a brief discussion of unsupervised and fully supervised learning within our general framework.},
	journal = {Journal of Machine Learning Research},
	author = {M. Belkin and P. Niyogi and V. Sindhwani},
	year = {2006},
	keywords = {Graph transduction, Kernel methods, Manifold learning, Regularization, Semi-supervised learning, Spectral graph theory, support vector machines, Unlabeled data},
	pages = {2399--2434}
},

@article{solomon_segmentation_2006,
	title = {Segmentation of brain tumors in {4D} {MR} images using the hidden Markov model},
	volume = {84},
	url = {http://portal.acm.org/citation.cfm?id=1219403},
	abstract = {Tumor size is an objective measure that is used to evaluate the effectiveness of anticancer agents. Responses to therapy are categorized as complete response, partial response, stable disease and progressive disease. Implicit in this scheme is the change in the tumor over time; however, most tumor segmentation algorithms do not use temporal information. Here we introduce an automated method using probabilistic reasoning over both space and time to segment brain tumors from {4D} spatio-temporal {MRI} data. The {3D} expectation-maximization method is extended using the hidden Markov model to infer tumor classification based on previous and subsequent segmentation results. Spatial coherence via a Markov Random Field was included in the {3D} spatial model. Simulated images as well as patient images from three independent sources were used to validate this method. The sensitivity and specificity of tumor segmentation using this spatio-temporal model is improved over commonly used spatial or temporal models alone.},
	number = {2-3},
	journal = {Comput. Methods Prog. Biomed.},
	author = {Jeffrey Solomon and John A. Butman and Arun Sood},
	year = {2006},
	keywords = {brain tumor, Expectation-maximization, hidden markov model, Software},
	pages = {76--85}
},

@inproceedings{weinberger_learningkernel_2004,
	title = {Learning a kernel matrix for nonlinear dimensionality reduction},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-14344251006&partnerID=40},
	abstract = {We investigate how to learn a kernel matrix for high dimensional data that lies on or near a low dimensional manifold. Noting that the kernel matrix implicitly maps the data into a nonlinear feature space, we show how to discover a mapping that "unfolds" the underlying manifold from which the data was sampled. The kernel matrix is constructed by maximizing the variance in feature space subject to local constraints that preserve the angles and distances between nearest neighbors. The main optimization involves an instance of semidefinite programming - a fundamentally different computation than previous algorithms for manifold learning, such as Isomap and locally linear embedding. The optimized kernels perform better than polynomial and Gaussian kernels for problems in manifold learning, but worse for problems in large margin classification. We explain these results in terms of the geometric properties of different kernels and comment on various interpretations of other manifold learning algorithms as kernel methods.},
	booktitle = {Proceedings, {Twenty-First} International Conference on Machine Learning, {ICML} 2004},
	author = {{K.Q.} Weinberger and F. Sha and {L.K.} Saul},
	year = {2004},
	pages = {839--846}
},

@article{lanckriet_learningkernel_2004,
	title = {Learning the Kernel Matrix with Semidefinite Programming},
	volume = {5},
	url = {http://portal.acm.org/citation.cfm?id=1005332.1005334},
	abstract = {Kernel-based learning algorithms work by embedding the data into a Euclidean space, and then searching for linear relations among the embedded data points. The embedding is performed implicitly, by specifying the inner products between each pair of points in the embedding space. This information is contained in the so-called kernel matrix, a symmetric and positive semidefinite matrix that encodes the relative positions of all points. Specifying this matrix amounts to specifying the geometry of the embedding space and inducing a notion of similarity in the input space---classical model selection problems in machine learning. In this paper we show how the kernel matrix can be learned from data via semidefinite programming {(SDP)} techniques. When applied to a kernel matrix associated with both training and test data this gives a powerful transductive algorithm---using the labeled part of the data one can learn an embedding also for the unlabeled part. The similarity between test points is inferred from training points and their labels. Importantly, these learning problems are convex, so we obtain a method for learning both the model class and the function without local minima. Furthermore, this approach leads directly to a convex method for learning the 2-norm soft margin parameter in support vector machines, solving an important open problem.},
	journal = {J. Mach. Learn. Res.},
	author = {Gert R. G. Lanckriet and Nello Cristianini and Peter Bartlett and Laurent El Ghaoui and Michael I. Jordan},
	year = {2004},
	pages = {27--72}
},

@article{bottou_convergence_1995,
	title = {Convergence Properties of the {K-Means} Algorithms},
	volume = {7},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.3258},
	journal = {{ADVANCES} {IN} {NEURAL} {INFORMATION} {PROCESSING} {SYSTEMS} 7},
	author = {Léon Bottou and Yoshua Bengio},
	year = {1995},
	pages = {585---592}
},

@article{mallapragada_semiboost:_2009,
	title = {{SemiBoost:} Boosting for semi-supervised learning},
	volume = {31},
	shorttitle = {{SemiBoost}},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70349871686&partnerID=40},
	abstract = {Semi-supervised learning has attracted a significant amount of attention in pattern recognition and machine learning. Most previous studies have focused on designing special algorithms to effectively exploit the unlabeled data in conjunction with labeled data. Our goal is to improve the classification accuracy of any given supervised learning algorithm by using the available unlabeled examples. We call this as the Semi-supervised improvement problem, to distinguish the proposed approach from the existing approaches. We design a metasemi-supervised learning algorithm that wraps around the underlying supervised algorithm and improves its performance using unlabeled data. This problem is particularly important when we need to train a supervised learning algorithm with a limited number of labeled examples and a multitude of unlabeled examples. We present a boosting framework for semi-supervised learning, termed as {SemiBoost.} The key advantages of the proposed semi-supervised learning approach are: 1) performance improvement of any supervised learning algorithm with a multitude of unlabeled data, 2) efficient computation by the iterative boosting algorithm, and 3) exploiting both manifold and cluster assumption in training classification models. An empirical study on 16 different data sets and text categorization demonstrates that the proposed framework improves the performance of several commonly used supervised learning algorithms, given a large number of unlabeled examples. We also show that the performance of the proposed algorithm, {SemiBoost,} is comparable to the state-of-the-art semi-supervised learning algorithms. © 2009 {IEEE.}},
	number = {11},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {{P.K.} Mallapragada and R. Jin and {A.K.} Jain and Y. Liu},
	year = {2009},
	keywords = {Boosting, Cluster assumption, Machine learning, Manifold assumption, Semi-supervised improvement, Semi-supervised learning},
	pages = {2000--2014}
},

@article{karypis_chameleon:_1999,
	title = {Chameleon: hierarchical clustering using dynamic modeling},
	volume = {32},
	issn = {0018-9162},
	shorttitle = {Chameleon},
	doi = {10.1109/2.781637},
	abstract = {Clustering is a discovery process in data mining. It groups a set
of data in a way that maximizes the similarity within clusters and
minimizes the similarity between two different clusters. Many advanced
algorithms have difficulty dealing with highly variable clusters that do
not follow a preconceived model. By basing its selections on both
interconnectivity and closeness, the Chameleon algorithm yields accurate
results for these highly variable clusters. Existing algorithms use a
static model of the clusters and do not use information about the nature
of individual clusters as they are merged. Furthermore, one set of
schemes (the {CURE} algorithm and related schemes) ignores the information
about the aggregate interconnectivity of items in two clusters. Another
set of schemes (the Rock algorithm, group averaging method, and related
schemes) ignores information about the closeness of two clusters as
defined by the similarity of the closest items across two clusters. By
considering either interconnectivity or closeness only, these algorithms
can select and merge the wrong pair of clusters. Chameleon's key feature
is that it accounts for both interconnectivity and closeness in
identifying the most similar pair of clusters. Chameleon finds the
clusters in the data set by using a two-phase algorithm. During the
first phase, Chameleon uses a graph partitioning algorithm to cluster
the data items into several relatively small subclusters. During the
second phase, it uses an algorithm to find the genuine clusters by
repeatedly combining these subclusters},
	number = {8},
	journal = {Computer},
	author = {G. Karypis and {Eui-Hong} Han and V. Kumar},
	year = {1999},
	keywords = {advanced algorithms, aggregate interconnectivity, Chameleon algorithm, closeness, closest items, {CURE} algorithm, data analysis, data item clustering, data mining, data set, discovery process, dynamic modeling, graph partitioning algorithm, Graph theory, hierarchical clustering, highly variable clusters, most similar pair, pattern clustering, Rock algorithm, subclusters, two-phase algorithm},
	pages = {68--75}
},

@article{watts_collective_1998,
	title = {Collective dynamics of ‘small-world’networks},
	volume = {393},
	number = {6684},
	journal = {Nature},
	author = {D. J Watts and S. H Strogatz},
	year = {1998},
	pages = {440–442}
},

@inproceedings{zhuowen_tu_probabilistic_2005,
	title = {Probabilistic boosting-tree: learning discriminative models for classification, recognition, and clustering},
	volume = {2},
	isbn = {1550-5499},
	shorttitle = {Probabilistic boosting-tree},
	doi = {10.1109/ICCV.2005.194},
	abstract = {In this paper, a new learning framework - probabilistic boosting-tree {(PBT),} is proposed for learning two-class and multi-class discriminative models. In the learning stage, the probabilistic boosting-tree automatically constructs a tree in which each node combines a number of weak classifiers (evidence, knowledge,) into a strong classifier (a conditional posterior probability). It approaches the target posterior distribution by data augmentation (tree expansion) through a divide-and-conquer strategy. In the testing stage, the conditional probability is computed at each tree node based on the learned classifier, which guides the probability propagation in its sub-trees. The top node of the tree therefore outputs the overall posterior probability by integrating the probabilities gathered from its sub-trees. Also, clustering is naturally embedded in the learning phase and each sub-tree represents a cluster of certain level. The proposed framework is very general and it has interesting connections to a number of existing methods such as the A* algorithm, decision tree algorithms, generative models, and cascade approaches. In this paper, we show the applications of {PBT} for classification, detection, and object recognition. We have also applied the framework in segmentation},
	booktitle = {Computer Vision, 2005. {ICCV} 2005. Tenth {IEEE} International Conference on},
	author = {Zhuowen Tu},
	year = {2005},
	keywords = {conditional probability, data augmentation, divide and conquer methods, divide-and-conquer strategy, image classification, image segmentation, learning (artificial intelligence), multi-class discriminative models, object detection, object recognition, pattern clustering, probabilistic boosting-tree, probability, probability propagation, tree expansion, trees (mathematics), two-class discriminative models},
	pages = {1589--1596 Vol. 2}
},

@article{sonnenburg_large_2006,
	title = {Large Scale Multiple Kernel Learning},
	volume = {7},
	url = {http://portal.acm.org/citation.cfm?id=1248547.1248604},
	abstract = {While classical kernel-based learning algorithms are based on a single kernel, in practice it is often desirable to use multiple kernels. Lanckriet et al. (2004) considered conic combinations of kernel matrices for classification, leading to a convex quadratically constrained quadratic program. We show that it can be rewritten as a semi-infinite linear program that can be efficiently solved by recycling the standard {SVM} implementations. Moreover, we generalize the formulation and our method to a larger class of problems, including regression and one-class classification. Experimental results show that the proposed algorithm works for hundred thousands of examples or hundreds of kernels to be combined, and helps for automatic model selection, improving the interpretability of the learning result. In a second part we discuss general speed up mechanism for {SVMs,} especially when used with sparse feature maps as appear for string kernels, allowing us to train a string kernel {SVM} on a 10 million real-world splice data set from computational biology. We integrated multiple kernel learning in our machine learning toolbox {{\textless}tt{\textgreater}SHOGUN{\textless}/tt{\textgreater}} for which the source code is publicly available at {\textless}tt{\textgreater}http://www.fml.tuebingen.mpg.de/raetsch/projects/shogun{\textless}/tt{\textgreater}.},
	journal = {J. Mach. Learn. Res.},
	author = {Sören Sonnenburg and Gunnar Rätsch and Christin Schäfer and Bernhard Schölkopf},
	year = {2006},
	pages = {1531--1565}
},

@article{yan_parallelizing_2007,
	title = {Parallelizing {MCMC} for Bayesian spatiotemporal geostatistical models},
	volume = {17},
	url = {http://dx.doi.org/10.1007/s11222-007-9022-2},
	doi = {10.1007/s11222-007-9022-2},
	abstract = {Abstract  
When {MCMC} methods for Bayesian spatiotemporal modeling are applied to large geostatistical problems, challenges arise as a
consequence of memory requirements, computing costs, and convergence monitoring. This article describes the parallelization
of a reparametrized and marginalized posterior sampling {(RAMPS)} algorithm, which is carefully designed to generate posterior
samples efficiently. The algorithm is implemented using the Parallel Linear Algebra Package {(PLAPACK).} The scalability of
the algorithm is investigated via simulation experiments that are implemented using a cluster with 25 processors. The usefulness
of the method is illustrated with an application to sulfur dioxide concentration data from the Air Quality System database
of the {U.S.} Environmental Protection Agency.},
	number = {4},
	journal = {Statistics and Computing},
	author = {Jun Yan and Mary Cowles and Shaowen Wang and Marc Armstrong},
	month = dec,
	year = {2007},
	pages = {323--335}
},

@article{van_den_heuvel_normalized_2008,
	title = {Normalized Cut Group Clustering of {Resting-State} {fMRI} Data},
	volume = {3},
	url = {http://dx.plos.org/10.1371/journal.pone.0002001},
	doi = {10.1371/journal.pone.0002001},
	abstract = {Functional brain imaging studies have indicated that distinct anatomical brain regions can show coherent spontaneous neuronal activity during rest. Regions that show such correlated behavior are said to form resting-state networks {(RSNs).} {RSNs} have been investigated using seed-dependent functional connectivity maps and by using a number of model-free methods. However, examining {RSNs} across a group of subjects is still a complex task and often involves human input in selecting meaningful networks.

We report on a voxel based model-free normalized cut graph clustering approach with whole brain coverage for group analysis of resting-state data, in which the number of {RSNs} is computed as an optimal clustering fit of the data. Inter-voxel correlations of time-series are grouped at the individual level and the consistency of the resulting networks across subjects is clustered at the group level, defining the group {RSNs.} We scanned a group of 26 subjects at rest with a fast {BOLD} sensitive {fMRI} scanning protocol on a 3 Tesla {MR} scanner.

An optimal group clustering fit revealed 7 {RSNs.} The 7 {RSNs} included motor/visual, auditory and attention networks and the frequently reported default mode network. The found {RSNs} showed large overlap with recently reported resting-state results and support the idea of the formation of spatially distinct {RSNs} during rest in the human brain.},
	number = {4},
	journal = {{PLoS} {ONE}},
	author = {Martijn van den Heuvel and Rene Mandl and Hilleke Hulshoff Pol},
	month = apr,
	year = {2008},
	keywords = {{TODO}},
	pages = {e2001}
},

@article{xia_defining_2009,
	title = {On defining affinity graph for spectral clustering through ranking on manifolds},
	volume = {72},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/B6V10-4W1JVYV-4/2/0c7ef67a82993940f4639a35962fb0c4},
	doi = {10.1016/j.neucom.2009.03.012},
	abstract = {Spectral clustering consists of two distinct stages: (a) construct an affinity graph from the dataset and (b) cluster the data points through finding an optimal partition of the affinity graph. The focus of the paper is the first step. Existing spectral clustering algorithms adopt Gaussian function to define the affinity graph since it is easy to implement. However, Gaussian function is hard to depict the intrinsic structure of the data, and it has to specify a scaling parameter whose selection is still an open issue in spectral clustering. Therefore, we propose a new definition of affinity graph for spectral clustering from the graph partition perspective. In particular, we propose two consistencies: smooth consistency and constraint consistency, for affinity graph to hold, and then define the affinity graph respecting these consistencies in a regularization framework of ranking on manifolds. Meanwhile the proposed definition of affinity graph is applicable to both unsupervised and semi-supervised spectral clustering. Encouraging experimental results on synthetic and real world data demonstrate the effectiveness of the proposed approach.},
	number = {13-15},
	journal = {Neurocomputing},
	author = {Tian Xia and Juan Cao and Yong-dong Zhang and Jin-tao Li},
	month = aug,
	year = {2009},
	keywords = {Affinity graph, Ranking on manifolds, Spectral clustering},
	pages = {3203--3211}
},

@inproceedings{lafferty_conditional_2001,
	title = {Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
	shorttitle = {Conditional random fields},
	booktitle = {{MACHINE} {LEARNING-INTERNATIONAL} {WORKSHOP} {THEN} {CONFERENCE-}},
	author = {J. Lafferty and A. {McCallum} and F. Pereira},
	year = {2001},
	pages = {282–289}
},

@article{woolrich_mixture_2005,
	title = {Mixture models with adaptive spatial regularization for segmentation with an application to {FMRI} data},
	volume = {24},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-11844293467&partnerID=40},
	abstract = {Mixture models are often used in the statistical segmentation of medical images. For example, they can be used for the segmentation of structural images into different matter types or of functional statistical parametric maps {(SPMs)} into activations and nonactivations. Nonspatial mixture models segment using models of just the histogram of intensity values. Spatial mixture models have also been developed which augment this histogram information with spatial regularization using Markov random fields. However, these techniques have control parameters, such as the strength of spatial regularization, which need to be tuned heuristically to particular datasets. We present a novel spatial mixture model within a fully Bayesian framework with the ability to perform fully adaptive spatial regularization using Markov random fields. This means that the amount of spatial regularization does not have to be tuned heuristically but is adaptively determined from the data. We examine the behavior of this model when applied to artificial data with different spatial characteristics, and to functional magnetic resonance imaging {SPMs.}},
	number = {1},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {{M.W.} Woolrich and {T.E.J.} Behrens and {C.F.} Beckmann and {S.M.} Smith},
	year = {2005},
	keywords = {Adaptive, {FMRI,} {MRF,} Segmentation, Spatial mixture models},
	pages = {1--11}
},

@inproceedings{davis_information-theoretic_2007,
	title = {Information-theoretic metric learning},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-36048971647&partnerID=40},
	abstract = {In this paper, we present an information-theoretic approach to learning a Mahalanobis distance function. We formulate the problem as that of minimizing the differential relative entropy between two multivariate Gaussians under constraints on the distance function. We express this problem as a particular Bregman optimization problem-that of minimizing the {LogDet} divergence subject to linear constraints. Our resulting algorithm has several advantages over existing methods. First, our method can handle a wide variety of constraints and can optionally incorporate a prior on the distance function. Second, it is fast and scalable. Unlike most existing methods, no eigenvalue computations or semi-definite programming are required. We also present an online version and derive regret bounds for the resulting algorithm. Finally, we evaluate our method on a recent error reporting system for software called Clarify, in the context of metric learning for nearest neighbor classification, as well as on standard data sets.},
	booktitle = {{ICML} 2007 - Proceedings of the 24th International Conference on Machine Learning},
	author = {{J.V.} Davis and B. Kulis and P. Jain and S. Sra and {I.S.} Dhillon},
	year = {2007},
	pages = {209--216}
},

@misc{__????,
	url = {https://engineering.purdue.edu/~bouman/software/cluster/cluster.bib},
	howpublished = {https://engineering.purdue.edu/{\textasciitilde}bouman/software/cluster/cluster.bib}
},

@article{fraley_model-based_2002,
	title = {{Model-Based} Clustering, Discriminant Analysis, and Density Estimation.},
	volume = {97},
	number = {458},
	journal = {Journal of the American Statistical Association},
	author = {C. Fraley and A. E Raftery},
	year = {2002},
	pages = {611–632}
},

@article{kulis_semi-supervised_2009,
	title = {Semi-supervised graph clustering: a kernel approach},
	volume = {74},
	shorttitle = {Semi-supervised graph clustering},
	url = {http://dx.doi.org/10.1007/s10994-008-5084-4},
	doi = {10.1007/s10994-008-5084-4},
	abstract = {Abstract  Semi-supervised clustering algorithms aim to improve clustering results using limited supervision. The supervision is generally
given as pairwise constraints; such constraints are natural for graphs, yet most semi-supervised clustering algorithms are
designed for data represented as vectors. In this paper, we unify vector-based and graph-based approaches. We first show that
a recently-proposed objective function for semi-supervised clustering based on Hidden Markov Random Fields, with squared Euclidean
distance and a certain class of constraint penalty functions, can be expressed as a special case of the weighted kernel k-means objective {(Dhillon} et al., in Proceedings of the 10th International Conference on Knowledge Discovery and Data Mining,
2004a). A recent theoretical connection between weighted kernel k-means and several graph clustering objectives enables us to perform semi-supervised clustering of data given either as vectors
or as a graph. For graph data, this result leads to algorithms for optimizing several new semi-supervised graph clustering
objectives. For vector data, the kernel approach also enables us to find clusters with non-linear boundaries in the input
data space. Furthermore, we show that recent work on spectral learning {(Kamvar} et al., in Proceedings of the 17th International
Joint Conference on Artificial Intelligence, 2003) may be viewed as a special case of our formulation. We empirically show that our algorithm is able to outperform current
state-of-the-art semi-supervised algorithms on both vector-based and graph-based data sets.},
	number = {1},
	journal = {Machine Learning},
	author = {Brian Kulis and Sugato Basu and Inderjit Dhillon and Raymond Mooney},
	year = {2009},
	pages = {1--22}
},

@inproceedings{ham_kernel_2004,
	address = {Banff, Alberta, Canada},
	title = {A kernel view of the dimensionality reduction of manifolds},
	isbn = {1-58113-828-5},
	url = {http://portal.acm.org/citation.cfm?id=1015417},
	doi = {10.1145/1015330.1015417},
	abstract = {We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods. Isomap, graph Laplacian eigenmap, and locally linear embedding {(LLE)} all utilize local neighborhood information to construct a global embedding of the manifold. We show how all three algorithms can be described as kernel {PCA} on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples.},
	booktitle = {Proceedings of the twenty-first international conference on Machine learning},
	publisher = {{ACM}},
	author = {Jihun Ham and Daniel D. Lee and Sebastian Mika and Bernhard Schölkopf},
	year = {2004},
	pages = {47}
},

@article{damoiseaux_consistent_2006,
	title = {Consistent resting-state networks across healthy subjects},
	volume = {103},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33748796093&partnerID=40},
	abstract = {Functional {MRI} {(fMRI)} can be applied to study the functional connectivity of the human brain. It has been suggested that fluctuations in the blood oxygenation level-dependent {(BOLD)} signal during rest reflect the neuronal baseline activity of the brain, representing the state of the human brain in the absence of goal-directed neuronal action and external input, and that these slow fluctuations correspond to functionally relevant resting-state networks. Several studies on resting {fMRI} have been conducted, reporting an apparent similarity between the identified patterns. The spatial consistency of these resting patterns, however, has not yet been evaluated and quantified. In this study, we apply a data analysis approach called tensor probabilistic independent component analysis to resting-state {fMRI} data to find coherencies that are consistent across subjects and sessions. We characterize and quantify the consistency of these effects by using a bootstrapping approach, and we estimate the {BOLD} amplitude modulation as well as the voxel-wise cross-subject variation. The analysis found 10 patterns with potential functional relevance, consisting of regions known to be involved in motor function, visual processing, executive functioning, auditory processing, memory, and the so-called default-mode network, each with {BOLD} signal changes up to 3\%. In general, areas with a high mean percentage {BOLD} signal are consistent and show the least variation around the mean. These findings show that the baseline activity of the brain is consistent across subjects exhibiting significant temporal dynamics, with percentage {BOLD} signal change comparable with the signal changes found in task-related experiments. © 2006 by The National Academy of Sciences of the {USA.}},
	number = {37},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {{J.S.} Damoiseaux and {S.A.R.B.} Rombouts and F. Barkhof and P. Scheltens and {C.J.} Stam and {S.M.} Smith and {C.F.} Beckmann},
	year = {2006},
	keywords = {Functional connectivity, functional {MRI,} Resting fluctuations},
	pages = {13848--13853}
},

@article{yan_parallelizing_2007-1,
	title = {Parallelizing {MCMC} for Bayesian spatiotemporal geostatistical models},
	volume = {17},
	url = {http://dx.doi.org/10.1007/s11222-007-9022-2},
	doi = {10.1007/s11222-007-9022-2},
	abstract = {Abstract  
When {MCMC} methods for Bayesian spatiotemporal modeling are applied to large geostatistical problems, challenges arise as a
consequence of memory requirements, computing costs, and convergence monitoring. This article describes the parallelization
of a reparametrized and marginalized posterior sampling {(RAMPS)} algorithm, which is carefully designed to generate posterior
samples efficiently. The algorithm is implemented using the Parallel Linear Algebra Package {(PLAPACK).} The scalability of
the algorithm is investigated via simulation experiments that are implemented using a cluster with 25 processors. The usefulness
of the method is illustrated with an application to sulfur dioxide concentration data from the Air Quality System database
of the {U.S.} Environmental Protection Agency.},
	number = {4},
	journal = {Statistics and Computing},
	author = {Jun Yan and Mary Cowles and Shaowen Wang and Marc Armstrong},
	month = dec,
	year = {2007},
	pages = {323--335}
},

@article{mller_multivariate_2001,
	title = {On Multivariate Spectral Analysis of {fMRI} Time Series},
	volume = {14},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-457VFJT-19/2/495421aedd5d6d64a3777408b65ecb46},
	doi = {10.1006/nimg.2001.0804},
	abstract = {Most of functional magnetic resonance imaging {(fMRI)} time series analysis is based on single voxel data evaluation using parametric statistical tests. The result of such an analysis is a statistical parametric map. Voxels with a high significance value in the parametric test are interpreted as activation regions stimulated by the experimental task. However, for the investigation of functional connectivities it would be interesting to get some detailed information about the temporal dynamics of the blood oxygen level-dependent {(BOLD)} signal. For investigating that behavior, a method for {fMRI} data analysis has been developed that is based on Wiener theory of spectral analysis for multivariate time series. Spectral parameters such as coherence measure and phase lead can be estimated. The resulting maps give detailed information on brain regions that belong to a network structure and also show the temporal behavior of the {BOLD} response function. This paper describes the method and presents a visual {fMRI} experiment as an example to demonstrate the results.},
	number = {2},
	journal = {{NeuroImage}},
	author = {Karsten M\"{u}ller and Gabriele Lohmann and Volker Bosch and D. Yves von Cramon},
	month = aug,
	year = {2001},
	keywords = {{fMRI;} functional connectivities; spectral analysis; coherence; phase lead},
	pages = {347--356}
},

@article{logothetis_interpretingbold_2004,
	title = {Interpreting the {BOLD} signal},
	volume = {66},
	issn = {0066-4278},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/14977420},
	doi = {10.1146/annurev.physiol.66.082602.092845},
	abstract = {The development of functional magnetic resonance imaging {(fMRI)} has brought together a broad community of scientists interested in measuring the neural basis of the human mind. Because {fMRI} signals are an indirect measure of neural activity, interpreting these signals to make deductions about the nervous system requires some understanding of the signaling mechanisms. We describe our current understanding of the causal relationships between neural activity and the blood-oxygen-level-dependent {(BOLD)} signal, and we review how these analyses have challenged some basic assumptions that have guided neuroscience. We conclude with a discussion of how to use the {BOLD} signal to make inferences about the neural signal.},
	journal = {Annual Review of Physiology},
	author = {Nikos K Logothetis and Brian A Wandell},
	year = {2004},
	note = {{PMID:} 14977420},
	keywords = {Animals, Brain, Brain Mapping, Cerebrovascular Circulation, Electrophysiology, Humans, Magnetic Resonance Imaging, Models, Neurological, Oxygen},
	pages = {735--769}
},

@article{hardoon_canonical_2004,
	title = {Canonical Correlation Analysis: An Overview with Application to Learning Methods},
	volume = {16},
	shorttitle = {Canonical Correlation Analysis},
	url = {http://dx.doi.org/10.1162/0899766042321814},
	doi = {10.1162/0899766042321814},
	abstract = {We present a general method using kernel canonical correlation analysis to learn a semantic representation to web images and their associated text. The semantic space provides a common representation and enables a comparison between the text and images. In the experiments, we look at two approaches of retrieving images based on only their content from a text query. We compare orthogonalization approaches against a standard cross-representation retrieval technique known as the generalized vector space model.},
	number = {12},
	journal = {Neural Computation},
	author = {David R. Hardoon and Sandor Szedmak and John {Shawe-Taylor}},
	month = dec,
	year = {2004},
	pages = {2639--2664}
},

@book{basu_constrained_2008,
	title = {Constrained clustering},
	isbn = {1584889969, 9781584889960},
	publisher = {{CRC} Press},
	author = {Sugato Basu and Ian Davidson and Kiri Lou Wagstaff},
	month = aug,
	year = {2008}
},

@article{huafu_chen_integrated_2006,
	title = {An integrated neighborhood correlation and hierarchical clustering approach of functional {MRI}},
	volume = {53},
	issn = {0018-9294},
	abstract = {Clustering analysis is a promising data-driven method for the analysis of functional magnetic resonance imaging {(fMRI)} time series, however, the huge computation load makes it difficult for practical use. In this paper, neighborhood correlation {(NC)} and hierarchical clustering {(HC)} methods are integrated as a new approach where {fMRI} data are processed first by {NC} to get a preliminary image of brain activations, and then by {HC} to remove some noises. In {HC,} to better use spatial and temporal information in {fMRI} data, a new spatio-temporal measure is introduced. A simulation study and an application to visual {fMRI} data show that the brain activations can be effectively detected and that different response patterns can be discriminated. These results suggest that the proposed new integrated approach could be useful in detecting weak {fMRI} signals.},
	number = {3},
	journal = {Biomedical Engineering, {IEEE} Transactions on},
	author = {Huafu Chen and Hong Yuan and Dezhong Yao and Lin Chen and Wufan Chen},
	year = {2006},
	keywords = {biomedical {MRI,} Brain, brain activations, {FMRI,} functional magnetic resonance imaging, functional {MRI,} hierarchical clustering, hierarchical clustering analysis, integrated neighborhood correlation, medical image processing, neighborhood correlation, noise removal, spatio-temporal measure, spatiotemporal measure, spatiotemporal phenomena, statistical analysis, time series},
	pages = {452--458}
},

@article{lawrence_probabilistic_2005,
	title = {Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models},
	volume = {6},
	url = {http://portal.acm.org/citation.cfm?id=1046920.1194904},
	abstract = {Summarising a high dimensional data set with a low dimensional embedding is a standard approach for exploring its structure. In this paper we provide an overview of some existing techniques for discovering such embeddings. We then introduce a novel probabilistic interpretation of principal component analysis {(PCA)} that we term dual probabilistic {PCA} {(DPPCA).} The {DPPCA} model has the additional advantage that the linear mappings from the embedded space can easily be non-linearised through Gaussian processes. We refer to this model as a Gaussian process latent variable model {(GP-LVM).} Through analysis of the {GP-LVM} objective function, we relate the model to popular spectral techniques such as kernel {PCA} and multidimensional scaling. We then review a practical algorithm for {GP-LVMs} in the context of large data sets and develop it to also handle discrete valued data and missing attributes. We demonstrate the model on a range of real-world and artificially generated data sets.},
	journal = {J. Mach. Learn. Res.},
	author = {Neil Lawrence},
	year = {2005},
	pages = {1783--1816}
},

@book{schlkopf_advances_2007,
	title = {Advances in Neural Information Processing Systems 19},
	isbn = {0262195682, 9780262195683},
	publisher = {{MIT} Press},
	author = {Bernhard Schölkopf and John Platt and Thomas Hofmann},
	year = {2007}
},

@article{weinberger_unsupervised_2006,
	title = {Unsupervised learning of image manifolds by semidefinite programming},
	volume = {70},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33744949513&partnerID=40},
	abstract = {Can we detect low dimensional structure in high dimensional data sets of images? In this paper we propose an algorithm for unsupervised learning of image manifolds by semidefinite programming. Given a data set of images our algorithm computes a low dimensional representation of each image with the property that distances between nearby images are preserved. More generally it can be used to analyze high dimensional data that lies on or near a low dimensional manifold. We illustrate the algorithm on easily visualized examples of curves and surfaces as well as on actual images of faces handwritten digits and solid objects. © 2006 Springer Science + Business Media, {LLC.}},
	number = {1},
	journal = {International Journal of Computer Vision},
	author = {{K.Q.} Weinberger and {L.K.} Saul},
	year = {2006},
	keywords = {data analysis, Dimensionality reduction, Image manifolds, Kernel methods, Manifold learning, Semidefinite embedding, Semidefinite programming},
	pages = {77--90}
},

@article{filippone_survey_2008,
	title = {A survey of kernel and spectral methods for clustering},
	volume = {41},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/B6V14-4P0X57W-1/2/809fa9ac4bc248c9bb73f83a1eee266a},
	doi = {10.1016/j.patcog.2007.05.018},
	abstract = {Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, {SOM} and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.},
	number = {1},
	journal = {Pattern Recognition},
	author = {Maurizio Filippone and Francesco Camastra and Francesco Masulli and Stefano Rovetta},
	year = {2008},
	keywords = {Kernel clustering, Kernel fuzzy clustering, Mercer kernels, Partitional clustering, Spectral clustering},
	pages = {176--190}
},

@article{zhang_segmentation_2001,
	title = {Segmentation of brain {MR} images through a hidden Markov random field model and the expectation-maximization algorithm},
	volume = {20},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0034745001&partnerID=40},
	abstract = {The finite mixture {(FM)} model is the most commonly used model for statistical segmentation of brain magnetic resonance {(MR)} images because of its simple mathematical form and the piecewise constant nature of ideal brain {MR} images. However, being a histogram-based model, the {FM} has an intrinsic limitation-no spatial information is taken into account. This causes the {FM} model to work only on well-defined images with low levels of noise; unfortunately, this is often not the case due to artifacts such as partial volume effect and bias field distortion. Under these conditions, {FM} model-based methods produce unreliable results. In this paper, we propose a novel hidden Markov random field {(HMRF)} model, which is a stochastic process generated by a {MRF} whose state sequence cannot be observed directly but which can be indirectly estimated through observations. Mathematically, it can be shown that the {FM} model is a degenerate version of the {HMRF} model. The advantage of the {HMRF} model derives from the way in which the spatial information is encoded through the mutual influences of neighboring sites. Although {MRF} modeling has been employed in {MR} image segmentation by other researchers, most reported methods are limited to using {MRF} as a general prior in an {FM} model-based approach. To fit the {HMRF} model, an {EM} algorithm is used. We show that by incorporating both the {HMRF} model and the {EM} algorithm into a {HMRF-EM} framework, an accurate and robust segmentation can be achieved. More importantly, the {HMRF-EM} framework can easily be combined with other techniques. As an example, we show how the bias field correction algorithm of Guillemaud and Brady (1997) can be incorporated into this framework to achieve a three-dimensional fully automated approach for brain {MR} image segmentation.},
	number = {1},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {Y. Zhang and M. Brady and S. Smith},
	year = {2001},
	keywords = {Bias field correction, Expectation-maximization, Hidden Markov random field, {MRI,} Segmentation},
	pages = {45--57}
},

@article{singer_detecting_2009,
	title = {Detecting intrinsic slow variables in stochastic dynamical systems by anisotropic diffusion maps},
	volume = {106},
	url = {http://www.pnas.org/content/106/38/16090.abstract},
	doi = {10.1073/pnas.0905547106},
	abstract = {Nonlinear independent component analysis is combined with diffusion-map data analysis techniques to detect good observables in high-dimensional dynamic data. These detections are achieved by integrating local principal component analysis of simulation bursts by using eigenvectors of a Markov matrix describing anisotropic diffusion. The widely applicable procedure, a crucial step in model reduction approaches, is illustrated on stochastic chemical reaction network simulations.},
	number = {38},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Amit Singer and Radek Erban and Ioannis G. Kevrekidis and Ronald R. Coifman},
	year = {2009},
	pages = {16090--16095}
},

@article{mitra_analysis_1999,
	title = {Analysis of dynamic brain imaging data},
	volume = {76},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0032988822&partnerID=40},
	abstract = {Modern imaging techniques for probing brain function, including functional magnetic resonance imaging, intrinsic and extrinsic contrast optical imaging, and magnetoencephalography, generate large data sets with complex content. In this paper we develop appropriate techniques for analysis and visualization of such imaging data to separate the signal from the noise and characterize the signal. The techniques developed fall into the general category of multivariate time series analysis, and in particular we extensively use the multitaper framework of spectral analysis. We develop specific protocols for the analysis of {fMRI,} optical imaging, and {MEG} data, and illustrate the techniques by applications to real data sets generated by these imaging modalities. In general, the analysis protocols involve two distinct stages: 'noise' characterization and suppression, and 'signal' characterization and visualization. An important general conclusion of our study is the utility of a frequency-based representation, with short, moving analysis windows to account for nonstationarity in the data. Of particular note are 1) the development of a decomposition technique (space-frequency singular value decomposition) that is shown to be a useful means of characterizing the image data, and 2) the development of an algorithm, based on multitaper methods, for the removal of approximately periodic physiological artifacts arising from cardiac and respiratory sources.},
	number = {2},
	journal = {Biophysical Journal},
	author = {{P.P.} Mitra and B. Pesaran},
	year = {1999},
	pages = {691--708}
},

@article{della_pietra_inducing_1995,
	title = {Inducing features of random fields},
	journal = {Arxiv preprint cmp-lg/9506014},
	author = {S. Della Pietra and V. Della Pietra and J. Lafferty},
	year = {1995}
},

@article{haaland_partial_1988,
	title = {Partial least-squares methods for spectral analyses. 1. Relation to other quantitative calibration methods and the extraction of qualitative information},
	volume = {60},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0024034712&partnerID=40},
	abstract = {Partial least-squares {(PLS)} methods for spectral analyses are related to other multivariate calibration methods such as classical least-squares {(CLS),} inverse least-squares {(ILS),} and principal component regression {(PCR)} methods which have been used often in quantitative spectral analyses. The {PLS} method which analyzes one chemical component at a time is presented, and the basis for each step in the algorithm is explained. {PLS} calibration is shown to be composed of a series of simplified {CLS} and {ILS} steps. This detailed understanding of the {PLS} algorithm has helped to identify how chemically interpretable qualitative spectral information can be obtained from the intermediate steps of the {PLS} algorithm. These methods for extracting qualitative information are demonstrated by use of simulated spectral data. The qualitative information directly available from the {PLS} analysis is superior to that obtained from {PCR} but is not as complete as that which can be generated during {CLS} analyses. Methods are presented for selecting optimal numbers of loading vectors for both the {PLS} and {PCR} models in order to optimize the model while simultaneously reducing the potential for over-fitting the calibration data. Outlier detection and methods to evaluate the statistical significance of results obtained from the different calibration methods applied to the same spectral data are also discussed. © 1988 American Chemical Society.},
	number = {11},
	journal = {Analytical Chemistry},
	author = {{D.M.} Haaland and {E.V.} Thomas},
	year = {1988},
	pages = {1193--1202}
},

@article{kolmogorov_what_2004,
	title = {What Energy Functions Can Be Minimized via Graph Cuts?},
	volume = {26},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0742286180&partnerID=40},
	abstract = {In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.},
	number = {2},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {V. Kolmogorov and R. Zabih},
	year = {2004},
	keywords = {Energy minimization, Graph algorithms, Markov random fields, Maximum flow, Minimum cut, Optimization},
	pages = {147--159}
},

@inproceedings{xiaozhe_wang_pattern_2008,
	title = {Pattern discovery in motion time series via structure-based spectral clustering},
	isbn = {1063-6919},
	doi = {10.1109/CVPR.2008.4587385},
	abstract = {This paper proposes an approach called dasiastructure-based spectral clusteringpsila to identify clusters in motion time series for sequential pattern discovery. The proposed approach deploys a dasiastatistical feature-based distance computationpsila for spectral clustering algorithm. Compared to traditional spectral clustering approaches, in which the similarity matrix is constructed from the original data points by applying some similarity functions, the proposed approach builds the matrix based on a finite set of feature vectors. When the proposed approach uses less data points and simpler similarity function to computing the similarity matrix input for spectral clustering, it can improve the computational efficiency in constructing the similarity graph in spectral clustering compared to conventional approach. Promising experimental results with high accuracy on real world data sets demonstrate the capability and effectiveness of the proposed approach for pattern discovery in motion video sequences.},
	booktitle = {Computer Vision and Pattern Recognition, 2008. {CVPR} 2008. {IEEE} Conference on},
	author = {Xiaozhe Wang and Liang Wang and A. Wirth},
	year = {2008},
	keywords = {Graph theory, image motion analysis, image sequences, matrix algebra, motion time series, motion video sequences, pattern clustering, pattern discovery, similarity function, similarity graph, similarity matrix, statistical feature-based distance computation, structure-based spectral clustering, time series},
	pages = {1--8}
},

@book{scholkopf_learning_2002,
	title = {Learning with kernels},
	publisher = {Citeseer},
	author = {B. Scholkopf and A. J Smola},
	year = {2002}
},

@article{ou_spatial_2005,
	title = {From spatial regularization to anatomical priors in fmri analysis},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.83.9637},
	journal = {{I}nformation {I}n {M}edical {I}maging},
	author = {Wanmei Ou and Polina Goll},
	year = {2005},
	pages = {88---100}
},

@article{penny_bayesian_2005,
	title = {Bayesian {fMRI} time series analysis with spatial priors},
	volume = {24},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-16244387927&partnerID=40},
	abstract = {We describe a Bayesian estimation and inference procedure for {fMRI} time series based on the use of General Linear Models {(GLMs).} Importantly, we use a spatial prior on regression coefficients which embodies our prior knowledge that evoked responses are spatially contiguous and locally homogeneous. Further, using a computationally efficient Variational Bayes framework, we are able to let the data determine the optimal amount of smoothing. We assume an arbitrary order {Auto-Regressive} {(AR)} model for the errors. Our model generalizes earlier work on voxel-wise estimation of {GLM-AR} models and inference in {GLMs} using Posterior Probability Maps {(PPMs).} Results are shown on simulated data and on data from an event-related {fMRI} experiment. © 2004 Elsevier Inc. All rights reserved.},
	number = {2},
	journal = {{NeuroImage}},
	author = {{W.D.} Penny and {N.J.} {Trujillo-Barreto} and {K.J.} Friston},
	year = {2005},
	keywords = {Autoregressive model, Effect-size, {FMRI,} General linear model, Laplacian, Smoothing, Spatial priors, Variational Bayes},
	pages = {350--362}
},

@article{schlkopf_nonlinear_1998,
	title = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem},
	volume = {10},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0347243182&partnerID=40},
	abstract = {A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map - for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.},
	number = {5},
	journal = {Neural Computation},
	author = {B. Schölkopf and A. Smola and {K.-R.} Müller},
	year = {1998},
	pages = {1299--1319}
},

@article{fox_spontaneous_2007,
	title = {Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging},
	volume = {8},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-34548014282&partnerID=40},
	abstract = {The majority of functional neuroscience studies have focused on the brain's response to a task or stimulus. However, the brain is very active even in the absence of explicit input or output. In this Article we review recent studies examining spontaneous fluctuations in the blood oxygen level dependent {(BOLD)} signal of functional magnetic resonance imaging as a potentially important and revealing manifestation of spontaneous neuronal activity. Although several challenges remain, these studies have provided insight into the intrinsic functional architecture of the brain, variability in behaviour and potential physiological correlates of neurological and psychiatric disease. © 2007 Nature Publishing Group.},
	number = {9},
	journal = {Nature Reviews Neuroscience},
	author = {{M.D.} Fox and {M.E.} Raichle},
	year = {2007},
	pages = {700--711}
},

@inproceedings{blaschko_correlational_2008,
	title = {Correlational spectral clustering},
	isbn = {1063-6919},
	doi = {10.1109/CVPR.2008.4587353},
	abstract = {We present a new method for spectral clustering with paired data based on kernel canonical correlation analysis, called correlational spectral clustering. Paired data are common in real world data sources, such as images with text captions. Traditional spectral clustering algorithms either assume that data can be represented by a single similarity measure, or by co-occurrence matrices that are then used in biclustering. In contrast, the proposed method uses separate similarity measures for each data representation, and allows for projection of previously unseen data that are only observed in one representation (e.g. images but not text). We show that this algorithm generalizes traditional spectral clustering algorithms and show consistent empirical improvement over spectral clustering on a variety of datasets of images with associated text.},
	booktitle = {Computer Vision and Pattern Recognition, 2008. {CVPR} 2008. {IEEE} Conference on},
	author = {{M.B.} Blaschko and {C.H.} Lampert},
	year = {2008},
	keywords = {co-occurrence matrices, correlational spectral clustering, data representation, data sources, data structures, image processing, kernel canonical correlation analysis, pattern clustering},
	pages = {1--8}
},

@misc{_zotero_????,
	title = {Zotero - Quick Start Guide},
	url = {http://www.zotero.org/documentation/quick_start_guide}
},

@misc{_url.pdf_????,
	title = {url.pdf},
	url = {http://www.google.com/url?sa=t&source=web&ct=res&cd=1&url=http%3A%2F%2Flib.stat.cmu.edu%2F~kass%2Ftspp%2Fnotes%2Fcoherence.pdf&ei=u2_NSrjSCoGItgffobDzAw&usg=AFQjCNGt9xByTm6RYeq0iOXwLQMrr-kyfQ&sig2=lYl7zSipizd7WgRxq3UNMg}
},

@misc{_data_????,
	title = {Data Clustering: A review},
	url = {http://www.google.com/url?sa=t&source=web&ct=res&cd=1&ved=0CAsQFjAA&url=http%3A%2F%2Fwww.cs.rutgers.edu%2F~mlittman%2Fcourses%2Flightai03%2Fjain99data.pdf&rct=j&q=clustering+review&ei=6uLbSsgmkKCzA9ycmLEJ&usg=AFQjCNHTlg-ZodP_wmv0qFGOHw2TwOW8OA&sig2=Aqs5sH_Odenc4QSlkDQIIw},
	howpublished = {{http://www.google.com/url?sa=t\&source=web\&ct=res\&cd=1\&ved=0CAsQFjAA\&url=http\%3A\%2F\%2Fwww.cs.rutgers.edu\%2F{\textasciitilde}mlittman\%2Fcourses\%2Flightai03\%2Fjain99data.pdf\&rct=j\&q=clustering+review\&ei=6uLbSsgmkKCzA9ycmLEJ\&usg=AFQjCNHTlg-ZodP\_wmv0qFGOHw2TwOW8OA\&sig2=Aqs5sH\_Odenc4QSlkDQIIw}}
},

@article{biemann_temporal_????,
	title = {Temporal kernel {CCA} and its application in multimodal neuronal data analysis},
	url = {http://dx.doi.org/10.1007/s10994-009-5153-3},
	doi = {10.1007/s10994-009-5153-3},
	abstract = {Abstract  Data recorded from multiple sources sometimes exhibit non-instantaneous couplings. For simple data sets, cross-correlograms
may reveal the coupling dynamics. But when dealing with high-dimensional multivariate data there is no such measure as the
cross-correlogram. We propose a simple algorithm based on Kernel Canonical Correlation Analysis {(kCCA)} that computes a multivariate
temporal filter which links one data modality to another one. The filters can be used to compute a multivariate extension
of the cross-correlogram, the canonical correlogram, between data sources that have different dimensionalities and temporal
resolutions. The canonical correlogram reflects the coupling dynamics between the two sources. The temporal filter reveals
which features in the data give rise to these couplings and when they do so. We present results from simulations and neuroscientific
experiments showing that {tkCCA} yields easily interpretable temporal filters and correlograms. In the experiments, we simultaneously
performed electrode recordings and functional magnetic resonance imaging {(fMRI)} in primary visual cortex of the non-human
primate. While electrode recordings reflect brain activity directly, {fMRI} provides only an indirect view of neural activity
via the Blood Oxygen Level Dependent {(BOLD)} response. Thus it is crucial for our understanding and the interpretation of {fMRI}
signals in general to relate them to direct measures of neural activity acquired with electrodes. The results computed by
{tkCCA} confirm recent models of the hemodynamic response to neural activity and allow for a more detailed analysis of neurovascular
coupling dynamics.},
	journal = {Machine Learning},
	author = {Felix Bießmann and Frank Meinecke and Arthur Gretton and Alexander Rauch and Gregor Rainer and Nikos Logothetis and {Klaus-Robert} Müller}
},

@misc{_url.pdf_????-1,
	title = {url.pdf},
	url = {http://www.google.com/url?sa=t&source=web&ct=res&cd=7&ved=0CDwQFjAG&url=http%3A%2F%2Fwww.cs.uoi.gr%2F~tzikas%2Fpapers%2FSPM08.pdf&ei=If4rS7rvL4jIsAOE28WJBA&usg=AFQjCNE48BaDlWhGzRyQegH308-yB-sC5A&sig2=EBvFvpPX0WEbF0Qoc2eTQg}
},

@inproceedings{liu_boostcluster:_2007,
	address = {San Jose, California, {USA}},
	title = {{BoostCluster:} boosting clustering by pairwise constraints},
	isbn = {978-1-59593-609-7},
	shorttitle = {{BoostCluster}},
	url = {http://portal.acm.org/citation.cfm?id=1281242},
	doi = {10.1145/1281192.1281242},
	abstract = {Data clustering is an important task in many disciplines. A large number of studies have attempted to improve clustering by using the side information that is often encoded as pairwise constraints. However, these studies focus on designing special clustering algorithms that can effectively exploit the pairwise constraints. We present a boosting framework for data clustering,termed as {BoostCluster,} that is able to iteratively improve the accuracy of any given clustering algorithm by exploiting the pairwise constraints. The key challenge in designing a boosting framework for data clustering is how to influence an arbitrary clustering algorithm with the side information since clustering algorithms by definition are unsupervised. The proposed framework addresses this problem by dynamically generating new data representations at each iteration that are, on the one hand, adapted to the clustering results at previous iterations by the given algorithm, and on the other hand consistent with the given side information. Our empirical study shows that the proposed boosting framework is effective in improving the performance of a number of popular clustering algorithms {(K-means,} partitional {SingleLink,} spectral clustering), and its performance is comparable to the state-of-the-art algorithms for data clustering with side information.},
	booktitle = {Proceedings of the 13th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	publisher = {{ACM}},
	author = {Yi Liu and Rong Jin and Anil K. Jain},
	year = {2007},
	keywords = {Boosting, Data clustering, pairwise constraints, Semi-supervised learning},
	pages = {450--459}
},

@misc{_signal_????,
	title = {Signal Processing Course},
	url = {http://www.fil.ion.ucl.ac.uk/~wpenny/course/course.html},
	howpublished = {http://www.fil.ion.ucl.ac.uk/{\textasciitilde}wpenny/course/course.html}
},

@article{warren_liao_clustering_2005,
	title = {Clustering of time series data--a survey},
	volume = {38},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/B6V14-4G7G4BP-2/2/8e96ce614dd47a4a84c6712bd0c43022},
	doi = {10.1016/j.patcog.2005.01.025},
	abstract = {Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research.},
	number = {11},
	journal = {Pattern Recognition},
	author = {T. Warren Liao},
	month = nov,
	year = {2005},
	keywords = {clustering, data mining, Distance measure, Time series data},
	pages = {1857--1874}
},

@article{lindeberg_detecting_1993,
	title = {Detecting salient blob-like image structures and their scales with a scale-space primal sketch: a method for focus-of-attention},
	volume = {11},
	shorttitle = {Detecting salient blob-like image structures and their scales with a scale-space primal sketch},
	number = {3},
	journal = {International Journal of Computer Vision},
	author = {T. Lindeberg},
	year = {1993},
	pages = {283–318}
},

@misc{galic_cardiac_2001,
	title = {Cardiac image segmentation using spatiotemporal clustering},
	url = {http://adsabs.harvard.edu/abs/2001SPIE.4322.1199G},
	author = {Sasa Galic and Sven Loncaric},
	month = jul,
	year = {2001},
	howpublished = {{http://adsabs.harvard.edu/abs/2001SPIE.4322.1199G}}
},

@book{mukhopadhyay_introductory_2006,
	title = {Introductory statistical inference},
	isbn = {1574446134, 9781574446135},
	publisher = {{CRC} Press},
	author = {Nitis Mukhopadhyay},
	year = {2006}
},

@inproceedings{ham_kernel_2004-1,
	title = {A kernel view of the dimensionality reduction of manifolds},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-11144299132&partnerID=40},
	abstract = {We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods. Isomap, graph Laplacian eigenmap, and locally linear embedding {(LLE)} all utilize local neighborhood information to construct a global embedding of the manifold. We show how all three algorithms can be described as kernel {PCA} on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples.},
	booktitle = {Proceedings, {Twenty-First} International Conference on Machine Learning, {ICML} 2004},
	author = {J. Ham and {D.D.} Lee and S. Mika and B. Schölkopf},
	year = {2004},
	pages = {369--376}
},

@article{woolrich_variational_2006,
	title = {Variational Bayes inference of spatial mixture models for segmentation},
	volume = {25},
	issn = {0278-0062},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/17024841},
	abstract = {Mixture models are commonly used in the statistical segmentation of images. For example, they can be used for the segmentation of structural medical images into different matter types, or of statistical parametric maps into activating and nonactivating brain regions in functional imaging. Spatial mixture models have been developed to augment histogram information with spatial regularization using Markov random fields {(MRFs).} In previous work, an approximate model was developed to allow adaptive determination of the parameter controlling the strength of spatial regularization. Inference was performed using Markov Chain Monte Carlo {(MCMC)} sampling. However, this approach is prohibitively slow for large datasets. In this work, a more efficient inference approach is presented. This combines a variational Bayes approximation with a second-order Taylor expansion of the components of the posterior distribution, which would otherwise be intractable to Variational Bayes. This provides inference on fully adaptive spatial mixture models an order of magnitude faster than {MCMC.} We examine the behavior of this approach when applied to artificial data with different spatial characteristics, and to functional magnetic resonance imaging statistical parametric maps.},
	number = {10},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {Mark W Woolrich and Timothy E Behrens},
	month = oct,
	year = {2006},
	note = {{PMID:} 17024841},
	keywords = {Algorithms, Artificial Intelligence, Bayes Theorem, Brain, Computer Simulation, Humans, Image Enhancement, Image Interpretation, {Computer-Assisted,} Information Storage and Retrieval, Magnetic Resonance Imaging, Models, Neurological, Models, Statistical, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity},
	pages = {1380--1391}
},

@article{everitt_mixture_1999,
	title = {Mixture model mapping of brain activation in functional magnetic resonance images},
	volume = {7},
	url = {http://dx.doi.org/10.1002/(SICI)1097-0193(1999)7:1<1::AID-HBM1>3.0.CO;2-H},
	doi = {10.1002/(SICI)1097-0193(1999)7:1<1::AID-HBM1>3.0.CO;2-H},
	abstract = {We report on a novel method of identifying brain regions activated by periodic experimental design in functional magnetic resonance imaging data. This involves fitting a mixture distribution with two components to a test statistic estimated at each voxel in an image. The two parameters of this distribution, the proportion of nonactivated voxels, and the effect size can be estimated using maximum likelihood methods. Standard errors of the parameters can also be estimated. The fitted distribution can be used to derive brain activation maps and two examples are described, one involving a visual stimulation task, the other an auditory stimulation task. The method appears to have some advantages over direct use of the P-values corresponding to each voxel's value of the test statistic. Hum. Brain Mapping 7:1-14, 1999. © 1999 {Wiley-Liss,} Inc.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Brian S. Everitt and Edward T. Bullmore},
	year = {1999},
	pages = {1--14}
},

@article{flandin_bayesian_2007,
	title = {Bayesian {fMRI} data analysis with sparse spatial basis function priors},
	volume = {34},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33947179549&partnerID=40},
	abstract = {In previous work we have described a spatially regularised General Linear Model {(GLM)} for the analysis of brain functional Magnetic Resonance Imaging {(fMRI)} data where Posterior Probability Maps {(PPMs)} are used to characterise regionally specific effects. The spatial regularisation is defined over regression coefficients via a Laplacian kernel matrix and embodies prior knowledge that evoked responses are spatially contiguous and locally homogeneous. In this paper we propose to finesse this Bayesian framework by specifying spatial priors using Sparse Spatial Basis Functions {(SSBFs).} These are defined via a hierarchical probabilistic model which, when inverted, automatically selects an appropriate subset of basis functions. The method includes non-linear wavelet shrinkage as a special case. As compared to Laplacian spatial priors, {SSBFs} allow for spatial variations in signal smoothness, are more computationally efficient and are robust to heteroscedastic noise. Results are shown on synthetic data and on data from an event-related {fMRI} experiment. © 2006 Elsevier Inc. All rights reserved.},
	number = {3},
	journal = {{NeuroImage}},
	author = {G. Flandin and {W.D.} Penny},
	year = {2007},
	keywords = {{FMRI,} General linear model, Hierarchical model, Sparse spatial prior, Variational Bayes, Wavelet denoising},
	pages = {1108--1125}
},

@article{faisan_hidden_2007,
	title = {Hidden Markov multiple event sequence models: A paradigm for the spatio-temporal analysis of {fMRI} data},
	volume = {11},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/B6W6Y-4M9H8YD-2/2/b842cf36879324781dfc45fd07c1ef74},
	doi = {doi: DOI: 10.1016/j.media.2006.09.003},
	number = {1},
	journal = {Medical Image Analysis},
	author = {S. Faisan and L. Thoraval and {J.-P.} Armspach and F. Heitz},
	month = feb,
	year = {2007},
	keywords = {Brain mapping, Data fusion, Functional {MRI,} Hidden Markov models, Multidimensional signal processing},
	pages = {1--20}
},

@article{franois_bayesian_2006,
	title = {Bayesian Clustering Using Hidden Markov Random Fields in Spatial Population Genetics},
	volume = {174},
	url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1602073},
	doi = {10.1534/genetics.106.059923},
	number = {2},
	journal = {Genetics},
	author = {Olivier François and Sophie Ancelet and Gilles Guillot},
	month = oct,
	year = {2006},
	note = {{PMCID:} {PMC1602073}},
	pages = {805–816}
},

@article{grira_unsupervised_2004,
	title = {Unsupervised and semi-supervised clustering: a brief survey},
	shorttitle = {Unsupervised and semi-supervised clustering},
	journal = {A Review of Machine Learning Techniques for Processing Multimedia Content’, Report of the {MUSCLE} European Network of Excellence {(FP6)}},
	author = {N. Grira and M. Crucianu and N. Boujemaa},
	year = {2004}
},

@article{garcia-garcia_new_2009,
	title = {A New Distance Measure for {Model-Based} Sequence Clustering},
	volume = {31},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2008.268},
	abstract = {We review the existing alternatives for defining model-based distances for clustering sequences and propose a new one based on the {Kullback-Leibler} divergence. This distance is shown to be especially useful in combination with spectral clustering. For improved performance in real-world scenarios, a model selection scheme is also proposed.},
	number = {7},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {D. {Garcia-Garcia} and {E.P.} Hernandez and F. Diaz de Maria},
	year = {2009},
	keywords = {clustering, {Kullback-Leibler} divergence, model-based distances, model-based sequence clustering, model selection scheme, pattern clustering, sequence clustering, sequential data, Similarity measures, similarity measures.},
	pages = {1325--1331}
},

@article{filippone_survey_2008-1,
	title = {A survey of kernel and spectral methods for clustering},
	volume = {41},
	number = {1},
	journal = {Pattern Recognition},
	author = {M. Filippone and F. Camastra and F. Masulli and S. Rovetta},
	year = {2008},
	pages = {176–190}
},

@article{bengio_learning_2004,
	title = {Learning Eigenfunctions Links Spectral Embedding and Kernel {PCA}},
	volume = {16},
	url = {http://dx.doi.org/10.1162/0899766041732396},
	doi = {10.1162/0899766041732396},
	abstract = {In this letter, we show a direct relation between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density. Whereas spectral embedding methods provided only coordinates for the training points, the analysis justifies a simple extension to out-of-sample examples (the Nyström formula) for multidimensional scaling {(MDS),} spectral clustering, Laplacian eigenmaps, locally linear embedding {(LLE),} and Isomap. The analysis provides, for all such spectral embedding methods, the definition of a loss function, whose empirical average is minimized by the traditional algorithms. The asymptotic expected value of that loss defines a generalization performance and clarifies what these algorithms are trying to learn. Experiments with {LLE,} Isomap, spectral clustering, and {MDS} show that this out-of-sample embedding formula generalizes well, with a level of error comparable to the effect of small perturbations of the training set on the embedding.},
	number = {10},
	journal = {Neural Computation},
	author = {Yoshua Bengio and Olivier Delalleau and Nicolas Le Roux and {Jean-François} Paiement and Pascal Vincent and Marie Ouimet},
	month = oct,
	year = {2004},
	pages = {2197--2219}
},

@book{mukhopadhyay_introductory_2006-1,
	title = {Introductory statistical inference},
	isbn = {1574446134, 9781574446135},
	publisher = {{CRC} Press},
	author = {Nitis Mukhopadhyay},
	year = {2006}
},

@article{ou_spatial_2005-1,
	title = {From spatial regularization to anatomical priors in fmri analysis},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.83.9637},
	journal = {{INFORMATION} {PROCESSING} {IN} {MEDICAL} {IMAGING}},
	author = {Wanmei Ou and Polina Goll},
	year = {2005},
	pages = {88---100}
},

@article{hawkins_using_1989,
	title = {Using U Statistics to Derive the Asymptotic Distribution of Fisher's Z Statistic},
	volume = {43},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685369},
	abstract = {A simple derivation of the asymptotic distribution of Fisher's Z statistic for general bivariate parent distributions F is obtained using U-statistic theory. This method easily reveals that the asymptotic variance of Z generally depends on the correlation ρ and on certain moments of F. It also reveals the particular structure of F that makes the asymptotic variance of Z independent of ρ, and shows that there are many distributions F with this property. The bivariate normal is only one such F.},
	number = {4},
	journal = {The American Statistician},
	author = {D. L. Hawkins},
	month = nov,
	year = {1989},
	note = {{ArticleType:} primary\_article / Full publication date: Nov., 1989 / Copyright © 1989 American Statistical Association},
	pages = {235--237}
},

@article{hayasaka_comparison_2010,
	title = {Comparison of characteristics between region-and voxel-based network analyses in resting-state {fMRI} data},
	volume = {50},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4Y05DJ6-D/2/64b68c47b7e27b59d8e2d69a56151f2f},
	doi = {10.1016/j.neuroimage.2009.12.051},
	abstract = {Small-world networks are a class of networks that exhibit efficient long-distance communication and tightly interconnected local neighborhoods. In recent years, functional and structural brain networks have been examined using network theory-based methods, and consistently shown to have small-world properties. Moreover, some voxel-based brain networks exhibited properties of scale-free networks, a class of networks with mega-hubs. However, there are considerable inconsistencies across studies in the methods used and the results observed, particularly between region-based and voxel-based brain networks. We constructed functional brain networks at multiple resolutions using the same resting-state {fMRI} data, and compared various network metrics, degree distribution, and localization of nodes of interest. It was found that the networks with higher resolutions exhibited the properties of small-world networks more prominently. It was also found that voxel-based networks were more robust against network fragmentation compared to region-based networks. Although the degree distributions of all networks followed an exponentially truncated power law rather than true power law, the higher the resolution, the closer the distribution was to a power law. The voxel-based analyses also enhanced visualization of the results in the {3D} brain space. It was found that nodes with high connectivity tended have high efficiency, a co-localization of properties that was not as consistently observed in the region-based networks. Our results demonstrate benefits of constructing the brain network at the finest scale the experiment will permit.},
	number = {2},
	journal = {{NeuroImage}},
	author = {Satoru Hayasaka and Paul J. Laurienti},
	month = apr,
	year = {2010},
	keywords = {Functional connectivity, Graph theory, Network theory, Resting-state {fMRI,} Scale-free network, Small-world network},
	pages = {499--508}
},

@article{beckmann_probabilistic_2004,
	title = {Probabilistic Independent Component Analysis for Functional Magnetic Resonance Imaging},
	volume = {23},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-1342324773&partnerID=40},
	abstract = {We present an integrated approach to probabilistic independent component analysis {(ICA)} for functional {MRI} {(FMRI)} data that allows for nonsquare mixing in the presence of Gaussian noise. In order to avoid overfitting, we employ objective estimation of the amount of Gaussian noise through Bayesian analysis of the true dimensionality of the data, i.e., the number of activation and {non-Gaussian} noise sources. This enables us to carry out probabilistic modeling and achieves an asymptotically unique decomposition of the data. It reduces problems of interpretation, as each final independent component is now much more likely to be due to only one physical or physiological process. We also describe other improvements to standard {ICA,} such as temporal prewhitening and variance normalization of timeseries, the latter being particularly useful in the context of dimensionality reduction when weak activation is present. We discuss the use of prior information about the spatiotemporal nature of the source processes, and an alternative-hypothesis testing approach for inference, using Gaussian mixture models. The performance of our approach is illustrated and evaluated on real and artificial {FMRI} data, and compared to the spatio-temporal accuracy of results obtained from classical {ICA} and {GLM} analyses.},
	number = {2},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {{C.F.} Beckmann and {S.M.} Smith},
	year = {2004},
	keywords = {Factor analysis, functional magnetic resonance imaging, Independent component analysis, Linear structural model, Mixture modeling},
	pages = {137--152}
},

@article{boykov_fast_2001,
	title = {Fast approximate energy minimization via graph cuts},
	volume = {23},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0035509961&partnerID=40},
	abstract = {Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. In this paper, we consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is {NP-hard} even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.},
	number = {11},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Y. Boykov and O. Veksler and R. Zabih},
	year = {2001},
	keywords = {Early vision, Energy minimization, Graph algorithms, Image restoration, Markov random fields, Maximum flow, Minimum cut, Motion, Multiway cut, Potts model, Stereo},
	pages = {1222--1239}
},

@inproceedings{neill_detection_2006,
	title = {Detection of Spatial and {Spatio-Temporal} Clusters},
	booktitle = {Ph},
	author = {D. B Neill},
	year = {2006}
},

@article{logan_evaluation_2008,
	title = {An evaluation of spatial thresholding techniques in {fMRI} analysis},
	volume = {29},
	issn = {1097-0193},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/18064589},
	doi = {10.1002/hbm.20471},
	abstract = {Many {fMRI} experiments have a common objective of identifying active voxels in a neuroimaging dataset. This is done in single subject experiments, for example, by performing individual voxel-wise tests of the null hypothesis that the observed time course is not significantly related to an assigned reference function. A voxel activation map is then constructed by applying a thresholding rule to the resulting statistics (e.g., t-statistics). Typically the task-related activation is expected to occur in clusters of voxels rather than in isolated single voxels. A variety of spatial thresholding techniques have been proposed to reflect this belief, including smoothing the raw t-statistics, cluster size inference, and spatial mixture modeling. We study two aspects of these spatial thresholding procedures applied to single subject {fMRI} analysis through simulation. First, we examine the performance of these procedures in terms of sensitivity to detect voxel activation, using receiver operating characteristic curves. Second, we consider the accuracy of these spatial thresholding procedures in estimation of the size of the activation region, both in terms of bias and variance. The findings indicate that smoothing has the highest sensitivity to modest magnitude signals, but tend to overestimate the size of the activation region. Spatial mixture models estimate the size of a spatially distributed activation region well, but may be less sensitive to modest magnitude signals, indicating that additional research into more sensitive spatial mixture models is needed. Finally, the methods are illustrated with a real bilateral finger-tapping {fMRI} experiment.},
	number = {12},
	journal = {Human Brain Mapping},
	author = {Brent R Logan and Maya P Geliazkova and Daniel B Rowe},
	month = dec,
	year = {2008},
	note = {{PMID:} 18064589},
	keywords = {Algorithms, Bias {(Epidemiology),} Brain, Brain Mapping, Computer Simulation, Fingers, Humans, Image Processing, {Computer-Assisted,} Magnetic Resonance Imaging, Models, Statistical, Movement, Psychomotor Performance, Signal Processing, {Computer-Assisted,} Software},
	pages = {1379--1389}
},

@article{geman_stochastic_1984,
	title = {Stochastic relaxation, {G}ibbs distributions, and the {B}ayesian restoration of images},
	volume = {6},
	journal = {{IEEE} {PAMI}},
	author = {S. Geman and D. Geman},
	year = {1984},
	pages = {721–-741}
},

@book{lawson_spatial_2002,
	title = {Spatial cluster modelling},
	isbn = {1584882662, 9781584882664},
	publisher = {{CRC} Press},
	author = {Andrew B. Lawson and David G. T. Denison},
	year = {2002}
},

@book{welch_real-time_2006,
	title = {Real-time digital signal processing from {MATLAB} to C with the {TMS320C6x} {DSK}},
	isbn = {0849373824, 9780849373824},
	publisher = {{CRC} Press},
	author = {Thad B. Welch and Cameron H. G. Wright and Michael G. Morrow},
	year = {2006}
},

@article{parrish_impact_2000,
	title = {Impact of signal-to-noise on functional {MRI}},
	volume = {44},
	number = {6},
	journal = {Magnetic Resonance in Medicine},
	author = {T. B Parrish and D. R Gitelman and K. S {LaBar} and M. M Mesulam},
	year = {2000},
	pages = {925–932}
},

@article{bond_seeingfisherz-transformation_2004,
	title = {Seeing the {FisherZ-transformation}},
	volume = {69},
	url = {http://dx.doi.org/10.1007/BF02295945},
	doi = {10.1007/BF02295945},
	abstract = {Abstract  Since 1915, statisticians have been applying {Fisher'sZ-transformation} to Pearson product-moment correlation coefficients. We offer new geometric interpretations of this transformation.},
	number = {2},
	journal = {Psychometrika},
	author = {Charles Bond and Ken Richardson},
	month = jun,
	year = {2004},
	pages = {291--303}
},

@book{__????-1
},

@article{frey_response_2008,
	title = {Response to comment on "clustering by passing messages between data points"},
	volume = {319},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38949137845&partnerID=40},
	abstract = {Affinity propagation {(AP)} can be viewed as a generalization of the vertex substitution heuristic {(VSH),} whereby probabilistic exemplar substitutions are performed concurrently. Although results on small data sets (≤900 points) demonstrate that {VSH} is competitive with {AP,} we found {VSH} to be prohibitively slow for moderate-to-large problems, whereas {AP} was much faster and could achieve lower error.},
	number = {5864},
	journal = {Science},
	author = {{B.J.} Frey and D. Dueck},
	year = {2008}
},

@inproceedings{kulis_learning_2006,
	title = {Learning low-rank kernel matrices},
	booktitle = {Proceedings of the 23rd international conference on Machine learning},
	author = {B. Kulis and M. Sustik and I. Dhillon},
	year = {2006},
	pages = {512}
},

@article{lawrence_probabilistic_2005-1,
	title = {Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models},
	volume = {6},
	url = {http://portal.acm.org/citation.cfm?id=1194904},
	abstract = {Summarising a high dimensional data set with a low dimensional embedding is a standard approach for exploring its structure. In this paper we provide an overview of some existing techniques for discovering such embeddings. We then introduce a novel probabilistic interpretation of principal component analysis {(PCA)} that we term dual probabilistic {PCA} {(DPPCA).} The {DPPCA} model has the additional advantage that the linear mappings from the embedded space can easily be non-linearised through Gaussian processes. We refer to this model as a Gaussian process latent variable model {(GP-LVM).} Through analysis of the {GP-LVM} objective function, we relate the model to popular spectral techniques such as kernel {PCA} and multidimensional scaling. We then review a practical algorithm for {GP-LVMs} in the context of large data sets and develop it to also handle discrete valued data and missing attributes. We demonstrate the model on a range of real-world and artificially generated data sets.},
	journal = {J. Mach. Learn. Res.},
	author = {Neil Lawrence},
	year = {2005},
	pages = {1783--1816}
},

@article{penny_bayesian_2007,
	title = {Bayesian comparison of spatially regularised general linear models},
	volume = {28},
	url = {http://dx.doi.org/10.1002/hbm.20327},
	doi = {10.1002/hbm.20327},
	abstract = {In previous work {(Penny} et al., [2005]: Neuroimage 24:350-362) we have developed a spatially regularised General Linear Model for the analysis of functional magnetic resonance imaging data that allows for the characterisation of regionally specific effects using Posterior Probability Maps {(PPMs).} In this paper we show how it also provides an approximation to the model evidence. This is important as it is the basis of Bayesian model comparison and provides a unified framework for Bayesian Analysis of Variance, Cluster of Interest analyses and the principled selection of signal and noise models. We also provide extensions that implement spatial and anatomical regularisation of noise process parameters. Hum Brain Mapp 2007. © 2006 {Wiley-Liss,} Inc.},
	number = {4},
	journal = {Human Brain Mapping},
	author = {Will Penny and Guillaume Flandin and Nelson {Trujillo-Barreto}},
	year = {2007},
	pages = {275--293}
},

@article{he_mrf_2008,
	title = {An {MRF} spatial fuzzy clustering method for {fMRI} {SPMs}},
	volume = {3},
	issn = {1746-8094},
	url = {http://www.sciencedirect.com/science/article/B7XMN-4T7W3NM-1/2/b268ebd578b17a6e3610caaa09b0175e},
	doi = {10.1016/j.bspc.2008.06.003},
	abstract = {The paper presents a method for spatial fuzzy clustering {(SFC)} via Markov Random Fields {(MRF)} for the detection of brain activation regions in Functional Magnetic Resonance Imaging {(fMRI)} statistical parametric maps {(SPMs)} to improve the accuracy of the detection of such regions. The {fMRI} {SPM} is assumed to be an {MRF} and we define a fuzzy neighborhood energy function to describe the interaction between neighboring voxels. The final labeling is determined by a joint fuzzy membership. We compare the proposed spatial fuzzy clustering technique with the usual voxel-wise thresholding, traditional fuzzy clustering and Contextual Clustering {(CC)} {[E.} Salli, {H.J.} Aronen, S. Savolainen, A. Korvenoja, A. Visa, Contextual clustering for analysis of functional {MRI} data, {IEEE} Transactions on Medical Imaging 20 (2001) 403-414]. Experiments based on synthetic and real {fMRI} data demonstrate that the clustering performance of our method is significantly better than both simple thresholding and conventional non-spatial fuzzy clustering techniques. Our experiments also show that in relatively high quality {SPMs} (contrast to noise ratio {(CNR){\textgreater}2.5),} the performance of {SFC} and {CC} is very similar. In the case of the simulated datasets, when the {SPMs} have poor quality {(CNR{\textless}2.5),} our method outperforms {CC} in reducing false positives and improving classification accuracy.},
	number = {4},
	journal = {Biomedical Signal Processing and Control},
	author = {Lili He and Ian R. Greenshields},
	month = oct,
	year = {2008},
	keywords = {{FMRI,} Fuzzy c-means, Markov Random Field, Spatial fuzzy clustering, Statistical parametric maps},
	pages = {327--333}
},

@article{watts_collective_1998-1,
	title = {Collective dynamics of 'small-world9 networks},
	volume = {393},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0032482432&partnerID=40},
	abstract = {Networks of coupled dynamical systems have been used to model biological oscillators 1-4, Josephson junction arrays5,6, excitable media7, neural networks8-10, spatial games", genetic control networks12 and many other self-organizing systems. Ordinarily, the connection topology is assumed to be either completely regular or completely random. But many biological, technological and social networks lie somewhere between these two extremes. Here we explore simple models of networks that can be tuned through this middle ground: regular networks 'rewired' to introduce increasing amounts of disorder. We find that these systems can be highly clustered, like regular lattices, yet have small characteristic path lengths, like random graphs. We call them 'small-world' networks, by analogy with the small-world phenomenon13'14 (popularly known as six degrees of separation15). The neural network of the worm Caenorhabditis elegans, the power grid of the western United States, and the collaboration graph of film actors are shown to be small-world networks. Models of dynamical systems with small-world coupling display enhanced signal-propagation speed, computational power, and synchronizability. In particular, infectious diseases spread more easily in small-world networks than in regular lattices.},
	number = {6684},
	journal = {Nature},
	author = {{D.J.} Watts and {S.H.} Strogatz},
	year = {1998},
	pages = {440--442}
},

@article{bassett_small-world_2006,
	title = {Small-world brain networks},
	volume = {12},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33750466904&partnerID=40},
	abstract = {Many complex networks have a small-world topology characterized by dense local clustering or cliquishness of connections between neighboring nodes yet a short path length between any (distant) pair of nodes due to the existence of relatively few long-range connections. This is an attractive model for the organization of brain anatomical and functional networks because a small-world topology can support both segregated/specialized and distributed/integrated information processing. Moreover, small-world networks are economical, tending to minimize wiring costs while supporting high dynamical complexity. The authors introduce some of the key mathematical concepts in graph theory required for small-world analysis and review how these methods have been applied to quantification of cortical connectivity matrices derived from anatomical tract-tracing studies in the macaque monkey and the cat. The evolution of small-world networks is discussed in terms of a selection pressure to deliver cost-effective information-processing systems. The authors illustrate how these techniques and concepts are increasingly being applied to the analysis of human brain functional networks derived from electroencephalography/ magnetoencephalography and {fMRI} experiments. Finally, the authors consider the relevance of small-world models for understanding the emergence of complex behaviors and the resilience of brain systems to pathological attack by disease or aberrant development. They conclude that small-world models provide a powerful and versatile approach to understanding the structure and function of human brain systems. Copyright © 2006 Sage Publications.},
	number = {6},
	journal = {Neuroscientist},
	author = {{D.S.} Bassett and E. Bullmore},
	year = {2006},
	keywords = {functional magnetic resonance imaging, Graph theory, Human brain functional networks, Small-world network},
	pages = {512--523}
},

@article{zou_estimatingtransformation_2002,
	title = {On estimating a transformation correlation coefficient},
	volume = {29},
	issn = {0266-4763},
	url = {http://www.informaworld.com/10.1080/02664760120098801},
	doi = {10.1080/02664760120098801},
	number = {5},
	journal = {Journal of Applied Statistics},
	author = {Kelly H. Zou and W. J. Hall},
	year = {2002},
	pages = {745}
},

@article{woolrich_multilevel_2004,
	title = {Multilevel linear modelling for {FMRI} group analysis using Bayesian inference},
	volume = {21},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-1842452778&partnerID=40},
	abstract = {Functional magnetic resonance imaging studies often involve the acquisition of data from multiple sessions and/or multiple subjects. A hierarchical approach can be taken to modelling such data with a general linear model {(GLM)} at each level of the hierarchy introducing different random effects variance components. Inferring on these models is nontrivial with frequentist solutions being unavailable. A solution is to use a Bayesian framework. One important ingredient in this is the choice of prior on the variance components and top-level regression parameters. Due to the typically small numbers of sessions or subjects in neuroimaging, the choice of prior is critical. To alleviate this problem, we introduce to neuroimage modelling the approach of reference priors, which drives the choice of prior such that it is noninformative in an information-theoretic sense. We propose two inference techniques at the top level for multilevel hierarchies (a fast approach and a slower more accurate approach). We also demonstrate that we can infer on the top level of multilevel hierarchies by inferring on the levels of the hierarchy separately and passing summary statistics of a noncentral multivariate t distribution between them. © 2004 Elsevier Inc. All rights reserved.},
	number = {4},
	journal = {{NeuroImage}},
	author = {{M.W.} Woolrich and {T.E.J.} Behrens and {C.F.} Beckmann and M. Jenkinson and {S.M.} Smith},
	year = {2004},
	keywords = {Bayes, {FMRI,} {GLM,} Mixed effects, Random effects, Reference priors},
	pages = {1732--1747}
},

@article{liu_partial_2009,
	title = {Partial correlation investigation on the default mode network involved in acupuncture: An {fMRI} study},
	volume = {462},
	issn = {0304-3940},
	shorttitle = {Partial correlation investigation on the default mode network involved in acupuncture},
	url = {http://www.sciencedirect.com/science/article/B6T0G-4WR66KX-4/2/a8b7fedf51e1c77445c467081847cf49},
	doi = {10.1016/j.neulet.2009.07.015},
	abstract = {Certain clinical reports and researches have shown that acupuncture effects can sustain a period during the post-stimulation state, and modulate the default mode network {(DMN).} In this study, partial correlation approach was utilized to investigate whether or not electro-acupuncture stimulation {(EAS)} at the three acupoints {(GB37} {(Guangming),} {BL60} {(Kunlun)} and {KI8} {(Jiaoxin))} and one sham point on the left leg modulated the {DMN} and how to change the intrinsic connectivity of the {DMN.} The results indicated that {DMN} could be modulated after {EAS,} and there existed different modulation patterns of the four points. Meanwhile, we found that the posterior cingulate cortex and precuneus {(PCC/pC)} strongly interacted with other nodes during the pre- and post-stimulation states. The correlation was interrupted between the {PCC/pC} and anterior cingulate cortex {(ACC).} The orbital prefrontal cortex {(OFC)} negatively interacted with the left medial temporal cortex {(lMTC)} at the acupoints. We suggested that the distinct modulation patterns to the {DMN} attributed to the different effects evoked by the three acupoints and one sham point.},
	number = {3},
	journal = {Neuroscience Letters},
	author = {Peng Liu and Yi Zhang and Guangyu Zhou and Kai Yuan and Wei Qin and Lu Zhuo and Jimin Liang and Peng Chen and Jianping Dai and Yijun Liu and Jie Tian},
	month = sep,
	year = {2009},
	keywords = {Acupuncture, {FMRI,} Partial correlation, The default mode network},
	pages = {183--187}
},

@article{faisan_unsupervised_2005,
	title = {Unsupervised learning and mapping of active brain functional {MRI} signals based on hidden {semi-Markov} event sequence models},
	volume = {24},
	issn = {0278-0062},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15707252},
	abstract = {In this paper, a novel functional magnetic resonance imaging {(fMRI)} brain mapping method is presented within the statistical modeling framework of hidden {semi-Markov} event sequence models {(HSMESMs).} Neural activation detection is formulated at the voxel level in terms of time coupling between the sequence of hemodynamic response onsets {(HROs)} observed in the {fMRI} signal, and an {HSMESM} of the hidden sequence of task-induced neural activations. The sequence of {HRO} events is derived from a continuous wavelet transform {(CWT)} of the {fMRI} signal. The brain activation {HSMESM} is built from the timing information of the input stimulation protocol. The rich mathematical framework of {HSMESMs} makes these models an effective and versatile approach for {fMRI} data analysis. Solving for the {HSMESM} Evaluation and Learning problems enables the model to automatically detect neural activation embedded in a given set of {fMRI} signals, without requiring any template basis function or prior shape assumption for the {fMRI} response. Solving for the {HSMESM} Decoding problem allows to enrich brain mapping with activation lag mapping, activation mode visualizing, and hemodynamic response function analysis. Activation detection results obtained on synthetic and real epoch-related {fMRI} data demonstrate the superiority of the {HSMESM} mapping method with respect to a real application case of the statistical parametric mapping {(SPM)} approach. In addition, the {HSMESM} mapping method appears clearly insensitive to timing variations of the hemodynamic response, and exhibits low sensitivity to fluctuations of its shape.},
	number = {2},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {Sylvain Faisan and Laurent Thoraval and {Jean-Paul} Armspach and {Marie-Noëlle} {Metz-Lutz} and Fabrice Heitz},
	month = feb,
	year = {2005},
	note = {{PMID:} 15707252},
	keywords = {Algorithms, Artificial Intelligence, Brain, Brain Mapping, Cluster Analysis, Computer Simulation, Evoked Potentials, Humans, Image Interpretation, {Computer-Assisted,} Information Storage and Retrieval, Magnetic Resonance Imaging, Markov Chains, Models, Neurological, Models, Statistical, Numerical Analysis, {Computer-Assisted,} Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Signal Processing, {Computer-Assisted}},
	pages = {263--276}
},

@article{hartvig_spatial_2000,
	title = {Spatial mixture modeling of {fMRI} data},
	volume = {11},
	url = {http://dx.doi.org/10.1002/1097-0193(200012)11:4<233::AID-HBM10>3.0.CO;2-F},
	doi = {10.1002/1097-0193(200012)11:4<233::AID-HBM10>3.0.CO;2-F},
	abstract = {Recently, Everitt and Bullmore [] proposed a mixture model for a test statistic for activation in {fMRI} data. The distribution of the statistic was divided into two components; one for nonactivated voxels and one for activated voxels. In this framework one can calculate a posterior probability for a voxel being activated, which provides a more natural basis for thresholding the statistic image, than that based on P-values. In this article, we extend the method of Everitt and Bullmore to account for spatial coherency of activated regions. We achieve this by formulating a model for the activation in a small region of voxels and using this spatial structure when calculating the posterior probability of a voxel being activated. We have investigated several choices of spatial models but find that they all work equally well for brain imaging data. We applied the model to synthetic data from statistical image analysis, a synthetic {fMRI} data set and to visual stimulation data. Our conclusion is that the method improves the estimation of the activation pattern significantly, compared to the nonspatial model and to smoothing the data with a kernel of {FWHM} 3 voxels. The difference between {FWHM} 2 smoothing and our method were more modest. Hum. Brain Mapping 11:233-248, 2000. © 2000 {Wiley-Liss,} Inc.},
	number = {4},
	journal = {Human Brain Mapping},
	author = {Niels Væver Hartvig and Jens Ledet Jensen},
	year = {2000},
	pages = {233--248}
},

@article{durand_commentinference_2009,
	title = {Comment on {'On} the inference of spatial structure from population genetics data'},
	volume = {25},
	url = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/25/14/1802},
	doi = {10.1093/bioinformatics/btp337},
	abstract = {Contact: Olivier.francois@imag.fr},
	number = {14},
	journal = {Bioinformatics},
	author = {Eric Durand and Chibiao Chen and Olivier Francois},
	month = jul,
	year = {2009},
	pages = {1802--1804}
},

@article{chalmond_iterative_1989,
	title = {An iterative Gibbsian technique for reconstruction of {\textless}italic{\textgreater}m{\textless}/italic{\textgreater}-ary images},
	volume = {22},
	url = {http://portal.acm.org/citation.cfm?id=78379},
	number = {6},
	journal = {Pattern Recogn.},
	author = {B. Chalmond},
	year = {1989},
	pages = {747--762}
},

@article{thirion_detection_2006,
	title = {Detection of signal synchronizations in resting-state {fMRI} datasets},
	volume = {29},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4H0BSYB-5/2/7486ca37ca0169666884d303b2bb6173},
	doi = {10.1016/j.neuroimage.2005.06.054},
	abstract = {In this paper, we propose a generic framework for the analysis of steady-state {fMRI} datasets, applied here to resting-state datasets. Our approach avoids the introduction of user-defined seed regions for the study of spontaneous activity. Unlike existing techniques, it yields a sparse representation of resting-state activity networks which can be characterized and investigated fairly easily in a semi-interactive fashion. We proceed in several steps, based on the idea that spectral coherence of the {fMRI} time courses in the low frequency band carries the information of interest. In particular, we address the question of building adapted representations of the data from the spectral coherence matrix. We analyze nine datasets taken from three subjects and show resting-state networks validated by {EEG-fMRI} simultaneous acquisition literature, with low intra-subject variability; we also discuss the merits of different (rapid/slow) {fMRI} acquisition schemes.},
	number = {1},
	journal = {{NeuroImage}},
	author = {Bertrand Thirion and Silke Dodel and {Jean-Baptiste} Poline},
	year = {2006},
	pages = {321--327}
},

@article{marrelec_partial_2006,
	title = {Partial correlation for functional brain interactivity investigation in functional {MRI}},
	volume = {32},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4K5ST4N-2/2/5acd94a1143bf0dae69bb3d03896f1c2},
	doi = {10.1016/j.neuroimage.2005.12.057},
	abstract = {Examination of functional interactions through effective connectivity requires the determination of three distinct levels of information: (1) the regions involved in the process and forming the spatial support of the network, (2) the presence or absence of interactions between each pair of regions, and (3) the directionality of the existing interactions. While many methods exist to select regions {(Step} 1), very little is available to complete Step 2. The two main methods developed so far, structural equation modeling {(SEM)} and dynamical causal modeling {(DCM),} usually require precise prior information to be used, while such information is sometimes lacking. Assuming that Step 1 was successfully completed, we here propose a data-driven method to deal with Step 2 and extract functional interactions from {fMRI} datasets through partial correlations. Partial correlation is more closely related to effective connectivity than marginal correlation and provides a convenient graphical representation for functional interactions. As an instance of brain interactivity investigation, we consider how simple hand movements are processed by the bihemispheric cortical motor network. In the proposed framework, Bayesian analysis makes it possible to estimate and test the partial statistical dependencies between regions without any prior model on the underlying functional interactions. We demonstrate the interest of this approach on real data.},
	number = {1},
	journal = {{NeuroImage}},
	author = {Guillaume Marrelec and Alexandre Krainik and Hugues Duffau and Mélanie {Pélégrini-Issac} and Stéphane Lehéricy and Julien Doyon and Habib Benali},
	month = aug,
	year = {2006},
	keywords = {Bayesian analysis, Effective connectivity, Functional brain interactivity, Functional connectivity, functional {MRI,} Motor network, Partial correlation},
	pages = {228--237}
},

@article{sanabria-diaz_surface_????,
	title = {Surface area and cortical thickness descriptors reveal different attributes of the structural human brain networks},
	volume = {In Press, Corrected Proof},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4Y65SD1-3/2/f3ae0e6695da17f9c36ab21158f8eac0},
	doi = {10.1016/j.neuroimage.2010.01.028},
	abstract = {Recently, a related morphometry-based connection concept has been introduced using local mean cortical thickness and volume to study the underlying complex architecture of the brain networks. In this article, the surface area is employed as a morphometric descriptor to study the concurrent changes between brain structures and to build binarized connectivity graphs. The statistical similarity in surface area between pair of regions was measured by computing the partial correlation coefficient across 186 normal subjects of the Cuban Human Brain Mapping Project. We demonstrated that connectivity matrices obtained follow a small-world behavior for two different parcellations of the brain gray matter. The properties of the connectivity matrices were compared to the matrices obtained using the mean cortical thickness for the same cortical parcellations. The topology of the cortical thickness and surface area networks were statistically different, demonstrating that both capture distinct properties of the interaction or different aspects of the same interaction (mechanical, anatomical, chemical, etc.) between brain structures. This finding could be explained by the fact that each descriptor is driven by distinct cellular mechanisms as result of a distinct genetic origin. To our knowledge, this is the first time that surface area is used to study the morphological connectivity of brain networks.},
	journal = {{NeuroImage}},
	author = {Gretel {Sanabria-Diaz} and Lester {Melie-García} and Yasser {Iturria-Medina} and Yasser {Alemán-Gómez} and Gertrudis {Hernández-González} and Lourdes {Valdés-Urrutia} and Lídice Galán and Pedro {Valdés-Sosa}}
},

@article{yeung_model-based_2001,
	title = {Model-based clustering and data transformations for gene expression data},
	volume = {17},
	number = {10},
	journal = {Bioinformatics},
	author = {K. Y. Yeung and C. Fraley and A. Murua and A. E. Raftery and W. L. Ruzzo},
	year = {2001},
	pages = {977}
},

@article{black_robust_1998,
	title = {Robust anisotropic diffusion},
	volume = {7},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0032023715&partnerID=40&md5=0477c34e40276cc920a3ac262ecf524e},
	abstract = {Relations between anisotropic diffusion and robust statistics are described in this paper. Specifically, we show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The "edge-stopping" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new "edge-stopping" function based on Tukey's biweight robust estimator that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in an image that has been smoothed with anisotropic diffusion. Additionally, we derive a relationship between anisotropic diffusion and regularization with line processes. Adding constraints on the spatial organization of the line processes allows us to develop new anisotropic diffusion equations that result in a qualitative improvement in the continuity of edges. © 1998 {IEEE.}},
	number = {3},
	journal = {{IEEE} Transactions on Image Processing},
	author = {{M.J.} Black and G. Sapiro and {D.H.} Marimont and D. Heeger},
	year = {1998},
	keywords = {Anisotropic diffusion, Line processes, Robust statistics},
	pages = {421--432}
},

@book{lindeberg_scale-space_1994,
	title = {Scale-space theory in computer vision},
	publisher = {Springer},
	author = {T. Lindeberg},
	year = {1994}
},

@article{brusco_commentclustering_2008,
	title = {Comment on "clustering by passing messages between data points"},
	volume = {319},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-38949090436&partnerID=40},
	abstract = {Frey and Dueck {(Reports,} 16 February 2007, p. 972) described an algorithm termed "affinity propagation" {(AP)} as a promising alternative to traditional data clustering procedures. We demonstrate that a well-established heuristic for the p-median problem often obtains clustering solutions with lower error than {AP} and produces these solutions in comparable computation time.},
	number = {5864},
	journal = {Science},
	author = {{M.J.} Brusco and {H.-F.} Köhn},
	year = {2008}
},

@article{ng_spectral_2001,
	title = {On Spectral Clustering: Analysis and an algorithm},
	volume = {14},
	shorttitle = {On Spectral Clustering},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.8100},
	journal = {{ADVANCES} {IN} {NEURAL} {INFORMATION} {PROCESSING} {SYSTEMS} 14},
	author = {Andrew Y Ng and Michael I Jordan and Yair Weiss},
	year = {2001},
	pages = {849---856}
},

@article{comaniciu_mean_2002,
	title = {Mean shift: A robust approach toward feature space analysis},
	volume = {24},
	shorttitle = {Mean shift},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0036565814&partnerID=40&md5=07ec0278eefc1f00f1080d8c3058a1b9},
	abstract = {A general nonparametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure, the mean shift. We prove for discrete data the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the {Nadaraya-Watson} estimator from kernel regression and the robust M-estimators of location is also established. Algorithms for two low-level vision tasks, discontinuity preserving smoothing and image segmentation, are described as applications. In these algorithms, the only user set parameter is the resolution of the analysis and either gray level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.},
	number = {5},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {D. Comaniciu and P. Meer},
	year = {2002},
	keywords = {clustering, Feature space, image segmentation, Image smoothing, Low-level vision, Mean shift},
	pages = {603--619}
},

@article{meyer_spatiotemporal_2005,
	title = {Spatiotemporal clustering of {fMRI} time series in the spectral domain.},
	volume = {9},
	issn = {1361-8415},
	url = {http://dx.doi.org/10.1016/j.media.2004.07.002},
	abstract = {We propose a new method for the analysis of functional magnetic resonance images {(fMRI).} The decision that a voxel v0 is activated is based not solely on the value of the {fMRI} signal at v0, but rather on the comparison of all time series s(v)(t) in a small neighborhood Nv0 around v0. Our approach explicitly takes into account the intrinsic spatiotemporal correlations that exist in the data. We focus on experimental designs with periodic stimuli, and therefore we can capture most of the features of the {BOLD} signal with a low dimensional subspace in the frequency domain. The presence of activated time series can be detected by partitioning the time series in this low dimensional space. Experiments with simulated data, and experimental {fMRI} data, demonstrate that our approach can outperform standard methods of analysis, such as the t-test.},
	number = {1},
	journal = {Med Image Anal},
	author = {{FG} Meyer and J Chinrungrueng},
	month = feb,
	year = {2005},
	keywords = {clustering, {FMRI,} fnak, kmeans},
	pages = {68, 51}
},

@article{clarke_properties_2008,
	title = {The properties of high-dimensional data spaces: Implications for exploring gene and protein expression data},
	volume = {8},
	shorttitle = {The properties of high-dimensional data spaces},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-37549029793&partnerID=40},
	abstract = {High-throughput genomic and proteomic technologies are widely used in cancer research to build better predictive models of diagnosis, prognosis and therapy, to identify and characterize key signalling networks and to find new targets for drug development. These technologies present investigators with the task of extracting meaningful statistical and biological information from high-dimensional data spaces, wherein each sample is defined by hundreds or thousands of measurements, usually concurrently obtained. The properties of high dimensionality are often poorly understood or overlooked in data modelling and analysis. From the perspective of translational science, this Review discusses the properties of high-dimensional data spaces that arise in genomic and proteomic studies and the challenges they can pose for data analysis and interpretation. © 2008 Nature Publishing Group.},
	number = {1},
	journal = {Nature Reviews Cancer},
	author = {R. Clarke and {H.W.} Ressom and A. Wang and J. Xuan and {M.C.} Liu and {E.A.} Gehan and Y. Wang},
	year = {2008},
	pages = {37--49}
},

@article{salli_contextual_2001,
	title = {Contextual clustering for analysis of functional {MRI} data},
	volume = {20},
	issn = {0278-0062},
	doi = {10.1109/42.925293},
	abstract = {Presents a contextual clustering procedure for statistical parametric maps {(SPM)} calculated from time varying three-dimensional images. The algorithm can be used for the detection of neural activations from functional magnetic resonance images {(fMRI).} An important characteristic of {SPM} is that the intensity distribution of background (nonactive area) is known whereas the distributions of activation areas are not. The developed contextual clustering algorithm divides an {SPM} into background and activation areas so that the probability of detecting false activations by chance is controlled, i.e., hypothesis testing is performed. Unlike the much used voxel-by-voxel testing, neighborhood information is utilized, an important difference. This is achieved by using a Markov random field prior and iterated conditional modes {(ICM)} algorithm. However, unlike in the conventional use of {ICM} algorithm, the classification is based only on the distribution of background. The results from the authors' simulations and human {fMRI} experiments using visual stimulation demonstrate that a better sensitivity is achieved with a given specificity in comparison to the voxel-by-voxel thresholding technique. The algorithm is computationally efficient and can be used to detect and delineate objects from a noisy background in other applications.},
	number = {5},
	journal = {Medical Imaging, {IEEE} Transactions on},
	author = {E. Salli and {H.J.} Aronen and S. Savolainen and A. Korvenoja and A. Visa},
	year = {2001},
	keywords = {activation areas, background distribution, biomedical {MRI,} contextual clustering, false activations detection probability, functional {MRI} data analysis, iterated conditional modes algorithm, Magnetic Resonance Imaging, Markov processes, Markov random field prior, medical diagnostic imaging, medical image processing, neighborhood information, neurophysiology, noisy background, objects delineation, objects detection, probability, statistical analysis, statistical parametric map, voxel-by-voxel testing, voxel-by-voxel thresholding technique},
	pages = {403--414}
},

@inproceedings{basu_probabilistic_2004,
	title = {A probabilistic framework for semi-supervised clustering},
	booktitle = {Proceedings of the tenth {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	author = {S. Basu and M. Bilenko and R. J Mooney},
	year = {2004},
	pages = {59–68}
},

@article{neumann_learning_2010,
	title = {Learning partially directed functional networks from meta-analysis imaging data},
	volume = {49},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70749094781&partnerID=40},
	abstract = {We propose a new exploratory method for the discovery of partially directed functional networks from {fMRI} meta-analysis data. The method performs structure learning of Bayesian networks in search of directed probabilistic dependencies between brain regions. Learning is based on the co-activation of brain regions observed across several independent imaging experiments. In a series of simulations, we first demonstrate the reliability of the method. We then present the application of our approach in an extensive meta-analysis including several thousand activation coordinates from more than 500 imaging studies. Results show that our method is able to automatically infer Bayesian networks that capture both directed and undirected probabilistic dependencies between a number of brain regions, including regions that are frequently observed in motor-related and cognitive control tasks. © 2009 Elsevier Inc. All rights reserved.},
	number = {2},
	journal = {{NeuroImage}},
	author = {J. Neumann and {P.T.} Fox and R. Turner and G. Lohmann},
	year = {2010},
	pages = {1372--1384}
},

@article{everitt_mixture_1999-1,
	title = {Mixture model mapping of the brain activation in functional magnetic resonance images},
	volume = {7},
	issn = {1065-9471},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/9882086},
	abstract = {We report on a novel method of identifying brain regions activated by periodic experimental design in functional magnetic resonance imaging data. This involves fitting a mixture distribution with two components to a test statistic estimated at each voxel in an image. The two parameters of this distribution, the proportion of nonactivated voxels, and the effect size can be estimated using maximum likelihood methods. Standard errors of the parameters can also be estimated. The fitted distribution can be used to derive brain activation maps and two examples are described, one involving a visual stimulation task, the other an auditory stimulation task. The method appears to have some advantages over direct use of the P-values corresponding to each voxel's value of the test statistic.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {B S Everitt and E T Bullmore},
	year = {1999},
	note = {{PMID:} 9882086},
	keywords = {Acoustic Stimulation, Brain, Brain Mapping, Computer Simulation, Humans, Image Processing, {Computer-Assisted,} Magnetic Resonance Imaging, Mathematics, Models, Neurological},
	pages = {1--14}
},

@misc{weisstein_correlation_????,
	type = {Text},
	title = {Correlation {Coefficient--Bivariate} Normal Distribution -- from Wolfram {MathWorld}},
	copyright = {Copyright 1999-2009 Wolfram Research, Inc.  See http://mathworld.wolfram.com/about/terms.html for a full terms of use statement.},
	url = {http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html},
	author = {Eric W Weisstein},
	note = {For a bivariate normal distribution, the distribution of correlation coefficients is given by P(r) = {1/pi(N-2)(1-r{\textasciicircum}2){\textasciicircum}((N-4)/2)(1-rho{\textasciicircum}2){\textasciicircum}((N-1)/2)int\_0{\textasciicircum}infty(dbeta)/((coshbeta-rhor){\textasciicircum}(N-1))} (1)   = {1/pi(N-2)(1-r{\textasciicircum}2){\textasciicircum}((N-4)/2)(1-rho{\textasciicircum}2){\textasciicircum}((N-1)/2)sqrt(pi/2)(Gamma(N-1))/(Gamma(N-1/2))×(1-rhor){\textasciicircum}(-(N-3/2))\_2F\_1(1/2,1/2,(2N-1)/2;(rhor+1)/2)} (2)   =...},
	keywords = {{62G,} {62J,} {Mathematics:Probability} and {Statistics:Regression}},
	howpublished = {{http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html}}
},

@inproceedings{dhillon_kernel_2004,
	title = {Kernel k-means: spectral clustering and normalized cuts},
	booktitle = {Proceedings of the tenth {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	author = {I. S Dhillon and Y. Guan and B. Kulis},
	year = {2004},
	pages = {556}
},

@article{norman_beyond_2006,
	title = {Beyond mind-reading: multi-voxel pattern analysis of {fMRI} data},
	volume = {10},
	issn = {1364-6613},
	shorttitle = {Beyond mind-reading},
	url = {http://www.sciencedirect.com/science/article/B6VH9-4KKNNHN-8/2/81baf5c442ebeb9c01ba967c241035d8},
	doi = {10.1016/j.tics.2006.07.005},
	abstract = {A key challenge for cognitive neuroscience is determining how mental representations map onto patterns of neural activity. Recently, researchers have started to address this question by applying sophisticated pattern-classification algorithms to distributed (multi-voxel) patterns of functional {MRI} data, with the goal of decoding the information that is represented in the subject's brain at a particular point in time. This multi-voxel pattern analysis {(MVPA)} approach has led to several impressive feats of mind reading. More importantly, {MVPA} methods constitute a useful new tool for advancing our understanding of neural information processing. We review how researchers are using {MVPA} methods to characterize neural coding and information processing in domains ranging from visual perception to memory search.},
	number = {9},
	journal = {Trends in Cognitive Sciences},
	author = {Kenneth A. Norman and Sean M. Polyn and Greg J. Detre and James V. Haxby},
	month = sep,
	year = {2006},
	pages = {424--430}
},

@article{perona_scale-space_1990,
	title = {Scale-space and edge detection using anisotropic diffusion},
	volume = {12},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0025465145&partnerID=40&md5=9f2d3532130bc5f02c5bfd4da5398c91},
	abstract = {A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in our approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image.},
	number = {7},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Pietro Perona and Jitendra Malik},
	year = {1990},
	pages = {629--639}
},

@misc{aclark_quaternion_????,
	type = {Document},
	title = {Quaternion representation — Neuroimaging Informatics Technology Initiative},
	url = {http://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields_pages/quatern.html},
	author = {aclark},
	howpublished = {http://nifti.nimh.nih.gov/nifti-1/documentation/nifti1fields/nifti1fields\_pages/quatern.html}
},

@article{fouladi_fisher_2008,
	title = {The Fisher Transform of the Pearson Product Moment Correlation Coefficient and Its Square: Cumulants, Moments, and Applications},
	volume = {37},
	issn = {0361-0918},
	shorttitle = {The Fisher Transform of the Pearson Product Moment Correlation Coefficient and Its Square},
	url = {http://www.informaworld.com/10.1080/03610910801943735},
	doi = {10.1080/03610910801943735},
	number = {5},
	journal = {Communications in Statistics - Simulation and Computation},
	author = {Rachel T. Fouladi and James H. Steiger},
	year = {2008},
	pages = {928}
},

@book{schlkopf_advances_2007-1,
	title = {Advances in Neural Information Processing Systems 19},
	isbn = {0262195682, 9780262195683},
	publisher = {{MIT} Press},
	author = {Bernhard Schölkopf and John Platt and Thomas Hofmann},
	year = {2007}
},

@article{grosenick_interpretable_2008,
	title = {Interpretable Classifiers for {fMRI} Improve Prediction of Purchases},
	volume = {16},
	issn = {1534-4320},
	doi = {10.1109/TNSRE.2008.926701},
	abstract = {Despite growing interest in applying machine learning to neuroimaging analyses, few studies have gone beyond classifying sensory input to directly predicting behavioral output. With spatial resolution on the order of millimeters and temporal resolution on the order of seconds, functional magnetic resonance imaging {(fMRI)} is a promising technology for such applications. However, {fMRI} data's low signal-to-noise ratio, high dimensionality, and extensive spatiotemporal correlations present formidable analytic challenges. Here, we apply different machine-learning algorithms to previously acquired data to examine the ability of {fMRI} activation in three regions—the nucleus accumbens {(NAcc),} medial prefrontal cortex {(MPFC),} and insula—to predict purchasing. Our goal was to improve spatiotemporal interpretability as well as classification accuracy. To this end, sparse penalized discriminant analysis {(SPDA)} enabled automatic selection of correlated variables, yielding interpretable models that generalized well to new data. Relative to logistic regression, linear discriminant analysis, and linear support vector machines, {SPDA} not only increased interpretability but also improved classification accuracy. {SPDA} promises to allow more precise inferences about when specific brain regions contribute to purchasing decisions. More broadly, this approach provides a general framework for using neuroimaging data to build interpretable models, including those that predict choice.},
	number = {6},
	journal = {Neural Systems and Rehabilitation Engineering, {IEEE} Transactions on},
	author = {L. Grosenick and S. Greer and B. Knutson},
	year = {2008},
	keywords = {Accumbens, classification, discriminant, elastic net, {FMRI,} frontal, functional magnetic resonance imaging {(fMRI),} human, insula, lasso, {PDA,} penalized discriminant analysis {(PDA),} prediction, purchasing, single-trial, sparse, spatiotemporal, support vector machine {(SVM),} {SVM}},
	pages = {539--548}
},

@article{schrder_gibbs_2000,
	title = {Gibbs random field models: a toolbox for spatial information extraction},
	volume = {26},
	issn = {0098-3004},
	shorttitle = {Gibbs random field models},
	url = {http://www.sciencedirect.com/science/article/B6V7D-3YVDBCW-7/2/4c132e3ca4dedd9b968c98b2c342689e},
	doi = {10.1016/S0098-3004(99)00122-3},
	abstract = {In this paper, we present Gibbs random field models in the form of a powerful toolbox for spatial information extraction from remote sensing images. These models are defined via parametrised energy functions that characterise local interactions between neighbouring pixels. After shortly revisiting the information theoretical concept and defining a family of Gibbs models, we give a tour through examples of different kinds of spatial information extraction. These examples range from parameter estimation and analysis, via selection of the model that best describes the image data, up to the segmentation of the whole image into regions with uniform properties of the model. Finally, the concept of across-image segmentation of spatial information leads to an application for content-based queries from remote sensing image archives.},
	number = {4},
	journal = {Computers \& Geosciences},
	author = {M. Schröder and M. Walessa and H. Rehrauer and K. Seidel and M. Datcu},
	month = may,
	year = {2000},
	keywords = {image processing, image segmentation, Remote sensing},
	pages = {423--432}
},

@article{friston_variational_2007,
	title = {Variational free energy and the Laplace approximation},
	volume = {34},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33751115761&partnerID=40},
	abstract = {This note derives the variational free energy under the Laplace approximation, with a focus on accounting for additional model complexity induced by increasing the number of model parameters. This is relevant when using the free energy as an approximation to the log-evidence in Bayesian model averaging and selection. By setting restricted maximum likelihood {(ReML)} in the larger context of variational learning and expectation maximisation {(EM),} we show how the {ReML} objective function can be adjusted to provide an approximation to the log-evidence for a particular model. This means {ReML} can be used for model selection, specifically to select or compare models with different covariance components. This is useful in the context of hierarchical models because it enables a principled selection of priors that, under simple hyperpriors, can be used for automatic model selection and relevance determination {(ARD).} Deriving the {ReML} objective function, from basic variational principles, discloses the simple relationships among Variational Bayes, {EM} and {ReML.} Furthermore, we show that {EM} is formally identical to a full variational treatment when the precisions are linear in the hyperparameters. Finally, we also consider, briefly, dynamic models and how these inform the regularisation of free energy ascent schemes, like {EM} and {ReML.} © 2006 Elsevier Inc. All rights reserved.},
	number = {1},
	journal = {{NeuroImage}},
	author = {K. Friston and J. Mattout and N. {Trujillo-Barreto} and J. Ashburner and W. Penny},
	year = {2007},
	keywords = {automatic relevance determination, Expectation maximisation, Free energy, Model selection, Relevance vector machines, Restricted maximum likelihood, Variational Bayes},
	pages = {220--234}
},

@article{cosman_exact_2004,
	title = {Exact {MAP} activity detection in {fMRI} using a {GLM} with an Ising spatial prior},
	journal = {Lecture Notes in Computer Science},
	author = {E. R. Cosman and J. W. Fisher and W. M. Wells},
	year = {2004},
	pages = {703–710}
},

@book{li_markov_2009,
	title = {Markov Random Field Modeling in Image Analysis},
	isbn = {1848002785, 9781848002784},
	publisher = {Springer},
	author = {Stan Z. Li},
	month = mar,
	year = {2009}
},

@article{lu_penalized_2007,
	title = {Penalized Probabilistic Clustering},
	volume = {19},
	url = {http://dx.doi.org/10.1162/neco.2007.19.6.1528},
	doi = {10.1162/neco.2007.19.6.1528},
	abstract = {While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to influence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on gaussian mixture models {(GMM)} of the data distribution. We express clustering preferences in a prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. The model parameters are fit with the expectation-maximization {(EM)} algorithm. Our model provides a flexible framework that encompasses several other semisupervised clustering models as its special cases. Experiments on artificial and real-world problems show that our model can consistently improve clustering results when pairwise relations are incorporated. The experiments also demonstrate the superiority of our model to other semisupervised clustering methods on handling noisy pairwise relations.},
	number = {6},
	journal = {Neural Computation},
	author = {Zhengdong Lu and Todd K. Leen},
	month = jun,
	year = {2007},
	pages = {1528--1567}
},

@article{van_horn_databasing_2002,
	title = {Databasing {fMRI} studies [mdash] towards a 'discovery science' of brain function},
	volume = {3},
	issn = {{1471-003X}},
	url = {http://dx.doi.org/10.1038/nrn788},
	doi = {10.1038/nrn788},
	number = {4},
	journal = {Nat Rev Neurosci},
	author = {John D. Van Horn and Michael S. Gazzaniga},
	month = apr,
	year = {2002},
	pages = {314--318}
},

@article{schn_similar_????,
	title = {Similar cerebral networks in language, music and song perception},
	volume = {In Press, Accepted Manuscript},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4YCS01G-C/2/3811c4319b8a2ba9259a559304950e71},
	doi = {10.1016/j.neuroimage.2010.02.023},
	abstract = {Two {fMRI} experiments were conducted using song to investigate the domain specificity of linguistic and musical processing. In Experiment 1, participants listened to pairs of spoken words, [`]vocalise' (i.e., singing without words), and sung words while performing a same-different task. Results revealed bilateral involvement of middle and superior temporal gyri and inferior and middle frontal gyri while listening to spoken words, sung words and vocalise, although to different degrees. In Experiment 2, participants listened to pairs of sung words that were similar or different in terms of the linguistic and musical dimensions (2x2 factorial event-related design) while performing a same-different task. Results showed widespread interactions between the linguistic and musical dimensions of sung words mainly within the network of brain areas identified in Experiment 1. Consequently, the activity in these brain regions cannot be considered as specific to either language or music processing. Taken together, results of both experiments argue against domain specificity and provide additional evidence for a common cerebral network involved in both lexical/phonological and melodic processing.},
	journal = {{NeuroImage}},
	author = {Daniele Schön and Reyna Gordon and Aurélie Campagne and Cyrille Magne and Corine Astésano and {Jean-Luc} Anton and Mireille Besson},
	keywords = {brain specificity, {FMRI,} melodic processing, phonological processing, song perception}
},

@article{weickert_scheme_2002,
	title = {A scheme for coherence-enhancing diffusion filtering with optimized rotation invariance},
	volume = {13},
	number = {1-2},
	journal = {Journal of Visual Communication and Image Representation},
	author = {J. Weickert and H. Scharr},
	year = {2002},
	pages = {103–118}
},

@inproceedings{lu_geometry-aware_2009,
	title = {Geometry-aware metric learning},
	volume = {382},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-70049118169&partnerID=40},
	abstract = {In this paper, we introduce a generic framework for semi-supervised kernel learning. Given pairwise (dis-)similarity constraints, we learn a kernel matrix over the data that respects the provided side-information as well as the local geometry of the data. Our framework is based on metric learning methods, where we jointly model the metric/kernel over the data along with the underlying manifold. Furthermore, we show that for some important parameterized forms of the underlying manifold model, we can estimate the model parameters and the kernel matrix efficiently. Our resulting algorithm is able to incorporate local geometry into the metric learning task; at the same time it can handle a wide class of constraints. Finally, our algorithm is fast and scalable - unlike most of the existing methods, it is able to exploit the low dimensional manifold structure and does not require semi-definite programming. We demonstrate wide applicability and effectiveness of our framework by applying to various machine learning tasks such as semisupervised classification, colored dimensionality reduction, manifold alignment etc. On each of the tasks our method performs competitively or better than the respective state-of-the-art {method.Copyright} 2009.},
	booktitle = {{ACM} International Conference Proceeding Series},
	author = {Z. Lu and P. Jain and {I.S.} Dhillon},
	year = {2009}
},

@book{weisberg_applied_2005,
	title = {Applied linear regression},
	isbn = {0471663794, 9780471663799},
	publisher = {John Wiley and Sons},
	author = {Sanford Weisberg},
	year = {2005}
},

@inproceedings{alzate_weighted_2006,
	title = {A Weighted Kernel {PCA} Formulation with {Out-of-Sample} Extensions for Spectral Clustering Methods},
	doi = {10.1109/IJCNN.2006.246671},
	abstract = {A new formulation to spectral clustering methods based on the weighted kernel principal component analysis is presented. This formulation fits in the Least Squares Support Vector Machines {(LS-SVM)} framework as a primal-dual interpretation in the context of constrained optimization problems. Starting from the {LS-SVM} formulation to kernel {PCA,} a weighted approach is derived. An advantage of this method is the possibility to apply the trained clustering model to out-of-sample (test) data points without using approximation techniques such as the Nystrom method. Links with some existing spectral clustering techniques are given, showing that these techniques are particular cases of weighted kernel {PCA.} Simulation results with toy and real-life data show improvements in terms of generalization to new samples.},
	booktitle = {Neural Networks, 2006. {IJCNN} '06. International Joint Conference on},
	author = {C. Alzate and {J.A.K.} Suykens},
	year = {2006},
	keywords = {approximation techniques, approximation theory, constrained optimization problems, generalisation (artificial intelligence), least squares approximations, least squares support vector machines, Nystrom method, optimisation, out-of-sample extensions, pattern clustering, principal component analysis, spectral clustering methods, support vector machines, trained clustering model, weighted kernel {PCA} formulation},
	pages = {138--144}
},

@article{besag_spatial_1974,
	title = {Spatial interaction and the statistical analysis of lattice systems},
	volume = {36},
	number = {2},
	journal = {Journal of the Royal Statistical Society. Series B {(Methodological)}},
	author = {J. Besag},
	year = {1974},
	pages = {192–236}
},

@misc{_url.pdf_????-2,
	title = {url.pdf},
	url = {http://www.google.com/url?sa=t&source=web&ct=res&cd=1&url=http%3A%2F%2Flib.stat.cmu.edu%2F~kass%2Ftspp%2Fnotes%2Fcoherence.pdf&ei=u2_NSrjSCoGItgffobDzAw&usg=AFQjCNGt9xByTm6RYeq0iOXwLQMrr-kyfQ&sig2=lYl7zSipizd7WgRxq3UNMg}
},

@article{frossyniotis_clustering_2004,
	title = {A clustering method based on boosting},
	volume = {25},
	url = {http://portal.acm.org/citation.cfm?id=987377},
	abstract = {It is widely recognized that the boosting methodology provides superior results for classification problems. In this paper, we propose the boost-clustering algorithm which constitutes a novel clustering methodology that exploits the general principles of boosting in order to provide a consistent partitioning of a dataset. The boost-clustering algorithm is a multi-clustering method. At each boosting iteration, a new training set is created using weighted random sampling from the original dataset and a simple clustering algorithm (e.g.k-means) is applied to provide a new data partitioning. The final clustering solution is produced by aggregating the multiple clustering results through weighted voting. Experiments on both artificial and real-world data sets indicate that boost-clustering provides solutions of improved quality.},
	number = {6},
	journal = {Pattern Recogn. Lett.},
	author = {D. Frossyniotis and A. Likas and A. Stafylopatis},
	year = {2004},
	keywords = {ensemble clustering, partitions schemes, unsupervised learning},
	pages = {641--654}
},

@article{descombes_fmri_1998,
	title = {{fMRI} Signal Restoration Using a {Spatio-Temporal} Markov Random Field Preserving Transitions},
	volume = {8},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-45JB17M-3/2/af2724db1314474349c0a39708d951af},
	doi = {10.1006/nimg.1998.0372},
	abstract = {In {fMRI} studies, Gaussian filtering is usually applied to improve the detection of activated areas. Such lowpass filtering enhances the signal to noise ratio. However, undesirable secondary effects are a bias on the signal shape and a blurring in the spatial domain. Neighboring activated areas may be merged and the high resolution of the {fMRI} data compromised. In the temporal domain, activation and deactivation slopes are also blurred. We propose an alternative to Gaussian filtering by restoring the signal using a spatiotemporal Markov Random Field which preserves the shape of the transitions. We define some interaction between neighboring voxels which allows us to reduce the noise while preserving the signal characteristics. An energy function is defined as the sum of the interaction potentials and is minimized using a simulated annealing algorithm. The shape of the hemodynamic response is preserved leading to a better characterization of its properties. We demonstrate the use of this approach by applying it to simulated data and to data obtained from a typical {fMRI} study.},
	number = {4},
	journal = {{NeuroImage}},
	author = {Xavier Descombes and Frithjof Kruggel and D. Yves von Cramon},
	month = nov,
	year = {1998},
	pages = {340--349}
},

@article{nadabar_parameter_1996,
	title = {Parameter estimation in Markov random field contextual models using geometric models of objects},
	volume = {18},
	issn = {0162-8828},
	doi = {10.1109/34.485560},
	abstract = {We present a new scheme for the estimation of Markov random field
line process parameters which uses geometric {CAD} models of the objects
in the scene. The models are used to generate synthetic images of the
objects from random view points. The edge maps computed from the
synthesized images are used as training samples to estimate the line
process parameters using a least squares method. We show that this
parameter estimation method is useful for detecting edges in range as
well as intensity edges. The main contributions of the paper are: 1) use
of {CAD} models to obtain true edge labels which are otherwise not
available; and 2) use of canonical Markov random field representation to
reduce the number of parameters},
	number = {3},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {{S.G.} Nadabar and {A.K.} Jain},
	year = {1996},
	keywords = {{CAD,} {CAD} models, clique potentials, computational geometry, computer graphics, contextual models, edge detection, edge maps, geometric models, least squares approximations, least squares method, Markov processes, Markov Random Field, parameter estimation, random view points, range image, synthetic images},
	pages = {326--329}
},

@incollection{shiavi_spectral_2007,
	address = {Burlington},
	title = {Spectral analysis for random signals: Nonparametric methods},
	isbn = {978-0-12-088581-7},
	shorttitle = {Spectral analysis for random signals},
	url = {http://www.sciencedirect.com/science/article/B87CR-4PB8FT9-C/2/69b3cc6f7d4c329d6cb285234470faa4},
	booktitle = {Introduction to Applied Statistical Signal Analysis {(Third} Edition)},
	publisher = {Academic Press},
	author = {Richard Shiavi},
	year = {2007},
	pages = {229--286}
},

@article{woolrich_fully_2004,
	title = {Fully Bayesian spatio-temporal modeling of {FMRI} data},
	volume = {23},
	issn = {0278-0062},
	doi = {10.1109/TMI.2003.823065},
	abstract = {We present a fully Bayesian approach to modeling in functional magnetic resonance imaging {(FMRI),} incorporating spatio-temporal noise modeling and haemodynamic response function {(HRF)} modeling. A fully Bayesian approach allows for the uncertainties in the noise and signal modeling to be incorporated together to provide full posterior distributions of the {HRF} parameters. The noise modeling is achieved via a nonseparable space-time vector autoregressive process. Previous {FMRI} noise models have either been purely temporal, separable or modeling deterministic trends. The specific form of the noise process is determined using model selection techniques. Notably, this results in the need for a spatially nonstationary and temporally stationary spatial component. Within the same full model, we also investigate the variation of the {HRF} in different areas of the activation, and for different experimental stimuli. We propose a novel {HRF} model made up of half-cosines, which allows distinct combinations of parameters to represent characteristics of interest. In addition, to adaptively avoid over-fitting we propose the use of automatic relevance determination priors to force certain parameters in the model to zero with high precision if there is no evidence to support them in the data. We apply the model to three datasets and observe matter-type dependence of the spatial and temporal noise, and a negative correlation between activation height and {HRF} time to main peak (although we suggest that this apparent correlation may be due to a number of different effects).},
	number = {2},
	journal = {Medical Imaging, {IEEE} Transactions on},
	author = {{M.W.} Woolrich and M. Jenkinson and {J.M.} Brady and {S.M.} Smith},
	year = {2004},
	keywords = {activation, automatic relevance determination, autoregressive processes, Bayes methods, biomedical {MRI,} {FMRI} data, full posterior distributions, fully Bayesian spatiotemporal modeling, functional magnetic resonance imaging, haemodynamic response function modeling, haemodynamics, half-cosines, matter-type dependence, model selection techniques, nonseparable space-time vector autoregressive process, signal modeling, spatiotemporal noise modeling, spatiotemporal phenomena},
	pages = {213--231}
},

@article{best_comparison_2005,
	title = {A comparison of Bayesian spatial models for disease mapping},
	volume = {14},
	url = {http://smm.sagepub.com/cgi/content/abstract/14/1/35},
	doi = {10.1191/0962280205sm388oa},
	abstract = {With the advent of routine health data indexed at a fine geographical resolution, small area disease mapping studies have become an established technique in geographical epidemiology. The specific issues posed by the sparseness of the data and possibility for local spatial dependence belong to a generic class of statistical problems involving an underlying (latent) spatial process of interest corrupted by observational noise. These are naturally formulated within the framework of hierarchical models, and over the past decade, a variety of spatial models have been proposed for the latent level(s) of the hierarchy. In this article, we provide a comprehensive review of the main classes of such models that have been used for disease mapping within a Bayesian estimation paradigm, and report a performance comparison between representative models in these classes, using a set of simulated data to help illustrate their respective properties. We also consider recent extensions to model the joint spatial distribution of multiple disease or health indicators. The aim is to help the reader choose an appropriate structural prior for the second level of the hierarchical model and to discuss issues of sensitivity to this choice.},
	number = {1},
	journal = {Statistical Methods in Medical Research},
	author = {Nicky Best and Sylvia Richardson and Andrew Thomson},
	month = feb,
	year = {2005},
	pages = {35--59}
},

@article{schlkopf_nonlinear_1998-1,
	title = {Nonlinear Component Analysis as a Kernel Eigenvalue Problem},
	volume = {10},
	url = {http://dx.doi.org/10.1162/089976698300017467},
	doi = {10.1162/089976698300017467},
	abstract = {A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.},
	number = {5},
	journal = {Neural Computation},
	author = {Bernhard Schölkopf and Alexander Smola and {Klaus-Robert} Müller},
	month = jul,
	year = {1998},
	pages = {1299--1319}
},

@article{woolrich_mixture_2005-1,
	title = {Mixture models with adaptive spatial regularization for segmentation with an application to {FMRI} data},
	volume = {24},
	issn = {0278-0062},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15638182},
	abstract = {Mixture models are often used in the statistical segmentation of medical images. For example, they can be used for the segmentation of structural images into different matter types or of functional statistical parametric maps {(SPMs)} into activations and nonactivations. Nonspatial mixture models segment using models of just the histogram of intensity values. Spatial mixture models have also been developed which augment this histogram information with spatial regularization using Markov random fields. However, these techniques have control parameters, such as the strength of spatial regularization, which need to be tuned heuristically to particular datasets. We present a novel spatial mixture model within a fully Bayesian framework with the ability to perform fully adaptive spatial regularization using Markov random fields. This means that the amount of spatial regularization does not have to be tuned heuristically but is adaptively determined from the data. We examine the behavior of this model when applied to artificial data with different spatial characteristics, and to functional magnetic resonance imaging {SPMs.}},
	number = {1},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {Mark W Woolrich and Timothy E J Behrens and Christian F Beckmann and Stephen M Smith},
	year = {2005},
	note = {{PMID:} 15638182},
	keywords = {Algorithms, Artificial Intelligence, Brain, Cluster Analysis, Computer Simulation, Humans, Image Enhancement, Image Interpretation, {Computer-Assisted,} Information Storage and Retrieval, Magnetic Resonance Imaging, Models, Biological, Models, Statistical, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Signal Processing, {Computer-Assisted}},
	pages = {1--11}
},

@article{perez_markov_1998,
	title = {Markov random fields and images},
	volume = {11},
	number = {4},
	journal = {{CWI} Quarterly},
	author = {P. Perez},
	year = {1998},
	pages = {413–437}
},

@article{black_robust_1998-1,
	title = {Robust anisotropic diffusion},
	volume = {7},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0032023715&partnerID=40&md5=0477c34e40276cc920a3ac262ecf524e},
	abstract = {Relations between anisotropic diffusion and robust statistics are described in this paper. Specifically, we show that anisotropic diffusion can be seen as a robust estimation procedure that estimates a piecewise smooth image from a noisy input image. The "edge-stopping" function in the anisotropic diffusion equation is closely related to the error norm and influence function in the robust estimation framework. This connection leads to a new "edge-stopping" function based on Tukey's biweight robust estimator that preserves sharper boundaries than previous formulations and improves the automatic stopping of the diffusion. The robust statistical interpretation also provides a means for detecting the boundaries (edges) between the piecewise smooth regions in an image that has been smoothed with anisotropic diffusion. Additionally, we derive a relationship between anisotropic diffusion and regularization with line processes. Adding constraints on the spatial organization of the line processes allows us to develop new anisotropic diffusion equations that result in a qualitative improvement in the continuity of edges. © 1998 {IEEE.}},
	number = {3},
	journal = {{IEEE} Transactions on Image Processing},
	author = {{M.J.} Black and G. Sapiro and {D.H.} Marimont and D. Heeger},
	year = {1998},
	keywords = {Anisotropic diffusion, Line processes, Robust statistics},
	pages = {421--432}
},

@article{hardoon_unsupervised_2007,
	title = {Unsupervised analysis of {fMRI} data using kernel canonical correlation},
	volume = {37},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4P40KMC-3/2/20228ae0edf6227baff7a4beb0b4412b},
	doi = {10.1016/j.neuroimage.2007.06.017},
	abstract = {We introduce a new unsupervised {fMRI} analysis method based on kernel canonical correlation analysis which differs from the class of supervised learning methods (e.g., the support vector machine) that are increasingly being employed in {fMRI} data analysis. Whereas {SVM} associates properties of the imaging data with simple specific categorical labels (e.g., - 1, 1 indicating experimental conditions 1 and 2), {KCCA} replaces these simple labels with a label vector for each stimulus containing details of the features of that stimulus. We have compared {KCCA} and {SVM} analyses of an {fMRI} data set involving responses to emotionally salient stimuli. This involved first training the algorithm {(SVM,} {KCCA)} on a subset of {fMRI} data and the corresponding labels/label vectors (of pleasant and unpleasant), then testing the algorithms on data withheld from the original training phase. The classification accuracies of {SVM} and {KCCA} proved to be very similar. However, the most important result arising form this study is the {KCCA} is able to extract some regions that {SVM} also identifies as the most important in task discrimination and these are located manly in the visual cortex. The results of the {KCCA} were achieved blind to the categorical task labels. Instead, the stimulus category is effectively derived from the vector of image features.},
	number = {4},
	journal = {{NeuroImage}},
	author = {David R. Hardoon and Janaina {Mourão-Miranda} and Michael Brammer and John {Shawe-Taylor}},
	month = oct,
	year = {2007},
	keywords = {Classifiers, Functional magnetic resonance imaging data analysis, kernel canonical correlation analysis, Machine learning methods, support vector machines},
	pages = {1250--1259}
},

@article{weickert_efficient_1998,
	title = {Efficient and Reliable Schemes for Nonlinear Diffusion Filtering},
	volume = {7},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.34.9979},
	journal = {{IEEE} {TRANSACTIONS} {ON} {IMAGE} {PROCESSING}},
	author = {Joachim Weickert and Bart M. Ter Haar Romeny and Max A Viergever},
	year = {1998},
	pages = {398---410}
},

@article{navarro_universal_1997,
	title = {A Universal density profile from hierarchical clustering},
	volume = {490},
	journal = {The Astrophysical Journal},
	author = {J. F Navarro and C. S Frenk and S. {D.M} White},
	year = {1997},
	pages = {493–508}
},

@article{kulis_semi-supervised_2009-1,
	title = {Semi-supervised graph clustering: a kernel approach},
	volume = {74},
	shorttitle = {Semi-supervised graph clustering},
	number = {1},
	journal = {Machine Learning},
	author = {B. Kulis and S. Basu and I. Dhillon and R. Mooney},
	year = {2009},
	pages = {1–22}
},

@article{friston_multiple_2008,
	title = {Multiple sparse priors for the {M/EEG} inverse problem},
	volume = {39},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-37849032654&partnerID=40},
	abstract = {This paper describes an application of hierarchical or empirical Bayes to the distributed source reconstruction problem in electro- and magnetoencephalography {(EEG} and {MEG).} The key contribution is the automatic selection of multiple cortical sources with compact spatial support that are specified in terms of empirical priors. This obviates the need to use priors with a specific form (e.g., smoothness or minimum norm) or with spatial structure (e.g., priors based on depth constraints or functional magnetic resonance imaging results). Furthermore, the inversion scheme allows for a sparse solution for distributed sources, of the sort enforced by equivalent current dipole {(ECD)} models. This means the approach automatically selects either a sparse or a distributed model, depending on the data. The scheme is compared with conventional applications of Bayesian solutions to quantify the improvement in performance. © 2007 Elsevier Inc. All rights reserved.},
	number = {3},
	journal = {{NeuroImage}},
	author = {K. Friston and L. Harrison and J. Daunizeau and S. Kiebel and C. Phillips and N. {Trujillo-Barreto} and R. Henson and G. Flandin and J. Mattout},
	year = {2008},
	keywords = {automatic relevance determination, Expectation maximization, Free energy, Model selection, Restricted maximum likelihood, Sparse priors, Variational Bayes},
	pages = {1104--1120}
},

@article{guyon_introduction_2003,
	title = {An introduction to variable and feature selection},
	volume = {3},
	url = {http://portal.acm.org/citation.cfm?id=944919.944968},
	abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
	journal = {J. Mach. Learn. Res.},
	author = {Isabelle Guyon and André Elisseeff},
	year = {2003},
	pages = {1157--1182}
},

@book{lazar_statistical_2008,
	title = {The Statistical Analysis of Functional {MRI} Data},
	isbn = {0387781900, 9780387781907},
	publisher = {Springer},
	author = {Nicole A. Lazar},
	year = {2008}
},

@article{zhang_mean_1993,
	title = {The mean field theory in {EM} procedures for blind Markov randomfield image restoration},
	volume = {2},
	number = {1},
	journal = {{IEEE} Transactions on Image Processing},
	author = {J. Zhang},
	year = {1993},
	pages = {27–40}
},

@article{zelnik-manor_self-tuning_2004,
	title = {Self-tuning spectral clustering},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.84.7940},
	journal = {{ADVANCES} {IN} {NEURAL} {INFORMATION} {PROCESSING} {SYSTEMS} 17},
	author = {Lihi Zelnik-manor and Pietro Perona},
	year = {2004},
	pages = {1601---1608}
},

@article{genovese_bayesian_2000,
	title = {A Bayesian {Time-Course} Model for Functional Magnetic Resonance Imaging Data},
	volume = {95},
	issn = {01621459},
	url = {http://www.jstor.org/stable/2669445},
	abstract = {Functional magnetic resonance imaging {(fMRI)} is a new technique for studying the workings of the active human brain. During an {fMRI} experiment, a sequence of magnetic resonance images is acquired while the subject performs specific behavioral tasks. Changes in the measured signal can be used to identify and characterize the brain activity resulting from task performance. The data obtained from an {fMRI} experiment are a realization of a complex spatiotemporal process with many sources of variation, both biological and technological. This article describes a nonlinear Bayesian hierarchical model for {fMRI} data and presents inferential methods that enable investigators to directly target their scientific questions of interest, many of which are inaccessible to current methods. The article describes optimization and posterior sampling techniques to fit the model, both of which must be applied many thousands of times for a single dataset. The model is used to analyze data from a psychological experiment and to test a specific prediction of a cognitive theory.},
	number = {451},
	journal = {Journal of the American Statistical Association},
	author = {Christopher R. Genovese},
	month = sep,
	year = {2000},
	note = {{ArticleType:} primary\_article / Full publication date: Sep., 2000 / Copyright © 2000 American Statistical Association},
	pages = {691--703}
},

@inproceedings{wang_spanbre:efficient_2007,
	address = {Los Alamitos, {CA,} {USA}},
	title = {{SPANBRE:} An Efficient Hierarchical Clustering Algorithm for Spatial Data with Neighborhood Relations},
	volume = {3},
	isbn = {0-7695-2874-0},
	shorttitle = {{SPANBRE}},
	doi = {http://doi.ieeecomputersociety.org/10.1109/FSKD.2007.524},
	abstract = {Due to the attributes of the neighbors are always similar or associated to each other, we address the problem of discovering spatial relationships in spatial data through the identification of clusters based on spatial neighborhood relations. We present an efficient clustering algorithm called {SPANBRE} that generates high quality clusters in O(nlogn) time and in O(n2) message complexity. {SPANBRE} is kind of agglomerative hierarchical method. By using a sequence data structure, {SPANBRE} avoids the complex spatial join operation. {SPANBRE} also execute an optimization strategy for clustering splitting and merging to achieve high clustering quality. The experimental results on traffic flow data sets show that the clustering quality and the algorithm efficiency of {SPANBRE} are superior to other alternative techniques.},
	booktitle = {Fuzzy Systems and Knowledge Discovery, Fourth International Conference on},
	publisher = {{IEEE} Computer Society},
	author = {Yaqin Wang and Yue Chen and Minggui Qin and Yangyong Zhu},
	year = {2007},
	pages = {665--669},
	annote = {Complete {PDF} document was either not available or accessible. Please make sure you're logged in to the digital library to retrieve the complete {PDF} document.}
},

@inproceedings{alzate_sparse_2008,
	title = {Sparse kernel models for spectral clustering using the incomplete Cholesky decomposition},
	isbn = {1098-7576},
	doi = {10.1109/IJCNN.2008.4634306},
	abstract = {A new sparse kernel model for spectral clustering is presented. This method is based on the incomplete Cholesky decomposition and can be used to efficiently solve large-scale spectral clustering problems. The formulation arises from a weighted kernel principal component analysis {(PCA)} interpretation of spectral clustering. The interpretation is within a constrained optimization framework with primal and dual model representations allowing the clustering model to be extended to out-of-sample points. The incomplete Cholesky decomposition is used to compute low-rank approximations of a modified affinity matrix derived from the data which contains cluster information. A reduced set method is also presented to compute efficiently the cluster indicators for out-of-sample data. Simulation results with large-scale toy datasets and images show improved performance in terms of computational complexity.},
	booktitle = {Neural Networks, 2008. {IJCNN} 2008. {(IEEE} World Congress on Computational Intelligence). {IEEE} International Joint Conference on},
	author = {C. Alzate and J. Suykens},
	year = {2008},
	keywords = {approximation theory, computational complexity, constrained optimization framework, dual model representations, incomplete Cholesky decomposition, low-rank approximations, matrix algebra, modified affinity matrix, optimisation, pattern clustering, primal model representations, principal component analysis, reduced set method, set theory, sparse kernel models, Spectral clustering, weighted kernel principal component analysis},
	pages = {3556--3563}
},

@article{wang_gaussian_2008,
	title = {Gaussian Process Dynamical Models for Human Motion},
	volume = {30},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2007.1167},
	abstract = {We introduce Gaussian process dynamical models {(GPDMs)} for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensional motion capture data. A {GPDM} is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, as well as a map from the latent space to an observation space. We marginalize out the model parameters in closed form by using Gaussian process priors for both the dynamical and the observation mappings. This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach and compare four learning algorithms on human motion capture data, in which each pose is 50-dimensional. Despite the use of small data sets, the {GPDM} learns an effective representation of the nonlinear dynamics in these spaces.},
	number = {2},
	journal = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {{J.M.} Wang and {D.J.} Fleet and A. Hertzmann},
	year = {2008},
	keywords = {animation, Gaussian process dynamical model, Gaussian processes, human motion capture data, learning (artificial intelligence), learning model, low-dimensional latent space, Machine learning, Motion, motion estimation, nonlinear time series analysis, stochastic processes, time series, time series analysis, tracking},
	pages = {283--298}
},

@article{list_0.1_2002,
	title = {0.1 Overview references},
	journal = {Reading},
	author = {R. List},
	year = {2002}
},

@article{belkin_consistency_2008,
	title = {Consistency of spectral clustering},
	volume = {36},
	url = {http://projecteuclid.org/DPubS?verb=Display&version=1.0&service=UI&handle=euclid.aos/1205420511&page=record},
	doi = {10.1214/009053607000000640},
	abstract = {Consistency is a key property of all statistical procedures analyzing randomly sampled data. Surprisingly, despite decades of work, little is known about consistency of most clustering algorithms. In this paper we investigate consistency of the popular family of spectral clustering algorithms, which clusters the data with the help of eigenvectors of graph Laplacian matrices. We develop new methods to establish that, for increasing sample size, those eigenvectors converge to the eigenvectors of certain limit operators. As a result, we can prove that one of the two major classes of spectral clustering (normalized clustering) converges under very general conditions, while the other (unnormalized clustering) is only consistent under strong additional assumptions, which are not always satisfied in real data. We conclude that our analysis provides strong evidence for the superiority of normalized spectral clustering.},
	number = {2},
	journal = {The Annals of Statistics},
	author = {Ulrike von Luxburg, Mikhail Belkin and Olivier Bousquet},
	year = {2008},
	pages = {555--586}
},

@article{purdon_locally_2001,
	title = {Locally Regularized Spatiotemporal Modeling and Model Comparison for Functional {MRI}},
	volume = {14},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-457D9PX-1F/2/70d16c7e50ae1cd8bc6e52555869597c},
	doi = {10.1006/nimg.2001.0870},
	abstract = {In this work we treat {fMRI} data analysis as a spatiotemporal system identification problem and address issues of model formulation, estimation, and model comparison. We present a new model that includes a physiologically based hemodynamic response and an empirically derived low-frequency noise model. We introduce an estimation method employing spatial regularization that improves the precision of spatially varying noise estimates. We call the algorithm locally regularized spatiotemporal {(LRST)} modeling. We develop a new model selection criterion and compare our model to the {SPM-GLM} method. Our findings suggest that our method offers a better approach to identifying appropriate statistical models for {fMRI} studies.},
	number = {4},
	journal = {{NeuroImage}},
	author = {Patrick L. Purdon and Victor Solo and Robert M. Weisskoff and Emery N. Brown},
	month = oct,
	year = {2001},
	keywords = {functional {MRI;} regularization; spatiotemporal modeling; system identification; model comparison},
	pages = {912--923}
},

@article{szymkowiak-have_clustering_2006,
	title = {Clustering via kernel decomposition},
	volume = {17},
	issn = {1045-9227},
	doi = {10.1109/TNN.2005.860840},
	abstract = {Spectral clustering methods were proposed recently which rely on the eigenvalue decomposition of an affinity matrix. In this letter, the affinity matrix is created from the elements of a nonparametric density estimator and then decomposed to obtain posterior probabilities of class membership. Hyperparameters are selected using standard cross-validation methods.},
	number = {1},
	journal = {Neural Networks, {IEEE} Transactions on},
	author = {A. {Szymkowiak-Have} and {M.A.} Girolami and J. Larsen},
	year = {2006},
	keywords = {affinity matrix, Aggregated Markov model, eigenvalue decomposition, eigenvalues and eigenfunctions, kernel decomposition, kernel principal component analysis, kernel principal component analysis {(KPCA),} Markov processes, nonparametric density estimator, posterior probabilities, principal component analysis, Spectral clustering, spectral clustering methods, standard cross-validation methods},
	pages = {256--264}
},

@article{van_gerven_efficient_????,
	title = {Efficient Bayesian Multivariate {fMRI} Analysis using a Sparsifying {Spatio-Temporal} Prior},
	volume = {In Press, Accepted Manuscript},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4XV06VX-6/2/eef01f695e8db60cc9492e25923409fc},
	doi = {10.1016/j.neuroimage.2009.11.064},
	abstract = {Bayesian logistic regression with a multivariate Laplace prior is introduced as a multivariate approach to the analysis of neuroimaging data. It is shown that, by rewriting the multivariate Laplace distribution as a scale mixture, we can incorporate spatio-temporal constraints which lead to smooth importance maps that facilitate subsequent interpretation. The posterior of interest is computed using an approximate inference method called expectation propagation and becomes feasible due to fast inversion ofa sparse precision matrix. We illustrate the performance of the method on an {fMRI} dataset acquired while subjects were shown handwritten digits. The obtained models perform competitively in terms of predictive performance and give rise to interpretable importance maps. Estimation of the posterior of interest is shown to be feasible even for very large models with thousands of variables.},
	journal = {{NeuroImage}},
	author = {Marcel {A.J.} van Gerven and Botond Cseke and Floris P. de Lange and Tom Heskes},
	keywords = {Bayesian inference, expectation propagation, logistic regression, multivariate Laplace distribution, Multivariate analysis}
},

@article{roweis_nonlinear_2000,
	title = {Nonlinear dimensionality reduction by locally linear embedding},
	volume = {290},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0034704222&partnerID=40},
	abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding {(LLE),} an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, {LLE} maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, {LLE} is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
	number = {5500},
	journal = {Science},
	author = {{S.T.} Roweis and {L.K.} Saul},
	year = {2000},
	pages = {2323--2326}
},

@article{parati_spectral_1995,
	title = {Spectral analysis of blood pressure and heart rate variability in evaluating cardiovascular regulation: A critical appraisal},
	volume = {25},
	shorttitle = {Spectral analysis of blood pressure and heart rate variability in evaluating cardiovascular regulation},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0029004874&partnerID=40},
	abstract = {Blood pressure variability includes rhythmic and nonrhythmic fluctuations that, with the use of spectral analysis, appear as clear peaks or broadband power, respectively. This review offers a concise and critical description of the spectral methods most commonly used (fast Fourier transform versus autoregressive modeling, time-varying versus broadband spectral analysis) and an evaluation of their advantages and disadvantages. It also provides insight into the problems that still affect the physiological and clinical interpretations of data provided by spectral analysis of blood pressure and heart rate variability. In particular, the assessment of blood pressure and heart rate spectra aimed at providing indexes of autonomic cardiovascular modulation is discussed. Evidence is given that multivariate models-which allow evaluation of the interactions between changes in blood pressure, heart rate, and other biological signals (such as respiratory activity) in the time or frequency domains-offer a more comprehensive approach to the assessment of cardiovascular regulation than that represented by the separate analysis of fluctuations in blood pressure or heart rate only.},
	number = {6},
	journal = {Hypertension},
	author = {G. Parati and {J.P.} Saul and M. Di Rienzo and G. Mancia},
	year = {1995},
	keywords = {autonomic nervous system, blood pressure, heart rate, hypertension, essential, sequence analysis},
	pages = {1276--1286}
},

@article{carbonell_fishers_2009,
	title = {On the Fisher's Z transformation of correlation random fields},
	volume = {79},
	issn = {0167-7152},
	url = {http://www.sciencedirect.com/science/article/B6V1D-4TYR040-1/2/81cb9a8aa30441a6032db086f4c6a32f},
	doi = {10.1016/j.spl.2008.11.007},
	abstract = {One of the most interesting problems studied in Random Field Theory {(RFT)} is to approximate the distribution of the maximum of a random field. This problem usually appears in a general hypothesis testing framework, where the statistics of interest are the maximum of a random field of a known distribution. In this paper, we use the {RFT} approach to compare two independent correlation random {fields,R1} and R2. Our statistics of interest are the maximum of a random field G, resulting from the difference between the Fisher's Z transformation of R1 and R2, respectively. The Fisher's Z transformation guarantees a Gaussian distribution at each point of G but, unfortunately, G is not transformed into a Gaussian random field. Hence, standard results of {RFT} for Gaussian random fields are not longer available for G. We show here that the distribution of the maximum of G can still be approximated by the distribution of the maximum of a Gaussian random field, provided there is some correction by its spatial smoothness. Indeed, we present a general setting to obtain this correction. This is done by allowing different smoothness parameters for the components of G. Finally, the performance of our method is illustrated by means of both numerical simulations and real Electroencephalography data, recorded during a face recognition experimental paradigm.},
	number = {6},
	journal = {Statistics \& Probability Letters},
	author = {F. Carbonell and {K.J.} Worsley and {N.J.} {Trujillo-Barreto}},
	month = mar,
	year = {2009},
	pages = {780--788}
},

@article{woolrich_mixture_2005-2,
	title = {Mixture models with adaptive spatial regularization for segmentation with an application to {FMRI} data},
	volume = {24},
	issn = {0278-0062},
	url = {http://www.ncbi.nlm.nih.gov/pubmed/15638182},
	abstract = {Mixture models are often used in the statistical segmentation of medical images. For example, they can be used for the segmentation of structural images into different matter types or of functional statistical parametric maps {(SPMs)} into activations and nonactivations. Nonspatial mixture models segment using models of just the histogram of intensity values. Spatial mixture models have also been developed which augment this histogram information with spatial regularization using Markov random fields. However, these techniques have control parameters, such as the strength of spatial regularization, which need to be tuned heuristically to particular datasets. We present a novel spatial mixture model within a fully Bayesian framework with the ability to perform fully adaptive spatial regularization using Markov random fields. This means that the amount of spatial regularization does not have to be tuned heuristically but is adaptively determined from the data. We examine the behavior of this model when applied to artificial data with different spatial characteristics, and to functional magnetic resonance imaging {SPMs.}},
	number = {1},
	journal = {{IEEE} Transactions on Medical Imaging},
	author = {Mark W Woolrich and Timothy E J Behrens and Christian F Beckmann and Stephen M Smith},
	year = {2005},
	note = {{PMID:} 15638182},
	keywords = {Algorithms, Artificial Intelligence, Brain, Cluster Analysis, Computer Simulation, Humans, Image Enhancement, Image Interpretation, {Computer-Assisted,} Information Storage and Retrieval, Magnetic Resonance Imaging, Models, Biological, Models, Statistical, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity, Signal Processing, {Computer-Assisted}},
	pages = {1--11}
},

@article{worsley_analysis_1995,
	title = {Analysis of {fMRI} time-series revisited{—}again},
	volume = {2},
	number = {3},
	journal = {Neuroimage},
	author = {K. J. Worsley and K. J. Friston},
	year = {1995},
	pages = {173–181}
},

@article{descombes_spatio-temporal_1998,
	title = {Spatio-temporal {fMRI} analysis using Markov random fields},
	volume = {17},
	issn = {0278-0062},
	doi = {10.1109/42.746636},
	abstract = {Functional magnetic resonance images {(fMRI's)} provide high-resolution datasets which allow researchers to obtain accurate delineation and sensitive detection of activation areas involved in cognitive processes. To preserve the resolution of this noninvasive technique, refined methods are required in the analysis of the data. In this paper, the authors first discuss the widely used methods based on a statistical parameter map {(SPM)} analysis exposing the different shortcomings of this approach when considering high-resolution data. First, the often used Gaussian filtering results in a blurring effect and in delocalization of the activated area. Secondly, the {SPM} approach only considers false alarms due to noise but not rejections of activated voxels. The authors propose to embed the {fMRI} analysis problem into a Bayesian framework consisting of two steps: (i) data restoration and (ii) data analysis. They, therefore, propose two Markov random fields {(MRF's)} to solve these two problems. Results on three protocols (visual, motor and word recognition) are shown for two {SPM} approaches and compared with the proposed {MRF-approach.}},
	number = {6},
	journal = {Medical Imaging, {IEEE} Trans.},
	author = {X. Descombes and F. Kruggel and {D.Y.} Von Cramon},
	year = {1998},
	keywords = {activated area delocalisation, activated voxels, activation areas, Bayesian framework, Bayes methods, biomedical {MRI,} blurring effect, Brain, brain imaging, cognitive processes, data analysis, data restoration, false alarms, functional magnetic resonance imaging, Gaussian filtering, high-resolution data, Markov random fields, medical diagnostic imaging, medical image processing, noninvasive technique, spatio-temporal {fMRI} analysis, statistical parameter map analysis, word recognition},
	pages = {1028--1039}
},

@article{lindeberg_feature_1998,
	title = {Feature detection with automatic scale selection},
	volume = {30},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {T. Lindeberg},
	year = {1998},
	pages = {79–116}
},

@unpublished{bouman_cluster:unsupervised_1997,
	title = {Cluster: An unsupervised algorithm for modeling Gaussian mixtures},
	author = {C. A. Bouman},
	month = apr,
	year = {1997},
	note = {Available from http://www.ece.purdue.edu/{\textbackslash}string bouman}
},

@article{hawkins_using_1989-1,
	title = {Using U Statistics to Derive the Asymptotic Distribution of Fisher's Z Statistic},
	volume = {43},
	issn = {00031305},
	url = {http://www.jstor.org/stable/2685369},
	abstract = {A simple derivation of the asymptotic distribution of Fisher's Z statistic for general bivariate parent distributions F is obtained using U-statistic theory. This method easily reveals that the asymptotic variance of Z generally depends on the correlation ρ and on certain moments of F. It also reveals the particular structure of F that makes the asymptotic variance of Z independent of ρ, and shows that there are many distributions F with this property. The bivariate normal is only one such F.},
	number = {4},
	journal = {The American Statistician},
	author = {D. L. Hawkins},
	month = nov,
	year = {1989},
	note = {{ArticleType:} primary\_article / Full publication date: Nov., 1989 / Copyright © 1989 American Statistical Association},
	pages = {235--237}
},

@article{jain_data_????,
	title = {Data clustering: 50 years beyond K-means},
	volume = {In Press, Corrected Proof},
	issn = {0167-8655},
	shorttitle = {Data clustering},
	url = {http://www.sciencedirect.com/science/article/B6V15-4X66S0V-1/2/f4838cc4cca125ce1f2da8a8e3df0a30},
	doi = {10.1016/j.patrec.2009.09.011},
	abstract = {Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into a system of ranked taxa: domain, kingdom, phylum, class, etc. Cluster analysis is the formal study of methods and algorithms for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is to find structure in data and is therefore exploratory in nature. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty in designing a general purpose clustering algorithm and the ill-posed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection during data clustering, and large scale data clustering.},
	journal = {Pattern Recognition Letters},
	author = {Anil K. Jain},
	keywords = {Data clustering, Historical developments, {King-Sun} Fu prize, Perspectives on clustering, User's dilemma}
},

@inproceedings{liu_boostcluster:_2007-1,
	address = {San Jose, California, {USA}},
	title = {{BoostCluster:} boosting clustering by pairwise constraints},
	isbn = {978-1-59593-609-7},
	shorttitle = {{BoostCluster}},
	url = {http://portal.acm.org/citation.cfm?id=1281192.1281242},
	doi = {10.1145/1281192.1281242},
	abstract = {Data clustering is an important task in many disciplines. A large number of studies have attempted to improve clustering by using the side information that is often encoded as pairwise constraints. However, these studies focus on designing special clustering algorithms that can effectively exploit the pairwise constraints. We present a boosting framework for data clustering,termed as {BoostCluster,} that is able to iteratively improve the accuracy of any given clustering algorithm by exploiting the pairwise constraints. The key challenge in designing a boosting framework for data clustering is how to influence an arbitrary clustering algorithm with the side information since clustering algorithms by definition are unsupervised. The proposed framework addresses this problem by dynamically generating new data representations at each iteration that are, on the one hand, adapted to the clustering results at previous iterations by the given algorithm, and on the other hand consistent with the given side information. Our empirical study shows that the proposed boosting framework is effective in improving the performance of a number of popular clustering algorithms {(K-means,} partitional {SingleLink,} spectral clustering), and its performance is comparable to the state-of-the-art algorithms for data clustering with side information.},
	booktitle = {Proceedings of the 13th {ACM} {SIGKDD} international conference on Knowledge discovery and data mining},
	publisher = {{ACM}},
	author = {Yi Liu and Rong Jin and Anil K. Jain},
	year = {2007},
	keywords = {Boosting, Data clustering, pairwise constraints, Semi-supervised learning},
	pages = {450--459}
},

@article{neill_bayesian_2006,
	title = {A Bayesian spatial scan statistic},
	volume = {18},
	journal = {Advances in Neural Information Processing Systems},
	author = {D. Neill and A. Moore and G. Cooper},
	year = {2006},
	pages = {1003}
},

@article{gssl_bayesian_2001,
	title = {Bayesian modeling of the hemodynamic response function in {BOLD} {fMRI}},
	volume = {14},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-0034973147&partnerID=40},
	abstract = {In functional magnetic resonance imaging {(fMRI),} modeling the complex link between neuronal activity and its hemodynamic response via the neurovascular coupling requires an elaborate and sensitive response model. Methods based on physiologic assumptions as well as direct, descriptive models have been proposed. The focus of this study is placed on such a direct approach that allows for a robust pixelwise determination of hemodynamic characteristics, such as time to peak or the poststimulus undershoot. A Bayesian procedure is presented that can easily be adapted to different hemodynamic properties in question and can be estimated without numerical problems known from nonlinear optimization algorithms. The usefulness of the model is demonstrated by thorough analyzes of the poststimulus undershoot in visual and acoustic stimulation paradigms. Further, we show the capability of this approach to improve analysis of {fMRI} data in altered hemodynamic conditions. © 2001 Academic Press.},
	number = {1 I},
	journal = {{NeuroImage}},
	author = {C. Gössl and L. Fahrmeir and {D.P.} Auer},
	year = {2001},
	keywords = {Bayesian analysis, {FMRI,} Hemodynamic response, {HRF,} {MCMC}},
	pages = {140--148}
},

@article{teh_hierarchical_2006,
	title = {Hierarchical dirichlet processes},
	volume = {101},
	number = {476},
	journal = {Journal of the American Statistical Association},
	author = {Y. W Teh and M. I Jordan and M. J Beal and D. M Blei},
	year = {2006},
	pages = {1566–1581}
},

@article{frey_clustering_2007,
	title = {Clustering by passing messages between data points},
	volume = {315},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-33847172327&partnerID=40},
	abstract = {Clustering data by identifying a subset of representative examples is important for processing sensory signals and detecting patterns in data. Such "exemplars" can be found by randomly choosing an initial subset of data points and then iteratively refining it, but this works well only if that initial choice is close to a good solution. We devised a method called "affinity propagation," which takes as input measures of similarity between pairs of data points. Real-valued messages are exchanged between data points until a high-quality set of exemplars and corresponding clusters gradually emerges. We used affinity propagation to cluster images of faces, detect genes in microarray data, identify representative sentences in this manuscript, and identify cities that are efficiently accessed by airline travel. Affinity propagation found clusters with much lower error than other methods, and it did so in less than one-hundredth the amount of time.},
	number = {5814},
	journal = {Science},
	author = {{B.J.} Frey and D. Dueck},
	year = {2007},
	pages = {972--976}
},

@article{geman_hidden_1995,
	title = {Hidden Markov Random Fields},
	volume = {5},
	url = {http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoap/1177004696},
	abstract = {A noninvertible function of a first-order Markov process or of a nearest-neighbor Markov random field is called a hidden Markov model. Hidden Markov models are generally not Markovian. In fact, they may have complex and long range interactions, which is largely the reason for their utility. Applications include signal and image processing, speech recognition and biological modeling. We show that hidden Markov models are dense among essentially all finite-state discrete-time stationary processes and finite-state lattice-based stationary random fields. This leads to a nearly universal parameterization of stationary processes and stationary random fields, and to a consistent nonparametric estimator. We show the results of attempts to fit simple speech and texture patterns.},
	number = {3},
	journal = {The Annals of Applied Probability},
	author = {Hans Kunsch, Stuart Geman and Athanasios Kehagias},
	year = {1995},
	pages = {577--602}
},

@incollection{chen_spectral_2008,
	title = {Spectral Analysis of {fMRI} Signal and Noise},
	url = {http://dx.doi.org/10.1007/978-4-431-73242-6_4},
	abstract = {We analyzed the noise in functional magnetic resonance imaging {(fMRI)} scans of the human brain during rest. The noise spectrum
in the cortex is well fitted by a model consisting of two additive components: flat-spectrum noise that is uniform throughout
the {MRI} image and frequency-dependent biological noise that is localized to the neural tissue and declines from low to high
temporal frequencies. We show that the frequency-dependent component is well fitted by the f
−p model with 0 {\textless} p {\textless} 1 throughout the measured frequency range. The parameters of the model indicate that the characteristic
noise is not attributable to the temporal filtering of the hemodynamic response but is an inherent property of the blood oxygenation
level-dependent {(BOLD)} signal. We then analyzed the power spectrum of the {BOLD} signal for various cognitive tasks. The signal-to-noise
ratio of a typical {fMRI} experiment peaks at around 0.04 Hz.},
	booktitle = {Novel Trends in Brain Science},
	author = {{Chien-Chung} Chen and Christopher W. Tyler},
	year = {2008},
	pages = {63--76}
},

@inproceedings{nock_grouping_2004,
	title = {Grouping with bias revisited},
	volume = {2},
	isbn = {1063-6919},
	doi = {10.1109/CVPR.2004.1315200},
	abstract = {In this paper, we improve and tailor a recent statistical region merging approach to biased (partially supervised) grouping. The approach appears to be attractive both for its theoretical benefits and its experimental results, as light bias brings dramatic improvements over unbiased approaches on difficult pictures. Comparisons with another biased grouping algorithm display very favorable results.},
	booktitle = {Computer Vision and Pattern Recognition, 2004. {CVPR} 2004. Proceedings of the 2004 {IEEE} Computer Society Conference on},
	author = {R. Nock and F. Nielsen},
	year = {2004},
	keywords = {biased grouping, Graph theory, image segmentation, light bias, pictures, statistical analysis, statistical region merging approach},
	pages = {II--460-II-465 Vol.2}
},

@article{friston_modalities_2009,
	title = {Modalities, Modes, and Models in Functional Neuroimaging},
	volume = {326},
	url = {http://www.sciencemag.org/cgi/content/abstract/326/5951/399},
	doi = {10.1126/science.1174521},
	abstract = {In this, the 21st century, human-brain mapping celebrates 21 years of cognitive activation studies. This review looks at imaging neuroscience and key ideas it has pursued; some ideas portend exciting developments, and others have failed gloriously. In terms of achievements, there is much to celebrate, in the sense that it is difficult to imagine modern neuroscience without brain imaging. I will look at recent advances from the perspectives of functional segregation and integration in the brain, paying special attention to approaches that deal with the distributed and integrated nature of neuronal processing and the questions they address.},
	number = {5951},
	journal = {Science},
	author = {Karl J. Friston},
	month = oct,
	year = {2009},
	pages = {399--403}
},

@article{salvador_undirected_2005,
	title = {Undirected graphs of frequency-dependent functional connectivity in whole brain networks},
	volume = {360},
	url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-25444511408&partnerID=40},
	abstract = {We explored properties of whole brain networks based on multivariate spectral analysis of human functional magnetic resonance imaging {(fMRI)} time-series measured in 90 cortical and subcortical subregions in each of five healthy volunteers studied in the (no-task) resting state. We note that undirected graphs representing conditional independence between multivariate time-series can be more readily approached in the frequency domain than the time domain. Estimators of partial coherency and normalized partial mutual information φ, an integrated measure of partial coherence over an arbitrary frequency band, are applied. Using these tools, we replicate the prior observations that bilaterally homologous brain regions tend to be strongly connected and functional connectivity is generally greater at low frequencies [0.0004, 0.1518 Hz]. We also show that long-distance intrahemispheric connections between regions of prefrontal and parietal cortex were more salient at low frequencies than at frequencies greater than 0.3 Hz, whereas many local or short-distance connections, such as those comprising segregated dorsal and ventral paths in posterior cortex, were also represented in the graph of high-frequency connectivity. We conclude that the partial coherency spectrum between a pair of human brain regional {fMRI} time-series depends on the anatomical distance between regions: long-distance (greater than 7 cm) edges represent conditional dependence between bilaterally symmetric neocortical regions, and between regions of prefrontal and parietal association cortex in the same hemisphere, are predominantly subtended by low-frequency components. © 2005 The Royal Society.},
	number = {1457},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {R. Salvador and J. Suckling and C. Schwarzbauer and E. Bullmore},
	year = {2005},
	keywords = {Coherence, Fourier domain, Graph theory, Multivariate time-series, Network, Neuroimaging},
	pages = {937--946}
},

@article{friston_classical_2002,
	title = {Classical and Bayesian Inference in Neuroimaging: Applications},
	volume = {16},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/B6WNP-4603732-K/2/029818164b29d28edb32402f5d8a6b2e},
	doi = {doi: DOI: 10.1006/nimg.2002.1091},
	number = {2},
	journal = {{NeuroImage}},
	author = {K. J. Friston and D. E. Glaser and R. N. A. Henson and S. Kiebel and C. Phillips and J. Ashburner},
	month = jun,
	year = {2002},
	keywords = {{fMRI;} {PET;} serial correlations; random effects; the {EM} algorithm; Bayesian inference; hierarchical models},
	pages = {484--512}
},

@article{achard_resilient_2006,
	title = {A Resilient, {Low-Frequency,} {Small-World} Human Brain Functional Network with Highly Connected Association Cortical Hubs},
	volume = {26},
	url = {http://www.jneurosci.org/cgi/content/abstract/26/1/63},
	doi = {10.1523/JNEUROSCI.3874-05.2006},
	abstract = {Small-world properties have been demonstrated for many complex networks. Here, we applied the discrete wavelet transform to functional magnetic resonance imaging {(fMRI)} time series, acquired from healthy volunteers in the resting state, to estimate frequency-dependent correlation matrices characterizing functional connectivity between 90 cortical and subcortical regions. After thresholding the wavelet correlation matrices to create undirected graphs of brain functional networks, we found a small-world topology of sparse connections most salient in the low-frequency interval 0.03-0.06 Hz. Global mean path length (2.49) was approximately equivalent to a comparable random network, whereas clustering (0.53) was two times greater; similar parameters have been reported for the network of anatomical connections in the macaque cortex. The human functional network was dominated by a neocortical core of highly connected hubs and had an exponentially truncated power law degree distribution. Hubs included recently evolved regions of the heteromodal association cortex, with long-distance connections to other regions, and more cliquishly connected regions of the unimodal association and primary cortices; paralimbic and limbic regions were topologically more peripheral. The network was more resilient to targeted attack on its hubs than a comparable scale-free network, but about equally resilient to random error. We conclude that correlated, low-frequency oscillations in human {fMRI} data have a small-world architecture that probably reflects underlying anatomical connectivity of the cortex. Because the major hubs of this network are critical for cognition, its slow dynamics could provide a physiological substrate for segregated and distributed information processing.},
	number = {1},
	journal = {J. Neurosci.},
	author = {Sophie Achard and Raymond Salvador and Brandon Whitcher and John Suckling and Ed Bullmore},
	year = {2006},
	pages = {63--72}
},

@article{gardner_unifying_1992,
	title = {A unifying view of coherence in signal processing},
	volume = {29},
	issn = {0165-1684},
	url = {http://www.sciencedirect.com/science/article/B6V18-48XCY87-CW/2/eea94d8b22f1c205d206b127049a13ae},
	doi = {10.1016/0165-1684(92)90015-O},
	abstract = {The concept of coherence is fundamental and quite important in all fields dealing with fluctuating quantities. Although there is a commonality among the many uses of the term coherence, the precise meaning of this term seems to vary from one field to another and even within some fields. The purpose of this tutorial paper is to present a unifying view of the concept of coherence that is particularly relevant to the related fields of statistical signal processing and time-series analysis, which permeate numerous other more specialized fields. Precise mathematical definitions of a variety of types of coherence are given and are related to commonly used physical meanings. A brief survey of methods, which can be implemented with digital signal processing algorithms, for exploiting the various types of coherence that can occur in measurements of fluctuating quantities is presented. Of the three types of coherence - temporal, spectral and spatial - some emphasis is placed on spectral coherence since its use in signal processing has received the least attention in the literature.},
	number = {2},
	journal = {Signal Processing},
	author = {William A. Gardner},
	month = nov,
	year = {1992},
	keywords = {Coherence, correlation, spatial coherence, spectral coherence, temporal coherence},
	pages = {113--140}
},

@book{mukhopadhyay_introductory_2006-2,
	title = {Introductory statistical inference},
	isbn = {1574446134, 9781574446135},
	publisher = {{CRC} Press},
	author = {Nitis Mukhopadhyay},
	year = {2006}
},

@incollection{law_clustering_2004,
	title = {Clustering with Soft and Group Constraints},
	url = {http://www.springerlink.com/content/5x8b5wf4vxvknav2},
	abstract = {Several clustering algorithms equipped with pairwise hard constraints between data points are known to improve the accuracy of clustering solutions. We develop a new clustering algorithm that extends mixture clustering in the presence of (i) soft constraints, and (ii) group-level constraints. Soft constraints can reflect the uncertainty associated with a priori knowledge about pairs of points that should or should not belong to the same cluster, while group-level constraints can capture larger building blocks of the target partition when afforded by the side information. Assuming that the data points are generated by a mixture of Gaussians, we derive the {EM} algorithm to estimate the parameters of different clusters. Empirical study demonstrates that the use of soft constraints results in superior data partitions normally unattainable without constraints. Further, the solutions are more robust when the hard constraints may be incorrect.},
	booktitle = {Structural, Syntactic, and Statistical Pattern Recognition},
	author = {Martin {H.C.} Law and Alexander Topchy and Anil K. Jain},
	year = {2004},
	pages = {662--670}
},

@article{weickert_efficient_1998-1,
	title = {Efficient and reliable schemes for nonlinear diffusion filtering},
	volume = {7},
	number = {3},
	journal = {{IEEE} Transactions on Image Processing},
	author = {J. Weickert and B. Romeny and M. A Viergever and others},
	year = {1998},
	pages = {398–410}
}