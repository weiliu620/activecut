% Template for ISBI-2012 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{amssymb}

%% % For algorithms
%% \usepackage{algorithm}
%% \usepackage{algorithmic}

%% % For text color
%% \usepackage{color}
%% \usepackage{multirow}
%% \usepackage{tabu}

% for table
\usepackage{multirow}

\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\mat}[1]{\text{\bf #1}}

% Title.
% ------
\title{Active cut based 4D pathological anatomy modeling:
 A TBI imaging study}
%% \title{Traumatic Brain Image Segmentation: An Active Learning Approach}
%
% Single address.
% ---------------
\name{Bo Wang$^{\dag,\ddag}$, Wei Liu$^{\dag,\ddag}$, Marcel
  Prastawa$^{\dag,\ddag}$, Andrei Irimia$^{\S}$, \vspace*{-1.5ex}}

\nameLots{Paul M. Vespa$^{\natural}$, John D. van Horn$^{\S}$, P. Thomas
  Fletcher$^{\dag,\ddag}$, Guido Gerig$^{\dag,\ddag}$\vspace*{-1ex}\sthanks{
    Supported by grants: National Alliance for Medical Image Computing (NA-MIC)
    U54 EB005149 (GG) and the Utah Science Technology and Research (USTAR)
    initiative at the University of Utah.  }}
%This work is part of the National Alliance for Medical Image Computing (NAMIC),
%funded by the National Institutes of Health through the NIH %Roadmap for
%Medical Research, Grant U54 EB005149.

\address{
\begin{tabular}{cc}
$^{\dag}$ Scientific Computing and Imaging Institute, &
$^{\S}$ Institute for Neuroimaging and Informatics, USC \\
$^{\ddag}$ School of Computing, University of Utah & $^{\natural}$ Brain Injury Research Center, UCLA
\end{tabular}
}

\begin{document}

%
\maketitle
%
\begin{abstract}
% we need to rewrite the abstract so it is more concise. We just begin with 'We
% propose a ...'.
%% Recently graph cuts based image segmentation methods have been successfully
%% applied to computer vision and medical imaging fields.  The user-interactive
%% nature of these methods allow user to iteratively refine the current
%% segmentation to improve the result. However, without any guidance or suggestion
%% from the algorithm itself, the user interaction can be viewed as a passive
%% process and it can take much longer time to get a user desired result. Moreover,
%% most of the time, graph cuts based methods are designed to segment single object
%% in the image/volume which is not appropriate to multi-object segmentation. Some
%% researchers have proposed to use active learning to make suggestion to users at
%% each iteration of the graph cuts based algorithm. However, the framework only
%% works for single object segmentation which is difficult to extend to the
%% multi-object scenario. In the paper, we propose a unified framework to integrate
%% active learning to graph cuts algorithm for multi-object segmentation tasks. To
%% enforce the smoothness of the segmentation, we use both MRF and spatial priors
%% (in the case we have).
4D pathological anatomy modeling is a challenging problem due to the difficulties
of localizing multiple lesions across time points and estimating deformations between
time points.
We proposed a novel semi-supervised method, called \emph{active-cut}, to solve the problem of longitudinal
pathological data labeling, and estimate the deformations based on the labeling result.
Unlike standard GrabCut algorithm that passively waits for user to refine the segmentation map which is
difficult and time-consuming to perform in 3D space. In our method, we use the active learning technique where
the algorithm actively selects the candidate regions for querying the user,
and user simply answers `yes' or `no' to a candidate
object instead of refining the map slice by slice. Moreover, our method is able to detect
multiple lesion regions unlike GrabCut which is for single object task.
Based the result of active-cut, we estimate mappings from a health template to each time point for 4D modeling.
The results show significant performance gain using our framework for modeling 4D pathological anatomy.
%and we obtain smooth segmentation maps and submit
%spatially-coherent objects for querying users by using Markov random field.
%The statistical inference problem is solved by graph cuts and variational inference
%methods. The results show significant performance gain with a few user
%involvement.

%% The significant performance gain in the labeling imporves the following
%% estimations of the mapplings from health template to each time point for 4D
%% modeling.
\end{abstract}
%
\begin{keywords}
active learning, graph cuts, longitudinal MRI, Markov Random Fields,
semi-supervised learning, \end{keywords}
%

\section{Introduction}
\label{sec:intro}

% This paragraph need revision.
Longitudinal (4D) pathological data set such as traumatic brain injury (TBI), autism, and Huntington's disease
is important for analysis of pathology and recovery to measure treatment efficacy or make predictions.
Therefore, 4D pathological anatomy modeling is essential to make sense of the complex 4D pathological data
and enables other analysis such as structural pathology \cite{Irimia2012} and brain connectivity \cite{irimia2013structural}. It is a challenge because of the difficulties
of localizing multiple lesions in individual time points and estimating deformations between
time points. To make it worse, both segmentation and registration problems depends on each other.
In the case of MR image segmentation of severe TBI patients, it is challenging due to its
multiple lesions, multi-modalities, and lack of prior knowledge of lesions'
location.
%The state-of-art image segmentation algorithms often fail to find the
%true lesions, with high false-positive rate for single lesion detection, and
%high false-negative rate in multiple lesion detection.

%However, for TBI images, a standalone algorithm
%such as graph cuts could not achieve good results without a human expert's
%involvement.
%We note a little user input at the right time and right place can
%significantly improve the algorithm's performance.
In computer vision and medical imaging fields, graph cuts based
user-interactive image segmentation methods have been applied to 2D/3D data \cite{boykov2001fast,rother2004grabcut}.
In particular, GrabCut method~\cite{rother2004grabcut} integrates human experts' knowledge and the
algorithm's computation power. In GrabCut, one typically gives an initial guess
of the region of interest (foreground), for example a bounding box. The algorithm estimates
an globally optimal boundary between the foreground and background regions. The user
then inspects the segmentation results, and adjusts the boundary by drawing a
region as a hard constraint. Such process works well on two dimensional natural
images, as human being can usually quickly find the incorrectly classified
regions. However, it is a huge burden to users once
applied on 3D volume data, since one has to visually inspect each slice and
correct it. The crux is the process is entirely based on user's active
inspection and correction. The algorithm is in a \emph{passive learning} state,
taking whatever the user gives as input. Therefore, the user has to take the
responsibility of looking for possible multiple objects, and the GrabCut
algorithm just refines the boundaries of the candidate objects. This passive
learning process is the bottleneck of the GrabCut algorithm when applied in
3D data.

% existing algorithm's issue: large false positive.

% Motivate our methods. active learning, multiple objects, MRF prior, query
% score, low false positive, low user interaction workload. Global optimum
% (graphcuts).

In this work we propose a new method that uses active learning technique for
interactive segmentation of the TBI images. We adopt a minimalist's philosophy
such that our algorithm need the least amount of user's involvement. By active
learning, the algorithm queries the user only on the most important data
point. As a result, the user's response to such query will be the most
informative, and the number of user interaction is minimized before the
algorithm reaches certain estimation accuracy. Even better, the algorithm has
the potential of automatically classifying the unlabeled data without user's
input, and re-learn the model based on the updated labeled data.  This
self-training further decrease the user involvement, without losing segmentation
accuracy. We refer the proposed algorithm as \emph{active-cut}.

Another contribution of work is the algorithm is able to detect multiple
lesions. Standard graph cut algorithm~\cite{rother2004grabcut} only detects
single object. Our active-cut algorithm learns the model from a simple user
initialization, find the candidate objects and submit to user for
inspection. The user is now in an passive state, by just answering a `yes' or
`no' question to the queried candidates. The active-cut algorithm does the
remaining work including refining the candidate objects, learning model
parameters and running graph cut algorithm for a globally optimal map.

A third contribution of our work is the introduction of the spatial context
constraints by Markov random field (MRF). Besides the energy term of the graph
cut's objective function to get smooth boundary between normal and abnormal
regions, we also define a MRF prior on label variables within the normal and
abnormal class. The estimated label maps within both classes will be piecewise
constant. We also define the MRF prior on the candidate objects submitted to the
user, so the candidates are spatially coherent objects instead of single voxels.

% some related work. and compare them with ours, to show ours is better! If
% space is limited, we may need to split this paragraph into small pieces and
% plug into previous paragraph.
Several researchers have applied active learning to image segmentation
\cite{top2011active,iglesias2011combining,veeraraghavan2011active}.
Veeraraghavan et al.\cite{veeraraghavan2011active} use grow cut for segmentation
and estimates the uncertainty by support vector machine classifier. We are
different from their methods in that instead of learning new voxels, our method
learn the new objects because of their better fit for human visual perception.

In the remaining part of the paper, we discuss the model and processing pipeline
in section \ref{sec:method}, give the segmentation results in section
\ref{sec:results} and conclude in \ref{sec:conc}.


%% algorithm in
%% which segmentation is performed by grow cut and uncertainty of segmentation is
%% estimated by support vector machine to give suggestion to user. The drawbacks of
%% this method are: the segmentation and uncertainty estimation are separated, the
%% algorithm is for single object segmentation, and the suggestion for user are
%% pixels which are not informative and not compact.  We propose a new objective
%% function for both graph cuts segmentation and uncertainty estimation for active
%% learning which naturally put both components into one unified framework.

\section{Method}
\label{sec:method}
\subsection{Graph Cuts Segmentation}
Following GrabCut~\cite{rother2004grabcut}, we build two mixture of Gaussian
(GMM) models for the normal brain regions and the lesions, and use the
expectation maximization (EM) method to estimate both the class labels and the
model parameters $\theta$. In the graph cut step, the algorithm takes model
parameters of both GMMs as input, and estimates a hard label $\alpha \in \{0,
1\}$ representing if each voxel $n$ is normal ($\alpha_n =0 $) or lesions
($\alpha_n = 1$). Besides the smoothness
constraint on the lesion boundary, we also apply MRF constraints on the label
maps within normal and lesions. This soft constraint guarantee the estimated
labels is smooth.

\noindent \textbf{Within-Class MRF and Variation Inference}: Define the label map $\mat z = \{\vec z_1,
\dots, \vec z_N\}$, where $\vec z_n$ is a K dimensional binary random variable
for voxel $n$ such that $\sum_k \!z_{nk} \!=\! 1$. A particular element
$z_{nk}\!=\!1$ indicates voxel $n$ is in Gaussian component $k$. The prior
distribution of $\mat z$ takes into account the MRF constraints as well as the
atlas, and is defined as
\begin{equation*}
  p(\mat z) = \frac{1}{C} \exp( \sum_{n=1}^N \sum_{k=1}^K z_{nk} \log \pi_{nk} + \beta \sum_{(n,m)} \langle \vec z_n, \vec z_m \rangle ),
\end{equation*}
where $\pi_{nk}$ is the affine-registered atlas prior probability of $n$ being
in component $k$, $(n, m)$ is pair of neighboring voxels, and $\langle, \rangle$
is the inner product of two vectors, representing our preference of piecewise
constant label map, with the constraint strength given by $\beta$. Given $\vec
z_n$, the likelihood function is defined as multivariate Gaussian $p(\vec x_n |
\vec z_n) = \mathcal{N}(\vec x_n; \theta(\vec z_n))$, with $\vec x_n$ the
observed data vector of the multi-modality images at $n$. In EM, one need to
evaluate $\mathbb{E}_{P(\mat z |\mat x)} [\log p(\mat x, \mat z)]$, which is
intractable due to the MRF prior on $\mat z$. Here we use the variational
inference method that iteratively updates $p(\vec z_n|\vec z_{\mathcal{N}(n)},
\vec x_n)$ given the expected value of $\vec z_n$'s neighbors
$\mathcal{N}(n)$. The update equation takes the form
\begin{equation*}
  \log p(z_{nk}) = z_{nk} \pi_{nk} + \!\!\!\!\! \sum_{m\in \mathcal{N}(n)} \!\!\!\langle \overline {\vec z}_m, \vec z_n \rangle + \log \mathcal{N} (\vec x_n; \theta(\vec z_n)),
\end{equation*}
where $\overline {\vec z}_m$ is the expected value at neighbor $m$. We
compute $\log p(z_{nk})$ for all $k$ and compute $p(\vec z_n)$ by taking
exponential and normalize. $\overline{z}_n$ is just $p(\vec z_n)$ for binary
variables and is used for updating $\vec z_n$'s neighbors. In M step, we
use $\mat z$ to estimate $\theta = \{\mu, \Sigma\}$ for all components. The
variational procedure stops when no $\vec z_n$ changes. Given $\alpha$, EM runs
on both GMM separately, with a uniform atlas map on lesion's GMM.

%% \noindent \textbf{Graph Cuts global optimization: }We define the objective
%% function of graph cuts optimization as
%% % possible to move two energy term in to text. Just keep E(alpha) here.
%% \begin{align*}
%%   &\mat E(\alpha) = \gamma \sum_{(m,n)} \psi(\alpha_n, \alpha_m) \exp \left ( -\beta_0 \| \vec x_n - \vec x_m\|^2 \right ) +\\
%%   & \sum_n^N \mathbb{E}_{p(\mat z|\mat x)} \log p(\vec x_n, \vec z_n; \theta (\alpha)),
  %% &\mathbb{E}_{p(\mat z|\mat x)} \log p(\vec x, \vec z; \theta (\alpha_n)) = \!\!\sum_{k=1}^K \!z_{nk}(\log \pi_{nk} \!+\! \log \mathcal{N}(\vec x_n; \theta(\alpha_n))) \!+\!  \beta \!\!\!\!\!\!\sum_{m \in \mathcal{N}(n)} \!\!\!\!\!\langle \vec z_n, \!\vec z_m\rangle \!-\! \log C \!\!\!\!,
%% \end{align*}
%% where $\psi = 1$ if $\alpha_n \neq \alpha_m$, otherwise $\psi = 0$, and
%% $\beta_0$ is estimated from data by taking expectation over image
%% sample~\cite{boykov2001fast,rother2004grabcut}. The smoothness constraint
%% depends on the data term, so it is a conditional random field. When building the
%% graph, we set the T-link by the second term, and the N-link by the first term in
%% the above equation.


%-------------------------------------------------------------------------
%\subsection{Active Learning New Object}
\subsection{Active-cut based 4D Pathological Anatomy Modeling}

% Gives a short intro of active learning with (just one) reference. Why active
% learning, benefit. How that works in general. Then talk about our
% strategy. Need to mention self-training (automatically add unlabeled data into
% labeled dataset, thus decreasing user interaction/burden).

%% We use graph cuts~\cite{rother2004grabcut} to update the voxel's $\alpha$ value
%% within the bounding box. Once the EM and graph-cut converges, the algorithm
%% enters into the active-learning step. In the graph-cut, we do not move the
%% voxels in normal region into the lesions in order to control the false positive
%% detection.

In the active learning step, the algorithm take the $\alpha$ and $\theta$ as
input, and computes the probability of each voxel in the normal region belonging
to the lesions. It then builds a connected component map, since such a
high-level object-based representation is convenient for user interaction. We
sort the multiple objects in a descending order of the probability of being in
the lesion regions, and submit the top object for user to query. Even better,
when the algorithm believes the top object should be in the lesion with
sufficient confidence, it adds the object into lesion in a self-training process
without querying users, hence further reducing the user involvement.

% How the query score are computed. (LW will add stuff here)
\noindent\textbf{Query Score: }The log-odds of $\alpha$ is defined as
\begin{align*}
  a = \log p(\alpha=1) + \mathbb{E}_{p(\vec z_n|\vec x_n)} \log p(\vec x_n, \vec z_n; \theta (\alpha=1))\\
  - \log p(\alpha=0) + \mathbb{E}_{p(\vec z_n|\vec x_n)} \log p(\vec x_n, \vec z_n; \theta (\alpha=0)),
\end{align*}
where the $p(\alpha)$ is assumed to be a MRF. The predictive probability of a
voxel being in lesion is computed by the standard logistic function
$p(\alpha_n=1|\vec x_n) = 1/ (1 + \exp (-a))$. We obtain a binary map $\vec w$
by thresholding the predictive map at 0.5, and identify a series of objects
$R_i$ by running a connected component routine on $\vec w$. To further select
the most salient objects, we sort the objects in decending order of the
following score:
\begin{align}
q(R_i) = \sum_{n\in R_i} p(\alpha = 1| \vec x_n) / \vert\{n: n\in \mathcal{B}(R_i) \}\vert
\label{eq:score}
\end{align}
The $\mathcal{B}(R)$ is the set of voxels on the boundary of $R$, and the
denominator denotes the number of voxels on the boundary of $R_i$. The above
query score prefers objects with larger volumes of posterior probability. The
score also prefers blob-like objects since such object has large volume-surface
ratio. Such criteria reflects our prior knowledge on the lesion object's shape.

% parameters empirically chosen, but not have big impact on results. Need to say
% that!


% partially initialized lesion region/objects can be recovered later by
% self-training/act-learning. Need to show that!
% Using the likelihood estimated using acCut for 4D modeling pathological
% anatomy which follows the MBIA paper.
\noindent\textbf{4D Modeling Pathological Anatomy: }
%% After estimating the data
%% likelihood by using the fixed prior and user interaction, we then fix the data
%% likelihood to update the prior to compute deformations from a healthy template
%% to each time point and mappings between time points. This follows the 4D
%% pathological anatomy modeling framework of Wang et al. \cite{WangMBIA2013}.  The
%% estimated likelihood, $p(\vec x_n | \vec z_n)$, can be plugged into the data
%% functional which is,
%% \begin{equation*}
%% \mathcal{F}(A, \phi_t, Q_t) = - \sum_{t=1}^T \, \sum_{n=1}^N \, \log \, ( \, \sum_{k=1}^K \pi_{nk}^t \, p(\vec x_n | \vec z_n) \, )
%% \end{equation*}
%% where the spatial prior $\pi_{k}^t = A^k \circ \phi_t + Q_t^k$, and $A$ is the
%% tissue class probability that is initially associated with the healthy template,
%% $\phi_t$ is the diffeomorphic deformation from time $t$ to the atlas, and $Q_t$
%% is the non-diffeomorphic probabilistic change for time $t$.  Alternating
%% gradient descent is used to update these parameters.
After the active-cut converges, we take the $\mat z$ and $\theta$ for both
normal and lesion classes as input, and estimate the atlas prior $\pi$ by
computing the deformaton from the healthy template to the images at each time
point. We follow the 4D pathological anatomy modeling framework of Wang et
al. \cite{WangMBIA2013}, and define $\pi_{k,t} = A_k \circ \phi_t + Q_{k,t}$,
where $A$ is the tissue class probability that is initially associated with the
healthy template, $\phi_t$ is the diffeomorphic deformation from time $t$ to the
atlas, $Q_t$ is the non-diffeomorphic probabilistic change. We use alternating
gradient descent to estiamte $A$, $\phi_t$ and $Q_t$ by optimizing
$\mathcal{F}(A, \phi_t, Q_t) = - \sum_{t=1}^T \mathbb{E}_{p(\mat z| \mat
  x)}[\log p (\mat z, \mat x| \theta, \pi_t)]$.

\begin{figure} [ht]
\centering
%% \includegraphics[width=8.5cm]{./figures/acLearn_flowchart}
\includegraphics[width=0.479\textwidth]{./figures/acLearn_flowchart}
\caption{Flowchart of the proposed algorithm.}
\label{fig:flowchart}
\end{figure}

% Give a summary of the pipeline. and give reference of pipeline's figure.
\noindent\textbf{Processing Pipeline: } With all the setting above, the learning
pipeline is given in Fig. \ref{fig:flowchart}. Given the bounding box from
user, we initialize the $\alpha$ map such that $\alpha = 1$ (lesion) within the
bounding box, and $\alpha = 0$ outside. The GMM learns $\theta$ of both GMMs
given $\alpha$, then a graph-cut step~\cite{rother2004grabcut} updates only the
$\alpha$ for voxels within the box. This update strategy of graph-cuts prevents
false-positive detections. Upon EM + graph cuts convergence, there may be some
false-negative voxels outside the box. We group these voxels into spatially
coherent objects and find the one with highest score computed from
\eqref{eq:score}. The algorithm either automatically add the candidate to
lesions or queries user for answer, depending on its confidence on the
candidate. We then update the hard-constraint map to reflect the knowledge
learned from the new object, and a new EM + graph cuts iteration starts. The
alredy accepted or rejected objects inprevious step are recorded so they will be
excluded from the query list next time. This learning process repeats until user
stops. Finally, we run this active-cut algorithm on the longitudinal datasets of
both time points and run 4D pathological anatomy modeling.


\section{Results}
\label{sec:results}
We applied our method to a data set of longitudinal multimodal MR images of four
severe TBI patients.  Each subject was scanned twice, an acute scan at about 5
days and another chronic scan at about 6 months post injury. Each subject's data
includes T1, T2, FLAIR, and GRE. For lesions' GMM model, we choose $K=2$ for
bleeding and edema component, and for normal regions we choose $K=3$ for gray
matter, white matter and CSF. We take 6 neighborhood system and choose the
smoothness parameter $\gamma = \beta = 1$. The image intensity of each modality
is normalized to the range [0, 255] before the learning process. We also run
K-Means 5 times with different initialization, and use the K-Means clustering
and the atlas prior to initialize the GMM.

\begin{figure} [ht]
\centering
\includegraphics[width=0.479\textwidth]{./figures/iterative_process}
\caption{Illustration of the iterative process of active-cut on subject
  I. Iteration 1: User-initialized bounding box. Iteration 2: Self
  training. Iteration 3 and 4: Active learning.  User stoped the process at 5th
  iteration. Arrows point to the changes between iterations. White matter
  surface is visualized in all figures as reference.
%Iteration 2 is self training, one candidate patch was added directly to update hard constraint;
%Iteration 3 is active learning, one candidate patch was rejected and a second candidate patch
%was accepted by user;
%Iteration 4 is also active learning, two candidate patches were rejected and a third candidate patch
%was accepted.
%The fifth iteration is not shown because user chose 'stop' to stop the active learning.
}
\label{fig:userinter}
\end{figure}

% This paragraph give some procedure, which should be in the previsou method
% section. This is just fore result.
Fig.~\ref{fig:userinter} shows the dynamic learning process of subject I. In
iteration 1, given the user initialized bounding box, active-cut successfully
detected the lesion object, as shown in the bottom $\alpha$ map. In iteration 2,
the candidate object has a large query score, so the algorithm decided to do
self training and added the candidate to the lesion class. This object is indeed
part of the lesion in the previous bounding box. That shows when the user leaves
a portion of the lesion outside the box, the algorithm still detects the
misssing portion. This result shows the robustness of the algorithm given
inaccurate user initialization. In iteration 3 and 4, user rejected some
candidate objects and accepted some others.  The accepted objects are not
connected to the major lesion but our algorithm still captured them. This result
shows that acive-cut is able to detect multiple objects. We also noted by
using volume, precditive probability and shape information, most of the
top-ranked candidates are indeed true positive ones, thus proving the effectness
of our query score.

\begin{figure} [ht]
\centering
\includegraphics[width=0.479\textwidth]{./figures/qualitative_comp}
\caption{Comparision of the baseline GrabCut method with the proposed active-cut
  method. Left: active-cut in 3D space and axial view. Right: GrabCut. Light
  blue: edema. Brown: bleeding. Note the large false-positive detection of
  GrabCut at the CSF region.}
\label{fig:QualComp}
\end{figure}

\begin{table} [ht]
%\begin{center}
\centering
\begin{tabular}{c|cc|cc|c}
\hline
 &  \multicolumn{2}{c}{Baseline} &  \multicolumn{3}{|c}{Active-cut}\\
\cline{2-6}
\multirow{1}{*}{Subject}  & NHL & HL & NHL & HL & UI\\

I  & 0.2503 & 0.0613  & 0.6349 & 0.5698 & 5\\ %\hline
II & 0.3269 & -  & 0.6910 & -   & 4 \\ %\hline
III  & 0.1311 & 0.2288   & 0.4512 & 0.4840 & 6 \\ %\hline
IV   & 0.0918 & 0.0998   & 0.3503 & 0.1153 & 5 \\ \hline
\end{tabular}
\caption{ Dice values comparing active-cut and and baseline methods to ground
  truth. HL and NHL are acute hemorrhagic and non-hemorrhagic lesions. UI
  denotes the number of interaction user performed using active-cut. Subject II
  has no ground truth for HL due to the lack of GRE.}
\label{tab:DiceResult}
\end{table}

In order to show the efficacy of the proposed method, we used the GrabCut
without user interaction as a baseline method and also allowed $\alpha$ outside
of the bounding box to switch labels in order to detect multiple lesion objects.
Fig.~\ref{fig:QualComp} shows the qualitative comparison of the baseline method
and the active-cut. Without user interaction, the baseline aglorithm detected a
large number of false-positive voxels due to the ambiguity between the lesion
and CSF. Table~\ref{tab:DiceResult} shows the quantitative comparison of both
methods. The proposed method is able to significantly improve the
segmentation. Smart and efficient user-interactive method gives us better result
\textemdash this is the rationale behind the proposed algorithm.


After active-cut, we updated the atlas prior by using the 4D modeling
method~\cite{WangMBIA2013}.  Fig.~\ref{fig:Deform} shows that parcellation
mapped to the space of each time point by using the estimted deformation
field. The result shows that with good segmentation of active-cut, the warped
parcellation captured the large-deformed ventricular system at both time
points. Because the mapping of the parcellation labels to individual time points
is a crucial step of the connectivity analysis of pathological brain with
longitudinal data~\cite{irimia2013structural}, our integrated framework has the
potential of being used in such study.

%% The estimated deformations $\phi_t$ can be used to map the parcellation label
%% associated with the healthy template to each time point.

\begin{figure} [ht]
\centering
\includegraphics[width=0.479\textwidth]{./figures/parcellation}
\caption{Result of mapping parcellation label associated with the healthy
  template to each time point. Left two images are acute T1 reference image and
  mapped parcellation, right two are chronic result.}
\label{fig:Deform}
\end{figure}


\section{Conclusions}
\label{sec:conc}
We presented an active-learning framework for 4D pathological anatomy
modeling. The algorithm can detect multiple lesion objects with little user
input. The MRF prior ensures the smooth label maps within class and within
candidates. Future work includes re-estimation of the model with updated atlas
prior, and application to other pathological data.

%% Our method actively recommend spatial coherent candidate to users. Second, our
%% algorithm is able to capture multiple objects which is common is severe TBI case
%% but the standard GrabCut is designed for single object. By taking the rough
%% bounding box into account, integrating different features of candidate patch,
%% and keeping track of the user interaction, our algorithm is able to make the
%% user interaction easy, robust and efficiently to segment multiple lesions. Both
%% quantitative and qualitative results show that our method is able to improve
%% segmentation significantly and therefore improve the following 4D modeling.

\bibliographystyle{IEEEbib}
\bibliography{strings,refs}
\end{document}
