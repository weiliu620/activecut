% Template for ISBI-2012 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}
\usepackage{amssymb}

%% % For algorithms
%% \usepackage{algorithm}
%% \usepackage{algorithmic}

%% % For text color
%% \usepackage{color}
%% \usepackage{multirow}
%% \usepackage{tabu}

% for table
\usepackage{multirow}

\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\mat}[1]{\text{\bf #1}}

% Title.
% ------
\title{Active learning based Graphcuts segmentation for modeling pathological
  anatomy: A study on TBI imaging }
%% \title{Traumatic Brain Image Segmentation: An Active Learning Approach}
%
% Single address.
% ---------------
\name{Bo Wang$^{\dag,\ddag}$, Wei Liu$^{\dag,\ddag}$, Marcel
  Prastawa$^{\dag,\ddag}$, Andrei Irimia$^{\S}$, \vspace*{-1.5ex}}

\nameLots{Paul M. Vespa$^{\natural}$, John D. van Horn$^{\S}$, P. Thomas
  Fletcher$^{\dag,\ddag}$, Guido Gerig$^{\dag,\ddag}$\vspace*{-1ex}\sthanks{
    Supported by grants: National Alliance for Medical Image Computing (NA-MIC)
    U54 EB005149 (GG) and the Utah Science Technology and Research (USTAR)
    initiative at the University of Utah.  }}
%This work is part of the National Alliance for Medical Image Computing (NAMIC),
%funded by the National Institutes of Health through the NIH %Roadmap for
%Medical Research, Grant U54 EB005149.

\address{
\begin{tabular}{cc}
$^{\dag}$ Scientific Computing and Imaging Institute, &
$^{\S}$ Institute for Neuroimaging and Informatics, USC \\
$^{\ddag}$ School of Computing, University of Utah & $^{\natural}$ Brain Injury Research Center, UCLA
\end{tabular}
}

\begin{document}

%
\maketitle
%
\begin{abstract}
% we need to rewrite the abstract so it is more concise. We just begin with 'We
% propose a ...'.
%% Recently graph cuts based image segmentation methods have been successfully
%% applied to computer vision and medical imaging fields.  The user-interactive
%% nature of these methods allow user to iteratively refine the current
%% segmentation to improve the result. However, without any guidance or suggestion
%% from the algorithm itself, the user interaction can be viewed as a passive
%% process and it can take much longer time to get a user desired result. Moreover,
%% most of the time, graph cuts based methods are designed to segment single object
%% in the image/volume which is not appropriate to multi-object segmentation. Some
%% researchers have proposed to use active learning to make suggestion to users at
%% each iteration of the graph cuts based algorithm. However, the framework only
%% works for single object segmentation which is difficult to extend to the
%% multi-object scenario. In the paper, we propose a unified framework to integrate
%% active learning to graph cuts algorithm for multi-object segmentation tasks. To
%% enforce the smoothness of the segmentation, we use both MRF and spatial priors
%% (in the case we have).
We proposed a novel semi-supervised method for segmentation of longitudinal
traumatic brain injury images with multiple lesion regions. Standard GrabCut
algorithm passively wait for user to refine the segmentation map. This is
difficult in 3D space. In our method, we use the active learning technique where
the algorithm actively selects the candidate regions for querying the user, and
obtains the most informative user feedback. The active learning also releases
the user's burden since the user simply answers `yes' or `no' to a candidate
object instead of refining the map slice by slice. Our method is able to detect
multiple lesion regions, and we obtain smooth segmentation maps and submit
spatially-coherent objects for querying users by using Markov random field. The
statistical inference problem is solved by graph cuts and variational inference
methods. The results show significant performance gain with a few user
involvement.
\end{abstract}
%
\begin{keywords}
active learning, graph cuts, longitudinal MRI, Markov Random Fields,
semi-supervised learning, \end{keywords}
%

\section{Introduction}
\label{sec:intro}

% This paragraph need revision.
Graph cuts based user-interactive image segmentation methods have been
successfully applied to computer vision, computer graphics, and medical imaging
fields \cite{boykov2001fast,rother2004grabcut}. For some complex images, a
standalone computer algorithm can not achieve good segmentation without a human
expert's involvemnet. GrabCut method~\cite{rother2004grabcut} integrates human
experts' knowledge and the algorithm's computatoin power. In GrabCut, one
typically gives an initial guess of the region of interest, for example a
bounding box. The algorithm estimates an globally optimal boundary between the
foreground and background regions. The user then inspects the segmentation
results, and adjust the boundary by drawing a region as a hard constraint. Such
process works well on two dimensional natural images, as human being can usually
quickly find the incorrectly classified regions. However, the process will be a
significant burden in 3D volume image since the user has to visually inspect
each slice and correct it. One reason of such a burdening interaction process is
the process is entirely based on user's active inspection and correction. The
algorithm is in a \emph{passive learning} state, taking whatever the user gives
as input. Therefore, the user has to take the responsibility of looking for
possible multiple objects, and the GrabCut algorithm refines the boundaries of
the candidate objects. This passive learning process is the bottle network of
the GrabCut algorithm when applied in 3D data.

% existing algorithm's issue: large false positive.

% Motivate our methods. active learning, multiple objects, MRF prior, query
% score, low false positive, low user interaction workload. Global optimum
% (graphcuts).

In this work we propose a new method that uses active learning technique for
interactive segmentation of the traumatic brain injury (TBI) images. We observe
the TBI image segmentation is a complex task due to its multiple lesion regions,
multi-modality, and lack of prior knowledge of lesions' location. The
state-of-art image segmentation algorithms often fail to find the true lesions,
with high false-positive rate for single lesion detection, and high
false-negative rate in multiple lesion detection. We note a little user input at
the right time and right place can significantly improve the algorithm's
performance, and we adopt a minimalist's philosophy such that out algorithm need
the least amount of user's involvement. We make it possible by using the
\emph{active learning} concept. By active learning, the algorithm querys the
user on the most important data point. As a result, the user's response to such
query will be the most informative, and the number of user interaction is
minimized before the algorithm reaches certain estimation accuracy. Even better,
the algorithm has the potential of automatically classifying the unlabeled data
without user's input, and re-learn the model based on the updated labeled data.
This self-training further decrease the user involvement, without losing
segmentation accuracy. We refer the proposed algorithm as \emph{active-cut}.

Another contribution of work is the algorithm is able to detect multiple
lesions. Standard graph cut algorithm~\cite{rother2004grabcut} only detects
single object. Our active-cut algorithm can learn the model from a simple user
initialization, find the candidate objects and submit to user for
inspection. The user is in an passive state with out method, and just choose a
`yes' or `no' for the candidates. The active-cut algorithm will do the remaining
work including refining the candidate objects, re-learning model parameters and
re-running graph cut algorithm for a globally optimal map.

The last contribution of our work is the introduction of the spatial context
constraints by Markov random field (MRF). Besides careful definition the energy
term of the graph cut's objective function to get smooth boundary between normal
and lesion regions, we also define a MRF prior on label variables within the
normal lesion regions. The estimated label map of gray matter, white matter and
Cerebrospinal fluid (CSF) in the normal region is piecewise constant, as well as
the label map of edema and bleeding in the lesions. We also define the MRF on
the candidate objects submitted to the user, so the candidates is spatially
coherence object instead of single voxles.

% some related work. and compare them with ours, to show ours is better! If
% space is limited, we may need to split this paragraph into small pieces and
% plug into previous paragraph.
Several researchers have applied active learning to image segmentation
\cite{top2011active,iglesias2011combining,veeraraghavan2011active}.
Veeraraghavan et al.\cite{veeraraghavan2011active} proposed an algorithm in
which segmentation is performed by grow cut and uncertainty of segmentation is
estimated by SVM to give suggestion to user. The drawbacks of this method are:
the segmentation and uncertainty estimation are separated, the algorithm is for
single object segmentation, and the suggestion for user are pixels which are not
informative and not compact.  We propose a new objective function for both graph
cuts segmentation and uncertainty estimation for active learning which naturally
put both components into one unified framework.

\section{Method}
\label{sec:method}
\subsection{Image segmentation by Graph Cuts}
Following GrabCut~\cite{rother2004grabcut}, we build two mixture of Gaussian
(GMM) models for the normal brain regions and the lesions. We use the
expectation maximization (EM) method to estimate both the class labels and the
model parameters $\theta$. In the graph cut step, the algorithm takes model
parameters of both GMMs as input, and estimates a hard label $\alpha \in \{0,
1\}$ representing if each voxel $n$ is normal ($\alpha_n =0 $) or lesions
($\alpha_n = 1$). We are different from GrabCuts in that besides the smoothness
constraint on the lesion's boundary, we also apply MRF constraints on the label
map within normal and lesions. This soft constraint guarantee the estimated
labels is smooth. We also re-define the data term in the energy function for
better fit of the EM framework.

\noindent \textbf{Within-Class MRF}: Define the label map $\mat z = \{\vec
z_1, \dots, \vec z_N\}$, where $\vec z_n$ is a K dimensional binary random
variable for voxel $n$ such that $\sum_k z_{nk} = 1$. A particular element
$z_{nk} = 1$ indicates voxel $n$ is in Gaussian component $k$. The prior
distribution of $\mat z$ takes into account both the information from the brain
atlas and the spatial context constraints of MRF, and is defined as
\begin{equation*}
  p(\mat z) = \frac{1}{C} \exp( \sum_{n=1}^N \sum_{k=1}^K z_{nk} \log \pi_{nk} + \beta \sum_{(n,m)} \langle \vec z_n, \vec z_m \rangle ),
\end{equation*}
where the $\pi_{nk}$ is the atlas prior probability of voxel $n$ being in class
$k$, $(n, m)$ is pair of neighboring voxels, and $\langle, \rangle$ is the inner
product of two vectors, representing our preference of piecewise constant label
map, with the constraint strength given by $\beta$. Given $\vec z_n$, the likelihood
function is defined as multivariate Gaussian $p(\vec x_n | \vec z_n) =
\mathcal{N}(\vec x_n; \theta(\vec z_n))$, with $\vec x_n$ the observed data vector of
the multi-modality images at $n$. In EM, one need to evaluate
$\mathbb{E}_{P(\mat z |\mat x)} [\log p(\mat x, \mat z)]$, which is intractable
due to the MRF prior on $\mat z$. In this work we use the variational inference
method that iteratively updates $p(\vec z_n|\vec z_{\mathcal{N}(n)}, \vec x_n)$
given the expected value of $\vec z_n$'s neighbors $\mathcal{N}(n)$. The update
equation takes the form
\begin{equation*}
  \log p(z_{nk}) = z_{nk} \pi_{nk} + \sum_{m\in \mathcal{N}(n)} \langle \overline {\vec z}_m, \vec z_n \rangle + \log \mathcal{N} (\vec x_n; \theta(\vec z_n)),
\end{equation*}
where $\overline {\vec z}_m$ is the expected value of neighbor voxel $m$. We
compute $\log p(z_{nk})$ for all $k$ and compute $p(\vec z_n)$ by taking
exponential and normalize. $\overline{z}_n$ is just $p(\vec z_n)$ for binary
variables and will be used for updating $\vec z_n$'s neighbors. In M step, we
use $\mat z$ to estimate $\theta = \{\mu, \Sigma\}$ for all components. The
variational procedure stops when no $\vec z_n$ changes. Given $\alpha$, EM runs
on both GMM separately.

\noindent \textbf{Graph Cuts global optimization: } We define the objective
function of graph cuts optimization as
% possible to move two energy term in to text. Just keep E(alpha) here.
\begin{align*}
  &\mat E(\alpha) = \gamma \sum_{(m,n)} \psi(\alpha_n, \alpha_m) \exp \left ( -\beta_0 \| \vec x_n - \vec x_m\|^2 \right ) +\\
  & \sum_n^N \mathbb{E}_{p(\mat z|\mat x)} \log p(\vec x_n, \vec z_n; \theta (\alpha)),
  %% &\mathbb{E}_{p(\mat z|\mat x)} \log p(\vec x, \vec z; \theta (\alpha_n)) = \!\!\sum_{k=1}^K \!z_{nk}(\log \pi_{nk} \!+\! \log \mathcal{N}(\vec x_n; \theta(\alpha_n))) \!+\!  \beta \!\!\!\!\!\!\sum_{m \in \mathcal{N}(n)} \!\!\!\!\!\langle \vec z_n, \!\vec z_m\rangle \!-\! \log C \!\!\!\!,
\end{align*}
where $\psi = 1$ if $\alpha_n \neq \alpha_m$, otherwise $\psi = 0$, and
$\beta_0$ is estimated from data by taking expectation over image
sample~\cite{boykov2001fast,rother2004grabcut}. The smoothness constraint
depends on the data term, so it is a conditional random field. When building the
graph, we set the T-link by the second term, and the N-link by the first term in
the above equation. Given the first initialization of a bounding box by the
user. we initialize the $\alpha$ map such that $\alpha = 1$ (lesion) within the
bounding box, and $\alpha = 0$ outside. The graph cuts algorithm keeps outside
voxels' $\alpha$ fixed, and update the $\alpha$ of voxels within bounding
box. Such strategy guarantees low false positive detection. The possible lesion
objects outside of the bounding box will be detected in the following active
learning algorithm.

%-------------------------------------------------------------------------
\subsection{Active Learning New Lesion Object}

% Gives a short intro of active learning with (just one) reference. Why active
% learning, benefit. How that works in general. Then talk about our
% strategy. Need to mention self-training (automatically add unlabeled data into
% labeled dataset, thus decreasing user interaction/burden).
Once the EM and graph-cut converges, the algorithm enters into the
active-learning step. In the graph-cut, we do not move the noxel in normal
region into the lesions in order to control the false positive detection. In
this learning step, the algorithm automatically computes the probability of each
voxel in the normal region belonging to the lesions. It then builds a connected
component map, since such a high-level object-based representation is convenient
for user interaction. We sort the multiple objects in a decending order of the
probability of being in the lesion regions, and submit the top object for user
to query. Even better, when the algorithm believes the top object should be in
the lesion with sufficient confidence, it adds the object into lesion in a
self-training process without querying users, hence further reducing the user
involvement.

% How the query score are computed. (LW will add stuff here)
\noindent\textbf{Query Score: }The log-odds of $\alpha$ is defined as
\begin{align*}
  a = \log p(\alpha=1) + \mathbb{E}_{p(\vec z_n|\vec x_n)} \log p(\vec x_n, \vec z_n; \theta (\alpha=1))\\
  - \log p(\alpha=0) + \mathbb{E}_{p(\vec z_n|\vec x_n)} \log p(\vec x_n, \vec z_n; \theta (\alpha=0)),
\end{align*}
where the $p(\alpha)$ is assumed to be a MRF. The predictive probability of a
voxel being in lesion can be computed by the standard logistic function
$p(\alpha_n=1|\vec x_n) = 1/ (1 + \exp (-a))$. We obtain a binary map $\vec w$
by thresholding the predictive map at 0.5, and identify a series of objects
$R_i$ by running a connected component routine on $\vec w$. To further select
the most salient objects, we sort the objects in decending order of the
following score:
\begin{align}
q(R_i) = \sum_{n\in R_i} p(\alpha = 1| \vec x_n) / \vert\{n: n\in \mathcal{B}(R_i) \}\vert
\end{align}
The $\mathcal{B}(R)$ is the set of voxels on the boundary of $R$, and the
denominator denotes the number of voxels on the bondary of $R_i$. The above
query score prefers objects with larger volumes of posterior probability. The
score also prefers blob-like objects since such object has large volume-surface
ratio. Such criteria reflects our prior knowledge on the lesion object's shape.

% Give a summary of the pipeline. and give referenc of pipeline's figure.
\noindent\textbf{Processing Pipeline: } With all the settings above, the
learning pipeline is given in Figure \ref{fig:flowchart}. Given the bounding box
from user, we initialize $\alpha = 0$ for the voxels outside of the box, and set
$\alpha=1$ for the in-box voxels. The EM and graph cuts only update $\alpha$ in
the box. Upon convergence, there will be some false-negative voxels outside the
box. These voxels go into higher level objects that is actively learned once we
compute the query score of each object. The new lesion objects added by
self-training or active learning is reflected on the updated hard-constraint
map, and a new EM + graph cut iteration starts. This iteration repeats until
user stops the learning process. We run the active cut algorithm on the
longitudinal datasets of both time points.

\begin{figure} [ht]
\centering
%% \includegraphics[width=8.5cm]{./figures/acLearn_flowchart}
\includegraphics[width=0.5\textwidth]{./figures/acLearn_flowchart}
\caption{Flowchart of the proposed algorithm.}
\label{fig:flowchart}
\end{figure}

% parameters empirically chosen, but not have big impact on results. Need to say
% that!


% partially initialized lesion region/objects can be recovered later by
% self-training/act-learning. Need to show that!
% Using the likelihood estimated using acCut for 4D modeling pathological
% anatomy which follows the MBIA paper.
\noindent\textbf{4D modeling Pathological Anatomy: }In order to estimate
deformations from a healthy template to each time point and evaluate mapping
between time points, the result of active learning based Graph cuts, likelihood,
is used for modeling pathological anatomy.  This follows the 4D pathological
anatomy modeling framework of Wang et al. \cite{WangMBIA2013}.  The estimated
likelihood, $p( I_{t}(x) | c, \theta_t^c )$, can be plugged into the data
functional $\mathcal{F}(A, \phi_t, Q_t) = $
\begin{equation}
- \sum_{t=1}^T \, \sum_{x=1}^N \, \log \, ( \, \sum_{c=1}^C P_t^{c}(x) \, p( I_{t}(x) | c, \theta_t^c ) \, )
\end{equation}
where the spatial prior $P_t^c$ for each class $c$ at time point $t$ is
$P_t^c = A^c \circ \phi_t + Q_t^c$,
and $A$ is the tissue class probability that is initially associated with the
healthy template, $\phi_t$ is the diffeomorphic deformation from time $t$ to the
atlas, and $Q_t$ is the non-diffeomorphic probabilistic change for time $t$.

\section{Results}
\label{sec:results}
We applied our method to multi-modality image data of four TBI patients with
large lesions.  Each subject was scanned twice, an acute scan at about 5 days
and another chronic scan at 6 months post injury. Each subject's data includes
T1, T2, FLAIR, and GRE. For lesions' GMM model, we choose $K=2$ for bleeding and
edema component, and for normal regions we choose $K=3$ for gray matter, white
matter and CSF. We take 6 neighborhood system and choose
the smooness parameter $\gamma = \beta = 1$. The image intensity of each
modality is normalized to the range [0, 255] before the learning process. We
also run K-Means 5 times with different initialization, and use the K-Means
clustering with the atlas prior map to initialize the GMM.
% need to say: the number of components of the Gaussian mixture model is set to
% 3 for normal region (GM, WM, CSF) and 2 for lesion area (edema, bleeding) to
% reflect our prior knowledge.

\begin{figure} [ht]
\centering
\begin{tabular}{c@{\hskip 0.2in}ccc}
Iteration 1 & Iteration 2 & Iteration 3
\\
\includegraphics[width=0.14\textwidth]{figures/iterative_results/trimap_initial.png} &
\includegraphics[width=0.14\textwidth]{figures/iterative_results/trimap_iteration_1.png} &
\includegraphics[width=0.14\textwidth]{figures/iterative_results/trimap_iteration_2_stop.png} &
\\
Yellow: uncertain & Red: foreground & Blue:background
\\
\includegraphics[width=0.14\textwidth]{figures/iterative_results/alphamap_Iteration_1.png} &
\includegraphics[width=0.14\textwidth]{figures/iterative_results/alphamap_Iteration_2.png} &
\includegraphics[width=0.14\textwidth]{figures/iterative_results/alphamap_Iteration_3_stop.png} &
\\
Red: foreground & Other: background &
\end{tabular}
\caption{Iterative active learning based user interaction. First raw is the
  result of hard constraint (trimap), second raw is the result of $\alpha$
  map. White matter surface is visualized in all figures as reference. Iteration
  1 is the beginning of the algorithm where user gives the bounding box to
  initialize the algorithm; Iteration 2 is active learning, one candidate patch
  is a query to ask user, and user chose yes and agreed it was foreground, and
  then the user interaction stopped; Iteration 3 is also active learning, one
  candidate patch was rejected and a second candidate patch was accepted by
  user, and then the user interaction stopped. The forth iteration is not shown
  because user chose 'stop' to stop the active learning.}
\label{fig:userinter}
\end{figure}

% This paragraph give some procedure, which should be in the previsou method
% section. This is just fore result.
Fig.~\ref{fig:userinter} shows the dynamic learning process of subject 1. In
iteration 1, the hard constraint is the bounding box of user input and therefore
the foreground alpha map is restricted in the bounding box. In the second
iteration, since user accepted one candidate patch, and then the hard constraint
was updated accordingly. We see this user-accepted patch is actually connected
to the bounding box. This is one advantage of our algorithm which doesn't
require user to give perfect bounding box for lesions. This is a good feature
because in practice it's extremely difficult and time-consuming to ask user to
give a good 3D bounding box to include one major lesion area. In the third
iteration, user rejected one candidate patch and accepted a second one. The
user-accepted patch is not connected to the major lesion but our algorithm is
still able to capture it, this is another advantage of our algorithm. Not like
regular GrabCut~\cite{rother2004grabcut}, it's designed for single object
segmentation. Our algorithm is able to segment multiple objects and actively
provide user candidate patches which makes the user interaction more
efficiently.  Another advantage of our algorithm is that by combing volume,
predictive probability, and shape information, most of the top-ranked patches
are actually true candidates. This further makes the user interaction
efficiently since if many top-ranked patches are wrong candidates, user will
have to reject many patches to be able to get good segmentation.  During the
iterations of user interaction, every user accepted or rejected candidate patch
is recorded and then used as mask in the following iterations to avoid to
recommend the same patch to users.

\begin{figure} [ht]
\centering
\includegraphics[width=0.5\textwidth]{./figures/qualitative_comp}
\caption{Qualitative comparison of the baseline and the acCut.}
\label{fig:QualComp}
\end{figure}

\begin{table} [ht]
%\begin{center}
\centering
\begin{tabular}{c|cc|cc|c}
\hline
 &  \multicolumn{2}{c}{Baseline} &  \multicolumn{3}{|c}{AcCut}\\ 
\cline{2-6}
\multirow{1}{*}{Subject}  & NHL & HL & NHL & HL & UI\\

I  & 0.2503 & 0.0613  & 0.6349 & 0.5698 & 3\\ %\hline
II & 0.3269 & -  & 0.6910 & -   & 4 \\ %\hline
III  & 0.1311 & 0.2288   & 0.4512 & 0.4840 & 6 \\ %\hline
IV   & 0.0918 & 0.0998   & 0.3503 & 0.1153 & 5 \\ \hline
\end{tabular}
\caption{
  % edema/bleeding or AHL/ANHL
  Dice values comparing semi-automatic segmentation to ground truth, using
  the baseline method and our approach. HL and NHL are acute
  hemorrhagic and non-hemorrhagic lesions. UI denotes the number of interaction user performed using AcCut.}
\label{tab:DiceResult}
\end{table}

In order to show the efficacy of the proposed method, we use the GrabCut without user interaction as baseline method and allow background change to foreground freely so that foreground segmentation is not restricted in the initial bounding box.
Fig.~\ref{fig:QualComp} shows the qualitative comparison of the baseline method and the acCut and  Table~\ref{tab:DiceResult} shows the quantitative comparison of both methods. 
From both qualitative and quantitative result, we see that the proposed method is able to significantly improve the segmentation. This kind of result is because there is no atlas for lesions, therefore without user interaction the algorithm tends to converge to bad local minimum (i.e., too large or too small lesion segmentation). Smart and efficient user-interactive method may give us better result \textemdash this is the rational behind the proposed algorithm.
Fig.~\ref{fig:Deform} shows the result of 4D modeling.  

\begin{figure} [ht]
\centering
\includegraphics[width=0.5\textwidth]{./figures/parcellation}
\caption{Result of 4D modeling. Left two images are acute T1 reference image and parcellation, right two are chronic result.}
\label{fig:Deform}
\end{figure}


\section{Conclusions}
We presented a semi-supervised method for modeling longitudinal MR images of
severe TBI patients with multiple lesion regions.  The major component of our
algorithm is active learning based segmentation which allows efficient user
interaction. Compare to standard GrabCut, our method has several advantages.
First, instead of passively waiting user to discover the missing segmentation
area, our method actively recommend coherent patch to users to decide if it is
true candidate.  Second, our algorithm is able to capture multiple objects which
is common is severe TBI case but the standard GrabCut is designed for single
object.  By taking the rough bounding box into account, integrating different
features of candidate patch, and keeping track of the user interaction, our
algorithm is able to make the user interaction easy, robust and efficiently to
segment multiple lesions.  We also used MRF to enforce the smoothness of FG/BG
segmentation and the provide user spatially-coherent object for query. Both
quantitative and qualitative results show that our method is able to improve
segmentation significantly and therefore improve the following 4D modeling.  In
the future, we'd like to validate our method using a large data set.


\bibliographystyle{IEEEbib}
\bibliography{strings,refs}
\end{document}
