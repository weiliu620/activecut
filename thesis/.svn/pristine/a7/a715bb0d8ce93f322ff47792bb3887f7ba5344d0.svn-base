\chapter{Full Pairwise Connectivity With Spatial Coherence}
\label{chap:method1}

% the functional activity has the multiple comparision problem. 
In this chapter we present a new method for spatial regularization of functional
connectivity maps based on the MRF priors. The high level of
noise in fMRI leads to errors in functional connectivity detection algorithms. A
common approach to mitigate the effects of noise is to apply spatial Gaussian
smoothing, which can lead to blurring of regions beyond their actual boundaries
and the loss of small connectivity regions. Recent work has suggested MRF as an
alternative spatial regularization in detection of fMRI activation in task-based
paradigms. We propose to apply MRF priors to the computation of functional
connectivity in resting-state fMRI. Our Markov priors are in the space of
pairwise voxel connections, rather than in the original image space, resulting
in a MRF whose dimension is twice that of the original image. The high
dimensionality of the MRF estimation problem leads to computational
challenges. We present an efficient, highly parallelized algorithm on the
Graphics Processing Unit (GPU). We validate our approach on a synthetically
generated example as well as real data from a resting state fMRI study.

\section{Backgrounds}
To show the noise level and the impact of spatial smoothing on the functional
connectivity estimation, we take a seed voxel at the MNI coordinate (42, 16, 25)
and compute the correlation between this seed region and every other voxel's
BOLD signals in the same volume of the rs-fMRI data, and show the correlation
map at Figure \ref{fig:conexample}. The seed's signal is computed by averaging
the BOLD signal of voxels within 5 mm distance from the seed voxel. Following
the standard seed-based functional connectivity methods, we average the BOLD
signal of the voxels within r = 5 mm from the seed voxel, and use the averaged
signal as a surrogate of the BOLD signal at this coordinates. We then compute
the sample correlation between this average signal and every other voxel's BOLD
signal in the full volume. For display purpose, we only show the correlation map
of one slice where the seed regions is located. Figure \ref{fig:fmrislice} shows
the first time point of the original BOLD signal. As expected it is impossible
to see any meaningful patterns from this image, since the functional
connectivity is not represented by voxels' intensity at single time point, but
the average effect across all time points. Figure \ref{fig:corrmap} shows the
linear correlation map with the seed regions. And the red dot gives the location
of the seed region. We can see the symmetric location of the seed region on the
other hemisphere shows higher intensity of correlation, suggesting these voxels
are more positively correlated with the seed. In Figure \ref{fig:corrmap_th}, we
show the correlation map thresholded at 0.3. Since the seed region belongs to
the default model network (DMN), an important component in the intrinsic
functional system, we expect to see other spatially remote regions in the same
network have higher correlation in \ref{fig:corrmap_th}, We observe one region
on the same location of the opposite hemisphere, and also one region at the
prefrontal lobe remains after thresholding. But overall the spatial patterns are
hard to identify, and there are also some false-positive detections. One reason
of the difficulty of detecting the connectivities is the large amount of noise
in the data, and the spatial smoothing in the preprocessing step. We aim to
address this problem in this chapter.

\begin{figure}[tb]
  \centering
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[height=\textwidth]{figures/method1/fmrislice}
    \caption{One slice of a resting-state fMRI dataset at $z = 25$. }
    \label{fig:fmrislice}
    \end{subfigure}
~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[height=\textwidth]{figures/method1/corrmap}
    % x = 42, y = 16, z = 25
    \caption{Correlation map between a seed and the current slice.}
    \label{fig:corrmap}
    \end{subfigure}
~
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \includegraphics[height=\textwidth]{figures/method1/corrmap_th}
    \caption{The correlation map thresholded at 0.3.}
    \label{fig:corrmap_th}
    \end{subfigure}
  \caption{An example of correlation map with a seed in the default model
    network on the rs-fMRI data set.}
  \label{fig:conexample}
\end{figure}

In both task-based and rs-fMRI the impact of imaging noise can be reduced by
taking advantage of the spatial correlations between neighboring voxels in the
image. A common approach used for instance in statistical parametric mapping
(SPM)\cite{worsley_analysis_1995} is to apply a spatial Gaussian filter to
smooth the signal prior to statistical analysis. However, this can lead to
overly blurred results, where effects with small spatial extent can be lost and
detected regions may extend beyond their actual boundaries. An alternative
approach to spatial regularization that has been proposed for task activation
paradigms is to use a Markov random field (MRF) prior~\cite{ou_spatial_2005,
  descombes_spatio-temporal_1998, descombes_fmri_1998,
  woolrich_fully_2004,cosman_exact_2004}, which models the conditional
dependence of the signals in neighboring voxels.

In this chapter we propose to use MRF models in rs- fMRI to leverage spatial
correlations in functional connectivity maps. Unlike previous MRF-based
approaches, which use the neighborhood structure defined by the original image
voxel grid, the neighborhoods in functional connectivity must take into account
the possible relationships between spatially distant voxels. Therefore, we
define the neighborhood graph on the set of all voxel pairs. This results in a
Markov structure on a grid with twice the dimensions of the original image data,
i.e., the pairwise connectivities for three-dimensional images results in a
six-dimensional MRF. The neighborhood structure is defined so that two voxels
are more likely to be connected if they are connected to each other's spatial
neighbors.

We combine the Markov prior on functional connectivity maps with a likelihood
model of the time series correlations in a posterior estimation problem.
Furthermore, we model solve for the unknown parameters of the MRF and likelihood
using the EM algorithm that we discussed in chapter \ref{chap:em}. In the
estimation step the posterior random field is sampled using Gibbs sampling and
estimated using mean field theory, also known as variational inference.

In the next section we describe our MRF model of functional connectivity maps.
In Section~\ref{sec:methods} we give the details of the algorithm to estimate
the functional connectivity probabilities, including implementation details for
the GPU solver. Finally, in Section~\ref{sec:results} we demonstrate the
advantages of our approach on a synthetically generated data set as well as on
real rs- fMRI data.

\section{Methods}
\label{sec:methods}
Our framework for functional connectivity is a Bayesian approach in which we
estimate the posterior distribution of the connectivity between voxels,
conditioned on the fMRI data. Let $X = \{x_{ij}\}$ denote the functional
connectivity map, i.e., a map denoting whether each pair of voxels $i,j$ is
connected, and let $Y$ denote the original fMRI data, or some measurement
derived from the fMRI. In this work we take $Y$ to be the map of correlations
between pairs voxel time series. The posterior distribution is then
proportionally given by
\begin{equation}
\label{eq:posterior}
P(X \, | \, Y) \prop P(X) \cdot P(Y \, | \, X).
\end{equation}
In this work we model $P(X)$, the prior on the connectivity map, using a
MRF, and the likelihood $P(Y \, | \, X)$ using Gaussian models of the
Fisher transformed correlation values. We now give details for both of these
pieces of the model.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/method1/6dmrf}
  \caption{MRF prior of the connectivity variables. Each node of the graph
    represents a pairwise connectivity variable between voxel $i$ and $j$. An
    edge is added between two nodes $x_{ij}$ and $x_{ik}$ if $k$ is the neighbor
    of voxel $j$. The graph where the MRF is defined on is twice the dimensions
    of the original image domain, i.e. six dimensions. Given the hidden variable
    $X$, the observed sample correlation values are assumed to be generated
    from a Gaussian distribution with unknown parameter $\cN(y_{ij} | x_{ij}; \mu,
    \sigma^2)$. }
  \label{fig:6dmrf}
\end{figure}

\subsection{Markov Prior}
Conventional image analysis applications of MRFs~\cite{li_markov_2009} define
the set of sites of the random field as the image voxels, with the neighborhood
structure given by a regular lattice. Because we are studying the pairwise
connectivity between voxels, we need to define a MRF in the higher-dimensional
space of voxel location pairs. Thus, if $\Omega \subset \mathbb{Z}^d$ is a
$d$-dimensional image domain, then the sites for our connectivity MRF form the
set $\mathcal{S} = \Omega \times \Omega$. Let $i, j \in \Omega$ be voxel
locations, and let $\mathcal{N}_i, \mathcal{N}_j$ denote the set of neighbors of
voxel $i$ and $j$, respectively, in the original image lattice. Then the set of
neighbors for the site $(i, j) \in \mathcal{S}$ is given by $\mathcal{N}_{ij} =
(\{i\} \times \mathcal{N}_j) \cup (\mathcal{N}_i \times \{j\})$. In other words,
two sites are neighbors if they share one coordinate and their other coordinates
are neighbors in the original image lattice. This neighborhood structure will
give us the property in the MRF that two voxels $i, j$ in the image are more
likely to be connected if $i$ is connected to $j$'s neighbors or
vice-versa. Equipped with this graph structure, $\mathcal{S}$ is a regular
$2d$-dimensional lattice. With the node set $\cX$ and neighboring system $\cN$,
we define a graph $\cG$ that we call the {\em connectivity graph}. Figure
\ref{fig:6dmrf} gives an illustration of how this connectivity graph is defined.

We next define a multivariate random variable $X = \{ x_{ij} \}$ on the set
$\mathcal{S}$, where each random variable $x_{ij}$ is a binary variable that
denotes the connectivity ($x_{ij} = 1$) or lack of connectivity ($x_{ij} = -1$)
between voxel $i$ and $j$. If $A \subset \mathcal{S}$, let $X_A$ denote the
set of all $x_{ij}$ with $(i,j) \in A$, and let $X_{-ij}$ denote the
collection of all variables in $X$ excluding $x_{ij}$. For $X$ to be a
MRF it must satisfy
\begin{equation*}
  P( x_{ij} \, | \, X_{-ij}) = p(x_{ij} \, | \, x_{\mathcal{N}_{ij}}).
\end{equation*}
According to the Hammersley and Clifford Theorem~\cite{besag_spatial_1974}, $X$
is Markov random field if and only if it is also a Gibbs distribution, defined
as
\begin{equation}
  P(X) = \frac{1}{Z}\exp\left(-U(X)\right), 
\end{equation}
where $U$ is the energy function $U(X) = \sum_{c \in \mathcal{C}}
V_c$, with potentials $V_c$ defined for each clique $c$ in the clique
set $\mathcal{C}$. The partition function $Z = \sum_{X} \exp(-U(X))$
is a normalizing constant, where the summation is over all possible
configurations of $X$. We use a particular form of MRF---the
Ising model---a commonly used model for MRFs with binary states. In
this model the energy function is given by
\begin{equation}
U(X) = - \beta \sum_{\langle ij, mn \rangle} x_{ij} x_{mn},
 \label{eq:A1}
\end{equation}
where the summation is over all edges $( ij, mn )$ on the graph $\cG$, i.e., all
adjacent voxel pairs $(i,j), (m,n)$ in the connectivity graph. When $\beta > 0$,
this definition favors similarity of neighbors. An alternative definition is to
make the MRF prior also contains the data term, such as the strength of the
connection between neighboring nodes also depends on the data. Where the
observed correlation value of two nodes are different, the strength of the MRF
prior will be decreased. This is the conditional random field we have discussed
in section \ref{sec:crf}.
\subsection{Likelihood Model}
We now define the likelihood model, $P(Y \, | \, X)$, which connects the
observed data $Y$ to our MRF. Because we are interested in the functional
connectivity between pairs of voxels, we compute the correlation between the
time courses of each pair of voxels, and get a correlation matrix $Y =
\{y_{ij}\}$. Just as in the case of the random field $X$, the correlation matrix
$Y$ is also defined on the $2d$-dimensional lattice $\mathcal{S}$. Linear
correlation is not the only choice for $Y$. We can use any statistic, as long as
it indicates the affinity between two voxel time series. Another possibility
could be frequency domain measures, such as the
coherence~\cite{mller_multivariate_2001}, although the definition of likelihood
function is not straightforward for such similarity measurement. On the other
hand, simple linear correlation has the advantage that after the Fisher
transformation, the correlation obeys the Gaussian distribution that can be used
for the conditional distribution of $P(y_{ij} | x_{ij})$, as can be shown below.

Before defining the full data likelihood, we start with a definition of the {\em
  emission function} at a single site $s_{ij} \in \mathcal{S}$. This is defined
as the conditional likelihood, $P(y_{ij} \, | \, x_{ij})$, and is interpreted as
the probability of the observed correlation, given the state of the connectivity
between voxels $i$ and $j$. We model the emission function as a Gaussian
distribution with unknown mean and variance on the Fisher transformed
correlation $y_{ij}$, that is,
\begin{equation}
\label{eq:emission}
P(y_{ij} \,|\, x_{ij} = k) = \frac{1}{\sqrt{2\pi} \sigma_k} \exp \left( -\frac{(F(y_{ij}) -  \mu_k)^2}{2\sigma_k^2}\right),
\end{equation}
where $F$ denotes the Fisher transform. Notice that each correlation $y_{ij}$ on
site $s_{ij}$ only depends on the latent variable $x_{ij}$ on the same site, and
does not depend on neighbors of $x_{ij}$. Alternative definitions exist. For
example, the observed correlation data $y_{ij}$ can also depends on the
neighbors of $x_{ij}$, similar to the work of Geman
et al.\cite{geman1984stochastic}. This is equivalent to add more edge on the
graphical model and therefore the posterior inference will be more
complicated. In this work, we use a simple model which has a one-to-one
correspondence between $x_{ij}$ and $y_{ij}$. Given the above setting, the full
likelihood is given by
\begin{equation}
\label{eq:likelihood}
P(Y \, | \, X) = \prod_{s_{ij}\in\mathcal{S}} P(y_{ij} \, | \, x_{ij}).
\end{equation}

\section{Estimation via Expectation Maximization}
\label{sec:algorithm}
Having defined the data likelihood and MRF prior in the previous section, we are
now ready to describe the maximization of the posterior given
by~\eqref{eq:posterior}. For this we need to determine the model parameters,
$\beta$ in \eqref{eq:A1} and $(\mu_k, \sigma_k^2)$ in
\eqref{eq:emission}. Rather than arbitrarily setting these parameters, we
estimate them using the EM algorithm. Exact
computation of the full posterior~\eqref{eq:posterior} is intractable, due to
the combinatorial number of terms in the partition function $Z$. Therefore, we
instead maximize the approximate posterior given by the pseudo-likelihood
function~\cite{li_markov_2009,besag_spatial_1974},
\begin{equation}
PL(X, Y) = \prod_{ij}^{}P (x_{ij}|x_{\mathcal{N}_{ij}}) P(y_{ij}|x_{ij}). \label{eq:2}
\end{equation}

In the E-step, the parameters are held fixed and we compute the posterior
probability for each $x_{ij}$, and sample $x_{ij}$ from the posterior
distribution using Gibbs sampling. We then compute the expected value of each
connectivity node by mean field theory. After we compute the posterior of
current point $x_{ij}$, we update $x_{ij}$ with its expected value $\langle
x_{ij} \rangle$. The equivalence of posterior probability and the expectation of
binary random variable is discussed in section \ref{chap:mathvar}.

In the M-step, the complete data $\{\langle X\rangle, Y\}$ is available, and the
parameters can be estimated by maximizing the joint pseudo-likelihood given
by~\eqref{eq:2} using Newton's method. After several iterations of this EM
algorithm, we get parameters as our MAP estimates. During parameter estimation,
the joint likelihood can be factorized into two separate term of the prior and
the conditional likelihood, and the parameter $\beta$ can be estimated by
maximizing the MRF prior (equivalently the pseudo-likelihood) by Newton's
method. The estimation of $\mu$ and $\sigma^2$ can be done in closed from just
like the standard Gaussian mixture model, as shown in section \ref{sec:parest}.

\subsection{GPU Implementation}
 The whole algorithm involves updating a high
dimensional connectivity matrix $X$ iteratively, and hence have high
computation cost. We designed a parallel Markov random field updating strategy
on graphics processing unit (GPU). The algorithm take only a few minutes
compared with more than 1 hour on CPU counterpart.

\begin{figure}[htb]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/method1/checkerboard}
  \label{fig:imagechain}
  \caption{Ideally the updates of each voxel is independent of other voxels in
    order to be used on GPU. In our Gibbs sampling, although the sampling of
    each voxel depends on its neighbors, the order of the voxels being updated
    does not matter. Upon convergence, the image will be a sample of the target
    Gibbs distribution. However, numerically, the sampling tends to be stuck in
    this local minimum of checkerboard image. At current state, each voxel has a
    neighbor with different states with itself, and the sampling flips the color
    of all voxels in the next stage.}
\end{figure}

To fit the algorithm into GPU's architecture, we use some special
strategy. First, because GPU only support 3-dimensional array, we need
to reshape $X$ and $Y$ defined originally on higher
dimensional graph by linear indexing their original subscripts. This
is especially difficult for brain fMRI data because the gray matter
voxels resides in a irregular 3-D lattice. Specific data structure are
used for mapping between original voxel subscripts and their linear
index $i$ and $j$. Second, to update each site of MRF in parallel we
have to make sure a site is not updated simultaneously with its
neighbors, otherwise the field tends to be stuck in a
checkerboard-like local maximum. Our strategy is to divide all the
sites of the field into several sub-groups, such that a site is not in
the same sub-group with its neighbors.  We then can update the
sub-group sequentially, while the data in sub-groups are updated
simultaneously. The whole procedure is summarized in Algorithm \ref{alg:1}.

It is noted this updating scheme is closely related the coding method of
parameter estimation of MRF that we discussed in section \ref{sec:parest}. Both
approaches split the variables in to multiple sub-groups. They differ in that
for coding methods, the separation is used to get independent variables within
the sub-group, while here the voxels in sub-groups is independent so we can
update them in parallel.

\begin{algorithm}[tbh]
  \caption{MAP estimation by EM}
  \label{alg:1}
  \begin{algorithmic}
    \REQUIRE Sample correlation matrix $\mat Y$.
    \STATE Init posterior matrix by maximizing conditional likelihood
    $P(y_{ij}|x_{ij})$.  
    \WHILE{$\Delta \{\beta, \mu, \sigma^2 \} >
      \varepsilon$ } 
    \STATE \textbf{E step: }

    (a) Based on the current
    parameters, compute the posterior by \eqref{eq:2}.

    (b) Repeatedly Do Gibbs Sampling until the field  stabilize.

    (c) Based on current value of $x_{ij}$, iteratively compute the mean
    field for all nodes in $\mathcal{S}$ until the field stable.

    \STATE \textbf{M step: } 

    (d) With complete data $\{\mat X, \mat
    Y\}$, estimate $\beta$ , $\mu$ and $\sigma^2$ by maximizing
    \eqref{eq:2}.
    \ENDWHILE
    \RETURN posterior matrix $\mat X$.
  \end{algorithmic}
\end{algorithm}

\section{Results}
\label{sec:results}
In this section, we give the experiment results for both the simulated data and
the real fMRI data. We compare the results of various methods on simulated data
with the ground truth to show the proposed method's performance. In the real
data experiment, we compare the results with the functional connectivity map of
other literatures.

\begin{figure}[tb] 
  \centering 
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/trueConn}
    \caption{ground-truth connectivity}
    \label{fig:6dconn1}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/corrNoSmooth}
    \caption{ correlation of original, noisy data.}
    \label{fig:6dconn2}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/SampleCorr}
    \caption{correlation of Gaussian-smoothed data.}
    \label{fig:6dconn3}
    \end{subfigure}

  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/threholdCorrRaw}
    \caption{connectivity based on noisy correlations.}
    \label{fig:6dconn4}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/threholdCorrSmoothed}
    \caption{connectivity based on smoothed data.}
    \label{fig:6dconn5}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/newtoy/newpost_sym2}
    \caption{connectivity computed using proposed MRF model}
    \label{fig:6dconn6}
    \end{subfigure}

  \caption[Test on synthetic data.]{Test of synthetic data by using correlation and MRF method proposed in this work.}
  \label{fig:6dconn}
\end{figure}

\subsection{Synthetic Data} 
We first construct a synthetic data set consisting of a $100\times 1$ 1-D image,
with each pixel a 300-point time course signal. The 1-D image will guarantee the
connectivity map be in 2D space and can be visualized easily. The time course
was constructed with a baseline DC signal of 800, plus additive Gaussian noise
of zero mean and variance 50. We then added a sine wave signal of frequency 0.2
and amplitude 20 to two distant regions of the image. The goal is to detect the
connectivity between these two distant regions. The true connectivity value will
be one between those pixels containing the sine wave signal, otherwise it is
defined as $-1$ for lack of connectivity between signal and noise, and between
noise time series. The true connectivity map is shown in
Figure.~\ref{fig:6dconn1}.

To compare our MRF model with conventional Gaussian blurring of the correlation
map, we applied both approaches to the synthetic data (Figure
~\ref{fig:6dconn}). On the correlation map in the top row, we see smoothing does
remove noise and results in a correlation map that looks more like the true
connectivity map. However, it also creates several errors, most noticeably false
positives around the diagonal (Fig.~\ref{fig:6dconn5}). This is because without
prior knowledge of the scale of the patterns we are interested in, the choice of
smoothing kernel size is arbitrary. Therefore, a large kernel size will enforce
the signals of many voxels look similar, the following correlation map will have
more false-positive detections. Figure~\ref{fig:6dconn6} shows the proposed MRF
method better detects the true connectivity regions while removing most false
positives.
 

\begin{figure}[tb] 
  \centering 
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R1_corr_nosmooth}
    \caption{sub1: correlation without smoothing}
    \label{fig:invivo21}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R1_corr_smooth}
    \caption{sub1: Correlation with smoothing}
    \label{fig:invivo22}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R1_mrf}
    \caption{Posterior from MRF}
    \label{fig:invivo23}
    \end{subfigure}

  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R2_corr_nosmooth}
    \caption{sub2: correlation without smoothing.}
    \label{fig:invivo24}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R2_corr_smooth}
    \caption{sub2: correlation with smoothing.}
    \label{fig:invivo25}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo2/R2_mrf}
    \caption{sub2: posterior from MRF}
    \label{fig:invivo26}
    \end{subfigure}
  \caption{Correlation map and posterior connectivity map between seed voxel and
    slice containing the seed.}
  \label{fig:invivo2}
\end{figure}

\subsection{Resting-State fMRI} 
Next we tested our method on real data from healthy control subjects in a
resting-state fMRI study. BOLD EPI images (TR= 2.0 s, TE = 28 ms, GRAPPA
acceleration factor = 2, 40 slices at 3 mm slice thickness, 64 x 64 matrix, 240
volumes) were acquired on a Siemens 3 Tesla Trio scanner with 12-channel head
coil during the resting state, eyes open. The data was motion corrected by SPM
software and registered to a T2 structural image. We used a gray matter mask
from an SPM tissue segmentation so that only gray matter voxels are counted in
the connectivity analysis. We do \emph{not} spatially smooth the data, in order
to see the benefit of replacing spatial smoothing with our MRF method. Before
computing the correlations, the time series at all voxels are linearly detrended
by least squares regression.

Figure \ref{fig:invivo1} compares the real data results using no spatial
regularization, Gaussian smoothing, and the proposed MRF model. Though the
posterior connectivity of the MRF is computed between every pair of voxels
within a slice, for visualization purposes, only the posterior of the
connectivity between one voxel and the slice is shown. We chose to visualize the
connectivity to a voxel in the posterior cingulate cortex (PCC) because this is
known to be involved in the default mode network~\cite{raichle2001}, with
connections to the medial prefrontal cortex (MPFC). The results show that
Gaussian smoothing is able to remove noise, but is unable to find a clear
connection between the PCC and the MPFC. Our proposed MRF model (rightmost plot)
is able to remove spurious connections, and also clearly shows a connection to
the MPFC.

To show the strongest connections found by each method, Figure
\ref{fig:invivo2} shows the thresholded connectivity maps overlaid on T2
structural image. Images in the first two columns are thresholded such that the
top $5\%$ voxel correlations are shown. For the MRF in the third column, the MAP
estimate is shown.


\begin{figure}[tb] 
  \centering 
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r1}
    \caption{Sub1: correlation map without smoothing.}
    \label{fig:invivo11}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r1_smooth}
    \caption{Sub1: correlation map with smoothing.}
    \label{fig:invivo12}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r1_mrf}
    \caption{Sub1: posterior probability by MRF.}
    \label{fig:invivo13}
    \end{subfigure}

  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r2}
    \caption{Sub2: correlation map without smoothing.}
    \label{fig:invivo14}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r2_smooth}
    \caption{Sub2: correlation map with smoothing. }
    \label{fig:invivo15}
    \end{subfigure}
~
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/method1/invivo1/r2_mrf}
    \caption{Sub3: posterior probability by MRF.}
    \label{fig:invivo16}
    \end{subfigure}
  \caption{ Threshold correlation mapand Posterior Connectivity map between seed
    voxel and the current slice, overlaid to T2 image.}
  \label{fig:invivo1}
\end{figure}

\section{Discussions}
Functional connectivity is a key step of understanding human brain's functional
networks, since it contains all the information of how each functional region
interacts with other regions. There are multiple ways of modeling functional
systems. One is defining some regions of interest (ROI) as the nodes on the
graph, and estimate the connectivities among these ROIs. The ROI definition has
no standard to follow. One can either define them according to the anatomical
structure, or by a parcellation on the functional data. The other way of
representing functional network is to cluster the full brain volume (indeed the
gray matter voxels) in to small regions. Regions are in the same cluster are
highly connected even they are spatially remote. Our method can be seen as a
pre-step of the above two methods. One potential usage of the full connectivity
matrix is the exploring the connectivity given a single seed coordinates. That
is, given the seed, one can explore the posterior connectivity between the seed
voxel and the full brain volume, in a real time. And such full connectivity will
be dynamically shown with the changing seed's location. Such dynamic, and
potentially user-interactive functional connectivity exploratory concept has
been partly realized by Yeo et al.~\cite{yeo2011organization}, though they did
not use MRF to model the spatial constraints of the connectivity
variables. Instead, Yeo use a large group of subjects and obtained a highly
consistent population functoinal connectivity network. The network can be
visualized given a seed region and also the change of the network patterns when
the seed changes.

On the optimization side, the MCEM algorithm, and the wider class of sampling
method is potentially a good candidate for the the application of GPU. Although
theoretically the computation on GPU need independence bewteen the data points,
the order of voxels being sampled have no effect on the quality of the samples
once the sampling reaches stationary distribution. Therefore, even at each scan,
the order, or the schedule of the data points change in an undetermined way
within the GPU cores, we can still get samples in the target distribtuion give
enough burn-in time.

Alternative optimization methods other than MCEM exist, such as graph
cut. However, graph cut tens to igore local features in order to acheieve a
global optimum. Because of such property, the estimated hidden variables are
mostly blob-like patterns with small ratio of boundary and area. Such preference
does not reflect the true structure in the data. As a result the estimation of
the parameters $\beta$ in \eqref{eq:A1} is also biased towards a larger value
than the true value, since the true $X$ is not as smooth as the estimated
one. Therefore, we choose to use MCEM in our EM procedure for unbiased
estimation of parameters.

% graph cut

